
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>2. Assessment &#8212; Fairlearn 0.6.2 documentation</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet" />
  <link href="../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/basic.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/custom.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.1c5a1a01449ed65a7b51.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>window.MathJax = {"tex": {"macros": {"E": "{\\mathbb{E}}", "P": "{\\mathbb{P}}", "given": "\\mathbin{\\vert}"}}}</script>
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="3. Mitigation" href="mitigation.html" />
    <link rel="prev" title="1. Fairness in Machine Learning" href="fairness_in_machine_learning.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    

<a class="navbar-brand" href="https://fairlearn.org">
  <img src="../_static/fairlearn_full_color.svg" class="logo" alt="logo">
</a>


    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../about/index.html">
  About
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../quickstart.html">
  Quickstart
 </a>
</li>

<li class="toctree-l1 current active nav-item">
 <a class="reference internal nav-link" href="index.html">
  User Guide
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../api_reference/index.html">
  API Reference
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../auto_examples/index.html">
  Example Notebooks
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../contributor_guide/index.html">
  Contributor Guide
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../faq.html">
  FAQ
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/fairlearn/fairlearn" rel="noopener" target="_blank" title="GitHub">
            <span><i class="fab fa-github"></i></span>
            <label class="sr-only">GitHub</label>
          </a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="https://twitter.com/fairlearn" rel="noopener" target="_blank" title="Twitter">
            <span><i class="fab fa-twitter"></i></span>
            <label class="sr-only">Twitter</label>
          </a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="https://stackoverflow.com/questions/tagged/fairlearn" rel="noopener" target="_blank" title="StackOverflow">
            <span><i class="fab fa-stack-overflow"></i></span>
            <label class="sr-only">StackOverflow</label>
          </a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="https://discord.gg/R22yCfgsRn" rel="noopener" target="_blank" title="Discord">
            <span><i class="fab fa-discord"></i></span>
            <label class="sr-only">Discord</label>
          </a>
        </li>
      </ul>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar"><div class="sidebar-message">
  
  <h4>Versions</h4>
  <ul>
      
        
          <li><a href="../../v0.4.6/user_guide/assessment.html">v0.4.6</a></li>
        
      
      
        
          <li><a href="../../v0.5.0/user_guide/assessment.html">v0.5.0</a></li>
        
      
      
        
          <li><strong><a href="assessment.html">v0.6.2</a></strong></li>
        
      
      
        
          <li><a href="../../v0.7.0/user_guide/assessment.html">v0.7.0</a></li>
        
      
      
        
          <li><a href="../../main/user_guide/assessment.html">main</a></li>
        
      
  </ul>
  
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="fairness_in_machine_learning.html">
   1. Fairness in Machine Learning
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   2. Assessment
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="mitigation.html">
   3. Mitigation
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="migrating_versions/index.html">
   4. Migrating from prior versions
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="migrating_versions/migrating_to_v0_5_0.html">
     4.1. Migrating to v0.5.0 from v0.4.6
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="further_resources.html">
   5. Further Resources
  </a>
 </li>
</ul>

  </div>
</nav>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
              
              <div class="toc-item">
                
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#metrics">
   2.1. Metrics
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ungrouped-metrics">
     2.1.1. Ungrouped Metrics
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#metrics-with-grouping">
     2.1.2. Metrics with Grouping
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#scalar-results-from-metricframe">
     2.1.3. Scalar Results from
     <code class="code docutils literal notranslate">
      <span class="pre">
       MetricFrame
      </span>
     </code>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#control-features-for-grouped-metrics">
     2.1.4. Control features for grouped metrics
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#fairlearn-dashboard">
   2.2. Fairlearn dashboard
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#setup-and-a-single-model-assessment">
     2.2.1. Setup and a single-model assessment
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#comparing-multiple-models">
     2.2.2. Comparing multiple models
    </a>
   </li>
  </ul>
 </li>
</ul>

</nav>
              </div>
              
              <div class="toc-item">
                
              </div>
              
            
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <div class="section" id="assessment">
<h1><span class="section-number">2. </span>Assessment<a class="headerlink" href="#assessment" title="Permalink to this headline">¶</a></h1>
<div class="section" id="metrics">
<h2><span class="section-number">2.1. </span>Metrics<a class="headerlink" href="#metrics" title="Permalink to this headline">¶</a></h2>
<p>The <a class="reference internal" href="../api_reference/fairlearn.metrics.html#module-fairlearn.metrics" title="fairlearn.metrics"><code class="xref py py-mod docutils literal notranslate"><span class="pre">fairlearn.metrics</span></code></a> module provides the means to assess fairness-related
metrics for models. This applies for any kind of model that users may already
use, but also for models created with mitigation techniques from the
<a class="reference internal" href="mitigation.html#mitigation"><span class="std std-ref">Mitigation</span></a> section. The <a class="reference internal" href="#dashboard"><span class="std std-ref">Fairlearn dashboard</span></a> provides a visual way to
compare metrics between models as well as compare metrics for different groups
on a single model.</p>
<div class="section" id="ungrouped-metrics">
<h3><span class="section-number">2.1.1. </span>Ungrouped Metrics<a class="headerlink" href="#ungrouped-metrics" title="Permalink to this headline">¶</a></h3>
<p>At their simplest, metrics take a set of ‘true’ values <span class="math notranslate nohighlight">\(Y_{true}\)</span> (from
the input data) and predicted values <span class="math notranslate nohighlight">\(Y_{pred}\)</span> (by applying the model
to the input data), and use these to compute a measure. For example, the
<em>recall</em> or <em>true positive rate</em> is given by</p>
<div class="math notranslate nohighlight">
\[P( Y_{pred}=1 \given Y_{true}=1 )\]</div>
<p>That is, a measure of whether the model finds all the positive cases in the
input data. The <cite>scikit-learn</cite> package implements this in
<a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html#sklearn.metrics.recall_score" title="(in scikit-learn v1.0)"><code class="xref py py-func docutils literal notranslate"><span class="pre">sklearn.metrics.recall_score()</span></code></a>.</p>
<p>Suppose we have the following data we can see that the prediction is <cite>1</cite> in five
of the ten cases where the true value is <cite>1</cite>, so we expect the recall to be 0.5:</p>
<div class="highlight-pycon3 notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">sklearn.metrics</span> <span class="k">as</span> <span class="nn">skm</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">skm</span><span class="o">.</span><span class="n">recall_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="go">0.5</span>
</pre></div>
</div>
</div>
<div class="section" id="metrics-with-grouping">
<span id="id1"></span><h3><span class="section-number">2.1.2. </span>Metrics with Grouping<a class="headerlink" href="#metrics-with-grouping" title="Permalink to this headline">¶</a></h3>
<p>When considering fairness, each row of input data will have an associated
group label <span class="math notranslate nohighlight">\(g \in G\)</span>, and we will want to know how the metric behaves
for each <span class="math notranslate nohighlight">\(g\)</span>. To help with this, Fairlearn provides a class, which takes
an existing (ungrouped) metric function, and applies it to each group within a
set of data.</p>
<p>Suppose in addition to the <span class="math notranslate nohighlight">\(Y_{true}\)</span> and <span class="math notranslate nohighlight">\(Y_{pred}\)</span> above, we had
the following set of labels:</p>
<div class="highlight-pycon3 notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">group_membership_data</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;d&#39;</span><span class="p">,</span> <span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;c&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="s1">&#39;c&#39;</span><span class="p">,</span> <span class="s1">&#39;c&#39;</span><span class="p">,</span> <span class="s1">&#39;c&#39;</span><span class="p">,</span>
<span class="gp">... </span>                         <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="s1">&#39;d&#39;</span><span class="p">,</span> <span class="s1">&#39;c&#39;</span><span class="p">,</span> <span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="s1">&#39;d&#39;</span><span class="p">,</span> <span class="s1">&#39;c&#39;</span><span class="p">,</span> <span class="s1">&#39;c&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;display.max_columns&#39;</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;display.width&#39;</span><span class="p">,</span> <span class="mi">80</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span> <span class="s1">&#39;y_true&#39;</span><span class="p">:</span> <span class="n">y_true</span><span class="p">,</span>
<span class="gp">... </span>               <span class="s1">&#39;y_pred&#39;</span><span class="p">:</span> <span class="n">y_pred</span><span class="p">,</span>
<span class="gp">... </span>               <span class="s1">&#39;group_membership_data&#39;</span><span class="p">:</span> <span class="n">group_membership_data</span><span class="p">})</span>
<span class="go">    y_true  y_pred group_membership_data</span>
<span class="go">0        0       0                     d</span>
<span class="go">1        1       0                     a</span>
<span class="go">2        1       1                     c</span>
<span class="go">3        1       0                     b</span>
<span class="go">4        1       1                     b</span>
<span class="go">5        0       1                     c</span>
<span class="go">6        1       1                     c</span>
<span class="go">7        0       0                     c</span>
<span class="go">8        1       0                     b</span>
<span class="go">9        0       1                     d</span>
<span class="go">10       0       1                     c</span>
<span class="go">11       0       1                     a</span>
<span class="go">12       1       1                     b</span>
<span class="go">13       1       0                     d</span>
<span class="go">14       1       0                     c</span>
<span class="go">15       1       1                     c</span>
</pre></div>
</div>
<p>We then calculate a metric which shows the subgroups:</p>
<div class="highlight-pycon3 notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">fairlearn.metrics</span> <span class="kn">import</span> <span class="n">MetricFrame</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">grouped_metric</span> <span class="o">=</span> <span class="n">MetricFrame</span><span class="p">(</span><span class="n">skm</span><span class="o">.</span><span class="n">recall_score</span><span class="p">,</span>
<span class="gp">... </span>                             <span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span>
<span class="gp">... </span>                             <span class="n">sensitive_features</span><span class="o">=</span><span class="n">group_membership_data</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Overall recall = &quot;</span><span class="p">,</span> <span class="n">grouped_metric</span><span class="o">.</span><span class="n">overall</span><span class="p">)</span>
<span class="go">Overall recall =  0.5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;recall by groups = &quot;</span><span class="p">,</span> <span class="n">grouped_metric</span><span class="o">.</span><span class="n">by_group</span><span class="o">.</span><span class="n">to_dict</span><span class="p">())</span>
<span class="go">recall by groups =  {&#39;a&#39;: 0.0, &#39;b&#39;: 0.5, &#39;c&#39;: 0.75, &#39;d&#39;: 0.0}</span>
</pre></div>
</div>
<p>Note that the overall recall is the same as that calculated above in the
Ungrouped Metric section, while the ‘by group’ dictionary can be checked
against the table above.</p>
<p>In addition to these basic scores, Fairlearn also provides
convenience functions to recover the maximum and minimum values of the metric
across groups and also the difference and ratio between the maximum and minimum:</p>
<div class="highlight-pycon3 notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;min recall over groups = &quot;</span><span class="p">,</span> <span class="n">grouped_metric</span><span class="o">.</span><span class="n">group_min</span><span class="p">())</span>
<span class="go">min recall over groups =  0.0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;max recall over groups = &quot;</span><span class="p">,</span> <span class="n">grouped_metric</span><span class="o">.</span><span class="n">group_max</span><span class="p">())</span>
<span class="go">max recall over groups =  0.75</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;difference in recall = &quot;</span><span class="p">,</span> <span class="n">grouped_metric</span><span class="o">.</span><span class="n">difference</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s1">&#39;between_groups&#39;</span><span class="p">))</span>
<span class="go">difference in recall =  0.75</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;ratio in recall = &quot;</span><span class="p">,</span> <span class="n">grouped_metric</span><span class="o">.</span><span class="n">ratio</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s1">&#39;between_groups&#39;</span><span class="p">))</span>
<span class="go">ratio in recall =  0.0</span>
</pre></div>
</div>
<p>A single instance of <a class="reference internal" href="../api_reference/fairlearn.metrics.html#fairlearn.metrics.MetricFrame" title="fairlearn.metrics.MetricFrame"><code class="xref py py-class docutils literal notranslate"><span class="pre">fairlearn.metrics.MetricFrame</span></code></a> can evaluate multiple
metrics simultaneously:</p>
<div class="highlight-pycon3 notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">multi_metric</span> <span class="o">=</span> <span class="n">MetricFrame</span><span class="p">({</span><span class="s1">&#39;precision&#39;</span><span class="p">:</span><span class="n">skm</span><span class="o">.</span><span class="n">precision_score</span><span class="p">,</span> <span class="s1">&#39;recall&#39;</span><span class="p">:</span><span class="n">skm</span><span class="o">.</span><span class="n">recall_score</span><span class="p">},</span>
<span class="gp">... </span>                            <span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span>
<span class="gp">... </span>                            <span class="n">sensitive_features</span><span class="o">=</span><span class="n">group_membership_data</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">multi_metric</span><span class="o">.</span><span class="n">overall</span>
<span class="go">precision    0.5555...</span>
<span class="go">recall       0.5...</span>
<span class="go">dtype: object</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">multi_metric</span><span class="o">.</span><span class="n">by_group</span>
<span class="go">                    precision recall</span>
<span class="go">sensitive_feature_0</span>
<span class="go">a                         0.0   0.0</span>
<span class="go">b                         1.0   0.5</span>
<span class="go">c                         0.6   0.75</span>
<span class="go">d                         0.0   0.0</span>
</pre></div>
</div>
<p>If there are per-sample arguments (such as sample weights), these can also be provided
in a dictionary via the <code class="docutils literal notranslate"><span class="pre">sample_params</span></code> argument.:</p>
<div class="highlight-pycon3 notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">s_w</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">s_p</span> <span class="o">=</span> <span class="p">{</span> <span class="s1">&#39;sample_weight&#39;</span><span class="p">:</span><span class="n">s_w</span> <span class="p">}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">weighted</span> <span class="o">=</span> <span class="n">MetricFrame</span><span class="p">(</span><span class="n">skm</span><span class="o">.</span><span class="n">recall_score</span><span class="p">,</span>
<span class="gp">... </span>                       <span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span>
<span class="gp">... </span>                       <span class="n">sensitive_features</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">group_membership_data</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;SF 0&#39;</span><span class="p">),</span>
<span class="gp">... </span>                       <span class="n">sample_params</span><span class="o">=</span><span class="n">s_p</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">weighted</span><span class="o">.</span><span class="n">overall</span>
<span class="go">0.45</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">weighted</span><span class="o">.</span><span class="n">by_group</span>
<span class="go">SF 0</span>
<span class="go">a    0...</span>
<span class="go">b    0.5...</span>
<span class="go">c    0.7142...</span>
<span class="go">d    0...</span>
<span class="go">Name: recall_score, dtype: object</span>
</pre></div>
</div>
<p>If mutiple metrics are being evaluated, then <code class="docutils literal notranslate"><span class="pre">sample_params</span></code> becomes a dictionary of
dictionaries, with the first key corresponding matching that in the dictionary holding
the desired underlying metric functions.</p>
<p>We do not support non-sample parameters at the current time. If these are required, then
use <a class="reference external" href="https://docs.python.org/3/library/functools.html#functools.partial" title="(in Python v3.10)"><code class="xref py py-func docutils literal notranslate"><span class="pre">functools.partial()</span></code></a> to prebind the required arguments to the metric
function:</p>
<div class="highlight-pycon3 notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">functools</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">fbeta_06</span> <span class="o">=</span> <span class="n">functools</span><span class="o">.</span><span class="n">partial</span><span class="p">(</span><span class="n">skm</span><span class="o">.</span><span class="n">fbeta_score</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">0.6</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metric_beta</span> <span class="o">=</span> <span class="n">MetricFrame</span><span class="p">(</span><span class="n">fbeta_06</span><span class="p">,</span>
<span class="gp">... </span>                          <span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span>
<span class="gp">... </span>                          <span class="n">sensitive_features</span><span class="o">=</span><span class="n">group_membership_data</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metric_beta</span><span class="o">.</span><span class="n">overall</span>
<span class="go">0.5396825396825397</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metric_beta</span><span class="o">.</span><span class="n">by_group</span>
<span class="go">sensitive_feature_0</span>
<span class="go">a    0...</span>
<span class="go">b    0.7906...</span>
<span class="go">c    0.6335...</span>
<span class="go">d    0...</span>
<span class="go">Name: metric, dtype: object</span>
</pre></div>
</div>
<p>Finally, multiple sensitive features can be specified. The <code class="docutils literal notranslate"><span class="pre">by_groups</span></code> property then
holds the intersections of these groups:</p>
<div class="highlight-pycon3 notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">g_2</span> <span class="o">=</span> <span class="p">[</span> <span class="mi">8</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">6</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">s_f_frame</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">group_membership_data</span><span class="p">,</span> <span class="n">g_2</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
<span class="gp">... </span>                         <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;SF 0&#39;</span><span class="p">,</span> <span class="s1">&#39;SF 1&#39;</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metric_2sf</span> <span class="o">=</span> <span class="n">MetricFrame</span><span class="p">(</span><span class="n">skm</span><span class="o">.</span><span class="n">recall_score</span><span class="p">,</span>
<span class="gp">... </span>                         <span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span>
<span class="gp">... </span>                         <span class="n">sensitive_features</span><span class="o">=</span><span class="n">s_f_frame</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metric_2sf</span><span class="o">.</span><span class="n">overall</span>  <span class="c1"># Same as before</span>
<span class="go">0.5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metric_2sf</span><span class="o">.</span><span class="n">by_group</span>
<span class="go">SF 0  SF 1</span>
<span class="go">a     6       0.0</span>
<span class="go">      8       NaN</span>
<span class="go">b     6       0.5</span>
<span class="go">      8       0.5</span>
<span class="go">c     6       1.0</span>
<span class="go">      8       0.5</span>
<span class="go">d     6       0.0</span>
<span class="go">      8       0.0</span>
<span class="go">Name: recall_score, dtype: object</span>
</pre></div>
</div>
<p>With such a small number of samples, we are obviously running into cases where
there are no members in a particular combination of sensitive features. In this
case we see that the subgroup <code class="docutils literal notranslate"><span class="pre">(a,</span> <span class="pre">8)</span></code> has a result of <code class="docutils literal notranslate"><span class="pre">NaN</span></code>, indicating
that there were no samples in it.</p>
</div>
<div class="section" id="scalar-results-from-metricframe">
<span id="scalar-metric-results"></span><h3><span class="section-number">2.1.3. </span>Scalar Results from <code class="code docutils literal notranslate"><span class="pre">MetricFrame</span></code><a class="headerlink" href="#scalar-results-from-metricframe" title="Permalink to this headline">¶</a></h3>
<p>Higher level machine learning algorithms (such as hyperparameter tuners) often
make use of metric functions to guide their optimisations.
Such algorithms generally work with scalar results, so if we want the tuning
to be done on the basis of our fairness metrics, we need to perform aggregations
over the <a class="reference internal" href="../api_reference/fairlearn.metrics.html#fairlearn.metrics.MetricFrame" title="fairlearn.metrics.MetricFrame"><code class="xref py py-class docutils literal notranslate"><span class="pre">MetricFrame</span></code></a>.</p>
<p>We provide a convenience function, <a class="reference internal" href="../api_reference/fairlearn.metrics.html#fairlearn.metrics.make_derived_metric" title="fairlearn.metrics.make_derived_metric"><code class="xref py py-func docutils literal notranslate"><span class="pre">fairlearn.metrics.make_derived_metric()</span></code></a>,
to generate scalar-producing metric functions based on the aggregation methods
mentioned above (<a class="reference internal" href="../api_reference/fairlearn.metrics.html#fairlearn.metrics.MetricFrame.group_min" title="fairlearn.metrics.MetricFrame.group_min"><code class="xref py py-meth docutils literal notranslate"><span class="pre">MetricFrame.group_min()</span></code></a>, <a class="reference internal" href="../api_reference/fairlearn.metrics.html#fairlearn.metrics.MetricFrame.group_max" title="fairlearn.metrics.MetricFrame.group_max"><code class="xref py py-meth docutils literal notranslate"><span class="pre">MetricFrame.group_max()</span></code></a>,
<a class="reference internal" href="../api_reference/fairlearn.metrics.html#fairlearn.metrics.MetricFrame.difference" title="fairlearn.metrics.MetricFrame.difference"><code class="xref py py-meth docutils literal notranslate"><span class="pre">MetricFrame.difference()</span></code></a>, and <a class="reference internal" href="../api_reference/fairlearn.metrics.html#fairlearn.metrics.MetricFrame.ratio" title="fairlearn.metrics.MetricFrame.ratio"><code class="xref py py-meth docutils literal notranslate"><span class="pre">MetricFrame.ratio()</span></code></a>).
This takes an underlying metric function, the name of the desired transformation, and
optionally a list of parameter names which should be treated as sample aligned parameters
(such as <cite>sample_weight</cite>).
Other parameters will be passed to the underlying metric function normally (unlike
<a class="reference internal" href="../api_reference/fairlearn.metrics.html#fairlearn.metrics.MetricFrame" title="fairlearn.metrics.MetricFrame"><code class="xref py py-class docutils literal notranslate"><span class="pre">MetricFrame</span></code></a> where <a class="reference external" href="https://docs.python.org/3/library/functools.html#functools.partial" title="(in Python v3.10)"><code class="xref py py-func docutils literal notranslate"><span class="pre">functools.partial()</span></code></a> must be used, as noted above).
The result is a function which builds the <a class="reference internal" href="../api_reference/fairlearn.metrics.html#fairlearn.metrics.MetricFrame" title="fairlearn.metrics.MetricFrame"><code class="xref py py-class docutils literal notranslate"><span class="pre">MetricFrame</span></code></a> internally and performs
the requested aggregation. For example:</p>
<div class="highlight-pycon3 notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">fairlearn.metrics</span> <span class="kn">import</span> <span class="n">make_derived_metric</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">fbeta_difference</span> <span class="o">=</span> <span class="n">make_derived_metric</span><span class="p">(</span><span class="n">metric</span><span class="o">=</span><span class="n">skm</span><span class="o">.</span><span class="n">fbeta_score</span><span class="p">,</span>
<span class="gp">... </span>                                       <span class="n">transform</span><span class="o">=</span><span class="s1">&#39;difference&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Don&#39;t need functools.partial for make_derived_metric</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">fbeta_difference</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span>
<span class="gp">... </span>                 <span class="n">sensitive_features</span><span class="o">=</span><span class="n">group_membership_data</span><span class="p">)</span>
<span class="go">0.752525...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># But as noted above, functools.partial is needed for MetricFrame</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">fbeta_07</span> <span class="o">=</span> <span class="n">functools</span><span class="o">.</span><span class="n">partial</span><span class="p">(</span><span class="n">skm</span><span class="o">.</span><span class="n">fbeta_score</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">MetricFrame</span><span class="p">(</span><span class="n">fbeta_07</span><span class="p">,</span>
<span class="gp">... </span>            <span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span>
<span class="gp">... </span>            <span class="n">sensitive_features</span><span class="o">=</span><span class="n">group_membership_data</span><span class="p">)</span><span class="o">.</span><span class="n">difference</span><span class="p">()</span>
<span class="go">0.752525...</span>
</pre></div>
</div>
<p>We use <a class="reference internal" href="../api_reference/fairlearn.metrics.html#fairlearn.metrics.make_derived_metric" title="fairlearn.metrics.make_derived_metric"><code class="xref py py-func docutils literal notranslate"><span class="pre">fairlearn.metrics.make_derived_metric()</span></code></a> to manufacture a number
of such functions which will be commonly used:</p>
<table class="table">
<colgroup>
<col style="width: 42%" />
<col style="width: 15%" />
<col style="width: 15%" />
<col style="width: 16%" />
<col style="width: 12%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Base metric</p></th>
<th class="head"><p><code class="code docutils literal notranslate"><span class="pre">group_min</span></code></p></th>
<th class="head"><p><code class="code docutils literal notranslate"><span class="pre">group_max</span></code></p></th>
<th class="head"><p><code class="code docutils literal notranslate"><span class="pre">difference</span></code></p></th>
<th class="head"><p><code class="code docutils literal notranslate"><span class="pre">ratio</span></code></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><a class="reference internal" href="../api_reference/fairlearn.metrics.html#fairlearn.metrics.false_negative_rate" title="fairlearn.metrics.false_negative_rate"><code class="xref py py-func docutils literal notranslate"><span class="pre">false_negative_rate()</span></code></a></p></td>
<td><p>.</p></td>
<td><p>.</p></td>
<td><p>Y</p></td>
<td><p>Y</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="../api_reference/fairlearn.metrics.html#fairlearn.metrics.false_positive_rate" title="fairlearn.metrics.false_positive_rate"><code class="xref py py-func docutils literal notranslate"><span class="pre">false_positive_rate()</span></code></a></p></td>
<td><p>.</p></td>
<td><p>.</p></td>
<td><p>Y</p></td>
<td><p>Y</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="../api_reference/fairlearn.metrics.html#fairlearn.metrics.selection_rate" title="fairlearn.metrics.selection_rate"><code class="xref py py-func docutils literal notranslate"><span class="pre">selection_rate()</span></code></a></p></td>
<td><p>.</p></td>
<td><p>.</p></td>
<td><p>Y</p></td>
<td><p>Y</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="../api_reference/fairlearn.metrics.html#fairlearn.metrics.true_negative_rate" title="fairlearn.metrics.true_negative_rate"><code class="xref py py-func docutils literal notranslate"><span class="pre">true_negative_rate()</span></code></a></p></td>
<td><p>.</p></td>
<td><p>.</p></td>
<td><p>Y</p></td>
<td><p>Y</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="../api_reference/fairlearn.metrics.html#fairlearn.metrics.true_positive_rate" title="fairlearn.metrics.true_positive_rate"><code class="xref py py-func docutils literal notranslate"><span class="pre">true_positive_rate()</span></code></a></p></td>
<td><p>.</p></td>
<td><p>.</p></td>
<td><p>Y</p></td>
<td><p>Y</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score" title="(in scikit-learn v1.0)"><code class="xref py py-func docutils literal notranslate"><span class="pre">sklearn.metrics.accuracy_score()</span></code></a></p></td>
<td><p>Y</p></td>
<td><p>.</p></td>
<td><p>Y</p></td>
<td><p>Y</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.balanced_accuracy_score.html#sklearn.metrics.balanced_accuracy_score" title="(in scikit-learn v1.0)"><code class="xref py py-func docutils literal notranslate"><span class="pre">sklearn.metrics.balanced_accuracy_score()</span></code></a></p></td>
<td><p>Y</p></td>
<td><p>.</p></td>
<td><p>.</p></td>
<td><p>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score" title="(in scikit-learn v1.0)"><code class="xref py py-func docutils literal notranslate"><span class="pre">sklearn.metrics.f1_score()</span></code></a></p></td>
<td><p>Y</p></td>
<td><p>.</p></td>
<td><p>.</p></td>
<td><p>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.log_loss.html#sklearn.metrics.log_loss" title="(in scikit-learn v1.0)"><code class="xref py py-func docutils literal notranslate"><span class="pre">sklearn.metrics.log_loss()</span></code></a></p></td>
<td><p>.</p></td>
<td><p>Y</p></td>
<td><p>.</p></td>
<td><p>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html#sklearn.metrics.mean_absolute_error" title="(in scikit-learn v1.0)"><code class="xref py py-func docutils literal notranslate"><span class="pre">sklearn.metrics.mean_absolute_error()</span></code></a></p></td>
<td><p>.</p></td>
<td><p>Y</p></td>
<td><p>.</p></td>
<td><p>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html#sklearn.metrics.mean_squared_error" title="(in scikit-learn v1.0)"><code class="xref py py-func docutils literal notranslate"><span class="pre">sklearn.metrics.mean_squared_error()</span></code></a></p></td>
<td><p>.</p></td>
<td><p>Y</p></td>
<td><p>.</p></td>
<td><p>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html#sklearn.metrics.precision_score" title="(in scikit-learn v1.0)"><code class="xref py py-func docutils literal notranslate"><span class="pre">sklearn.metrics.precision_score()</span></code></a></p></td>
<td><p>Y</p></td>
<td><p>.</p></td>
<td><p>.</p></td>
<td><p>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html#sklearn.metrics.r2_score" title="(in scikit-learn v1.0)"><code class="xref py py-func docutils literal notranslate"><span class="pre">sklearn.metrics.r2_score()</span></code></a></p></td>
<td><p>Y</p></td>
<td><p>.</p></td>
<td><p>.</p></td>
<td><p>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html#sklearn.metrics.recall_score" title="(in scikit-learn v1.0)"><code class="xref py py-func docutils literal notranslate"><span class="pre">sklearn.metrics.recall_score()</span></code></a></p></td>
<td><p>Y</p></td>
<td><p>.</p></td>
<td><p>.</p></td>
<td><p>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score" title="(in scikit-learn v1.0)"><code class="xref py py-func docutils literal notranslate"><span class="pre">sklearn.metrics.roc_auc_score()</span></code></a></p></td>
<td><p>Y</p></td>
<td><p>.</p></td>
<td><p>.</p></td>
<td><p>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.zero_one_loss.html#sklearn.metrics.zero_one_loss" title="(in scikit-learn v1.0)"><code class="xref py py-func docutils literal notranslate"><span class="pre">sklearn.metrics.zero_one_loss()</span></code></a></p></td>
<td><p>.</p></td>
<td><p>Y</p></td>
<td><p>Y</p></td>
<td><p>Y</p></td>
</tr>
</tbody>
</table>
<p>The names of the generated functions are of the form
<code class="code docutils literal notranslate"><span class="pre">fairlearn.metrics.&lt;base_metric&gt;_&lt;transformation&gt;</span></code>.
For example <code class="code docutils literal notranslate"><span class="pre">fairlearn.metrics.accuracy_score_difference</span></code> and
<code class="code docutils literal notranslate"><span class="pre">fairlearn.metrics.precision_score_group_min</span></code>.</p>
</div>
<div class="section" id="control-features-for-grouped-metrics">
<span id="control-features-metrics"></span><h3><span class="section-number">2.1.4. </span>Control features for grouped metrics<a class="headerlink" href="#control-features-for-grouped-metrics" title="Permalink to this headline">¶</a></h3>
<p>Control features (sometimes called ‘conditional’ features) enable more detailed
fairness insights by providing a further means of splitting the data into
subgroups.
When the data are split into subgroups, control features (if provided) act
similarly to sensitive features.
However, the ‘overall’ value for the metric is now computed for each subgroup
of the control feature(s).
Similarly, the aggregation functions (such as <code class="code docutils literal notranslate"><span class="pre">MetricFrame.group_max</span></code>) are
performed for each subgroup in the conditional feature(s), rather than across
them (as happens with the sensitive features).</p>
<p>Control features are useful for cases where there is some expected variation with
a feature, so we need to compute disparities while controlling for that feature.
For example, in a loan scenario we would expect people of differing incomes to
be approved at different rates, but within each income band we would still
want to measure disparities between different sensitive features. However, it
should be borne in mind that due to historic discrimination, the income band
might be correlated with various sensitive features. Because of this, control
features should be used with particular caution.</p>
<p>The <a class="reference internal" href="../api_reference/fairlearn.metrics.html#fairlearn.metrics.MetricFrame" title="fairlearn.metrics.MetricFrame"><code class="xref py py-class docutils literal notranslate"><span class="pre">MetricFrame</span></code></a> constructor allows us to specify control features in
a manner similar to sensitive features, using a <code class="code docutils literal notranslate"><span class="pre">conditional_features=</span></code>
parameter:</p>
<div class="highlight-pycon3 notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">decision</span> <span class="o">=</span> <span class="p">[</span>
<span class="gp">... </span>   <span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span>
<span class="gp">... </span>   <span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span>
<span class="gp">... </span>   <span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span>
<span class="gp">... </span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">prediction</span> <span class="o">=</span> <span class="p">[</span>
<span class="gp">... </span>   <span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span>
<span class="gp">... </span>   <span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span>
<span class="gp">... </span>   <span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span>
<span class="gp">... </span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">control_feature</span> <span class="o">=</span> <span class="p">[</span>
<span class="gp">... </span>   <span class="s1">&#39;H&#39;</span><span class="p">,</span><span class="s1">&#39;L&#39;</span><span class="p">,</span><span class="s1">&#39;H&#39;</span><span class="p">,</span><span class="s1">&#39;L&#39;</span><span class="p">,</span><span class="s1">&#39;H&#39;</span><span class="p">,</span><span class="s1">&#39;L&#39;</span><span class="p">,</span><span class="s1">&#39;L&#39;</span><span class="p">,</span><span class="s1">&#39;H&#39;</span><span class="p">,</span><span class="s1">&#39;H&#39;</span><span class="p">,</span><span class="s1">&#39;L&#39;</span><span class="p">,</span>
<span class="gp">... </span>   <span class="s1">&#39;L&#39;</span><span class="p">,</span><span class="s1">&#39;H&#39;</span><span class="p">,</span><span class="s1">&#39;H&#39;</span><span class="p">,</span><span class="s1">&#39;L&#39;</span><span class="p">,</span><span class="s1">&#39;L&#39;</span><span class="p">,</span><span class="s1">&#39;H&#39;</span><span class="p">,</span><span class="s1">&#39;L&#39;</span><span class="p">,</span><span class="s1">&#39;L&#39;</span><span class="p">,</span><span class="s1">&#39;H&#39;</span><span class="p">,</span><span class="s1">&#39;H&#39;</span><span class="p">,</span>
<span class="gp">... </span>   <span class="s1">&#39;L&#39;</span><span class="p">,</span><span class="s1">&#39;H&#39;</span><span class="p">,</span><span class="s1">&#39;L&#39;</span><span class="p">,</span><span class="s1">&#39;L&#39;</span><span class="p">,</span><span class="s1">&#39;H&#39;</span><span class="p">,</span><span class="s1">&#39;H&#39;</span><span class="p">,</span><span class="s1">&#39;L&#39;</span><span class="p">,</span><span class="s1">&#39;L&#39;</span><span class="p">,</span><span class="s1">&#39;H&#39;</span><span class="p">,</span><span class="s1">&#39;L&#39;</span>
<span class="gp">... </span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sensitive_feature</span> <span class="o">=</span> <span class="p">[</span>
<span class="gp">... </span>   <span class="s1">&#39;A&#39;</span><span class="p">,</span><span class="s1">&#39;B&#39;</span><span class="p">,</span><span class="s1">&#39;B&#39;</span><span class="p">,</span><span class="s1">&#39;C&#39;</span><span class="p">,</span><span class="s1">&#39;C&#39;</span><span class="p">,</span><span class="s1">&#39;B&#39;</span><span class="p">,</span><span class="s1">&#39;A&#39;</span><span class="p">,</span><span class="s1">&#39;A&#39;</span><span class="p">,</span><span class="s1">&#39;B&#39;</span><span class="p">,</span><span class="s1">&#39;A&#39;</span><span class="p">,</span>
<span class="gp">... </span>   <span class="s1">&#39;C&#39;</span><span class="p">,</span><span class="s1">&#39;B&#39;</span><span class="p">,</span><span class="s1">&#39;C&#39;</span><span class="p">,</span><span class="s1">&#39;A&#39;</span><span class="p">,</span><span class="s1">&#39;C&#39;</span><span class="p">,</span><span class="s1">&#39;C&#39;</span><span class="p">,</span><span class="s1">&#39;B&#39;</span><span class="p">,</span><span class="s1">&#39;B&#39;</span><span class="p">,</span><span class="s1">&#39;C&#39;</span><span class="p">,</span><span class="s1">&#39;A&#39;</span><span class="p">,</span>
<span class="gp">... </span>   <span class="s1">&#39;B&#39;</span><span class="p">,</span><span class="s1">&#39;B&#39;</span><span class="p">,</span><span class="s1">&#39;C&#39;</span><span class="p">,</span><span class="s1">&#39;A&#39;</span><span class="p">,</span><span class="s1">&#39;B&#39;</span><span class="p">,</span><span class="s1">&#39;A&#39;</span><span class="p">,</span><span class="s1">&#39;B&#39;</span><span class="p">,</span><span class="s1">&#39;B&#39;</span><span class="p">,</span><span class="s1">&#39;A&#39;</span><span class="p">,</span><span class="s1">&#39;A&#39;</span>
<span class="gp">... </span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metric_c_f</span> <span class="o">=</span> <span class="n">MetricFrame</span><span class="p">(</span><span class="n">skm</span><span class="o">.</span><span class="n">accuracy_score</span><span class="p">,</span>
<span class="gp">... </span>                         <span class="n">decision</span><span class="p">,</span> <span class="n">prediction</span><span class="p">,</span>
<span class="gp">... </span>                         <span class="n">sensitive_features</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;SF&#39;</span> <span class="p">:</span> <span class="n">sensitive_feature</span><span class="p">},</span>
<span class="gp">... </span>                         <span class="n">control_features</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;CF&#39;</span> <span class="p">:</span> <span class="n">control_feature</span><span class="p">})</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># The &#39;overall&#39; property is now split based on the control feature</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metric_c_f</span><span class="o">.</span><span class="n">overall</span>
<span class="go">CF</span>
<span class="go">H    0.4285...</span>
<span class="go">L    0.375...</span>
<span class="go">Name: accuracy_score, dtype: object</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># The &#39;by_group&#39; property looks similar to how it would if we had two sensitive features</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metric_c_f</span><span class="o">.</span><span class="n">by_group</span>
<span class="go">CF  SF</span>
<span class="go">H   A     0.2...</span>
<span class="go">    B     0.4...</span>
<span class="go">    C     0.75...</span>
<span class="go">L   A     0.4...</span>
<span class="go">    B     0.2857...</span>
<span class="go">    C     0.5...</span>
<span class="go">Name: accuracy_score, dtype: object</span>
</pre></div>
</div>
<p>Note how the <a class="reference internal" href="../api_reference/fairlearn.metrics.html#fairlearn.metrics.MetricFrame.overall" title="fairlearn.metrics.MetricFrame.overall"><code class="xref py py-attr docutils literal notranslate"><span class="pre">MetricFrame.overall</span></code></a> property is stratified based on the
supplied control feature. The <a class="reference internal" href="../api_reference/fairlearn.metrics.html#fairlearn.metrics.MetricFrame.by_group" title="fairlearn.metrics.MetricFrame.by_group"><code class="xref py py-attr docutils literal notranslate"><span class="pre">MetricFrame.by_group</span></code></a> property allows
us to see disparities between the groups in the sensitive feature for each
group in the control feature.
When displayed like this, <a class="reference internal" href="../api_reference/fairlearn.metrics.html#fairlearn.metrics.MetricFrame.by_group" title="fairlearn.metrics.MetricFrame.by_group"><code class="xref py py-attr docutils literal notranslate"><span class="pre">MetricFrame.by_group</span></code></a> looks similar to
how it would if we had specified two sensitive features (although the
control features will always be at the top level of the hierarchy).</p>
<p>With the <a class="reference internal" href="../api_reference/fairlearn.metrics.html#fairlearn.metrics.MetricFrame" title="fairlearn.metrics.MetricFrame"><code class="xref py py-class docutils literal notranslate"><span class="pre">MetricFrame</span></code></a> computed, we can perform aggregations:</p>
<div class="highlight-pycon3 notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># See the maximum accuracy for each value of the control feature</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metric_c_f</span><span class="o">.</span><span class="n">group_max</span><span class="p">()</span>
<span class="go">CF</span>
<span class="go">H    0.75</span>
<span class="go">L    0.50</span>
<span class="go">Name: accuracy_score, dtype: float64</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># See the maximum difference in accuracy for each value of the control feature</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metric_c_f</span><span class="o">.</span><span class="n">difference</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s1">&#39;between_groups&#39;</span><span class="p">)</span>
<span class="go">CF</span>
<span class="go">H    0.55...</span>
<span class="go">L    0.2142...</span>
<span class="go">Name: accuracy_score, dtype: float64</span>
</pre></div>
</div>
<p>In each case, rather than a single scalar, we receive one result for each
subgroup identified by the conditional feature. The call
<code class="code docutils literal notranslate"><span class="pre">metric_c_f.group_max()</span></code> call shows the maximum value of the metric across
the subgroups of the sensitive feature within each value of the control feature.
Similarly, <code class="code docutils literal notranslate"><span class="pre">metric_c_f.difference(method='between_groups')</span></code> call shows the
maximum difference between the subgroups of the sensitive feature within
each value of the control feature.
For more examples, please
see the <a class="reference internal" href="../auto_examples/plot_new_metrics.html#sphx-glr-auto-examples-plot-new-metrics-py"><span class="std std-ref">Metrics with Multiple Features</span></a> notebook in the
<a class="reference internal" href="../auto_examples/index.html#examples"><span class="std std-ref">Example Notebooks</span></a>.</p>
</div>
</div>
<div class="section" id="fairlearn-dashboard">
<span id="dashboard"></span><h2><span class="section-number">2.2. </span>Fairlearn dashboard<a class="headerlink" href="#fairlearn-dashboard" title="Permalink to this headline">¶</a></h2>
<p>The Fairlearn dashboard is a Jupyter notebook widget for assessing how a
model’s predictions impact different groups (e.g., different ethnicities), and
also for comparing multiple models along different fairness and performance
metrics.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The <code class="code docutils literal notranslate"><span class="pre">FairlearnDashboard</span></code> is no longer being developed as
part of Fairlearn.
The widget itself has been moved to
<a class="reference external" href="https://pypi.org/project/raiwidgets/">the raiwidgets package</a>.
Fairlearn will provide some of the existing functionality
through <code class="code docutils literal notranslate"><span class="pre">matplotlib</span></code>-based visualizations.</p>
</div>
<div class="section" id="setup-and-a-single-model-assessment">
<h3><span class="section-number">2.2.1. </span>Setup and a single-model assessment<a class="headerlink" href="#setup-and-a-single-model-assessment" title="Permalink to this headline">¶</a></h3>
<p>To assess a single model’s fairness and performance, the dashboard widget can
be launched within a Jupyter notebook as follows:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">fairlearn.widget</span> <span class="kn">import</span> <span class="n">FairlearnDashboard</span>

<span class="c1"># A_test containts your sensitive features (e.g., age, binary gender)</span>
<span class="c1"># sensitive_feature_names contains your sensitive feature names</span>
<span class="c1"># y_true contains ground truth labels</span>
<span class="c1"># y_pred contains prediction labels</span>

<span class="n">FairlearnDashboard</span><span class="p">(</span><span class="n">sensitive_features</span><span class="o">=</span><span class="n">A_test</span><span class="p">,</span>
                   <span class="n">sensitive_feature_names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;BinaryGender&#39;</span><span class="p">,</span> <span class="s1">&#39;Age&#39;</span><span class="p">],</span>
                   <span class="n">y_true</span><span class="o">=</span><span class="n">Y_test</span><span class="o">.</span><span class="n">tolist</span><span class="p">(),</span>
                   <span class="n">y_pred</span><span class="o">=</span><span class="p">[</span><span class="n">y_pred</span><span class="o">.</span><span class="n">tolist</span><span class="p">()])</span>
</pre></div>
</div>
<p>After the launch, the widget walks the user through the assessment setup,
where the user is asked to select</p>
<ol class="arabic simple">
<li><p>the sensitive feature of interest (e.g., binary gender or age), and</p></li>
<li><p>the performance metric (e.g., model precision) along which to evaluate the
overall model performance as well as any disparities across groups. These
selections are then used to obtain the visualization of the model’s impact
on the subgroups (e.g., model precision for females and model precision for
males).</p></li>
</ol>
<p>The following figures illustrate the setup steps, where <em>binary gender</em> is
selected as a sensitive feature and <em>accuracy rate</em> is selected as the
performance metric.</p>
<img alt="../_images/fairlearn-dashboard-start.png" src="../_images/fairlearn-dashboard-start.png" />
<img alt="../_images/fairlearn-dashboard-multiple-sensitive-features.png" src="../_images/fairlearn-dashboard-multiple-sensitive-features.png" />
<img alt="../_images/fairlearn-dashboard-performance-multiple-sensitive-features.png" src="../_images/fairlearn-dashboard-performance-multiple-sensitive-features.png" />
<p>After the setup, the dashboard presents the model assessment in two panels:</p>
<table class="colwidths-given table">
<colgroup>
<col style="width: 25%" />
<col style="width: 75%" />
</colgroup>
<tbody>
<tr class="row-odd"><th class="stub"><p>Disparity in performance</p></th>
<td><p>This panel shows: (1) the performance of your model with respect to
your selected performance metric (e.g., <em>accuracy rate</em>) overall as
well as on different subgroups based on your selected sensitive
feature (e.g., <em>accuracy rate</em> for females, <em>accuracy rate</em> for
males); (2) the disparity (difference) in the values of the selected
performance metric across different subgroups; (3) the distribution of
errors in each subgroup (e.g., female, male). For binary
classification, the errors are further split into overprediction
(predicting 1 when the true label is 0), and underprediction
(predicting 0 when the true label is 1).</p></td>
</tr>
<tr class="row-even"><th class="stub"><p>Disparity in predictions</p></th>
<td><p>This panel shows a bar chart that contains the selection rate in each
group, meaning the fraction of data classified as 1 (in binary
classification) or distribution of prediction values (in regression).</p></td>
</tr>
</tbody>
</table>
<img alt="../_images/fairlearn-dashboard-disparity-performance-multiple-sensitive-features.png" src="../_images/fairlearn-dashboard-disparity-performance-multiple-sensitive-features.png" />
<img alt="../_images/fairlearn-dashboard-disparity-predictions-multiple-sensitive-features.png" src="../_images/fairlearn-dashboard-disparity-predictions-multiple-sensitive-features.png" />
</div>
<div class="section" id="comparing-multiple-models">
<h3><span class="section-number">2.2.2. </span>Comparing multiple models<a class="headerlink" href="#comparing-multiple-models" title="Permalink to this headline">¶</a></h3>
<p>The dashboard also enables comparison of multiple models, such as the models
produced by different learning algorithms and different mitigation approaches,
including <code class="code docutils literal notranslate"><span class="pre">fairlearn.reductions.GridSearch</span></code>,
<code class="code docutils literal notranslate"><span class="pre">fairlearn.reductions.ExponentiatedGradient</span></code>, and
<code class="code docutils literal notranslate"><span class="pre">fairlearn.postprocessing.ThresholdOptimizer</span></code>.</p>
<p>As before, the user is first asked to select the sensitive feature and the
performance metric. The <em>model comparison</em> view then depicts the performance
and disparity of all the provided models in a scatter plot. This allows the
user to examine trade-offs between performance and fairness. Each of the dots
can be clicked to open the assessment of the corresponding model. The figure
below shows the model comparison view with <em>binary gender</em> selected as a
sensitive feature and <em>accuracy rate</em> selected as the performance metric.</p>
<img alt="../_images/fairlearn-dashboard-models.png" src="../_images/fairlearn-dashboard-models.png" />
</div>
</div>
</div>


              </div>
              
              
          </main>
          

      </div>
    </div>
  
  <script src="../_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  <footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="copyright">
    &copy; Copyright 2018 - 2022, Fairlearn contributors.<br/>
</p>
    </div>
    
    <div class="footer-item">
      <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 4.2.0.<br/>
</p>
    </div>
    
  </div>
</footer>
  </body>
</html>