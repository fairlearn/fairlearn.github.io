{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class='alert alert-warning'>\n\n# This notebook is just for preview\n\nIt isn't possible to install pytorch and run the full example. You can use this notebook to preview the content.\n</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# JupyterLite-specific code\n%pip install fairlearn\n%pip install pyodide-http\nimport pyodide_http\npyodide_http.patch_all()\nimport matplotlib\nimport pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Basics & Model Specification of [AdversarialFairnessClassifier]{.title-ref} {#adversarial_Example_1}\n===========================================================================\n\nThis example shows how to use\n`~fairlearn.adversarial.AdversarialFairnessClassifier`{.interpreted-text\nrole=\"class\"} on the UCI Adult dataset.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, we cover a most basic application of adversarial mitigation. We\nstart by loading and preprocessing the dataset:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from fairlearn.datasets import fetch_adult\n\nX, y = fetch_adult(return_X_y=True)\npos_label = y[0]\n\nz = X[\"sex\"]  # In this example, we consider 'sex' the sensitive feature."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As with other machine learning methods, it is wise to take a train-test\nsplit of the data in order to validate the model on unseen data:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test, Z_train, Z_test = train_test_split(\n    X, y, z, test_size=0.2, random_state=12345, stratify=y\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The UCI adult dataset cannot be fed into a neural network (yet), as we\nhave many columns that are not numerical in nature. To resolve this\nissue, we could for instance use one-hot encodings to preprocess\ncategorical columns. Additionally, let\\'s preprocess the numeric columns\nto a standardized range. For these tasks, we can use functionality from\nscikit-learn (:py`sklearn.preprocessing`{.interpreted-text role=\"mod\"}).\nWe also use an imputer to get rid of NaN\\'s:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import sklearn\nfrom numpy import number\nfrom sklearn.compose import make_column_selector, make_column_transformer\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\n\nsklearn.set_config(enable_metadata_routing=True)\n\nct = make_column_transformer(\n    (\n        Pipeline(\n            [\n                (\"imputer\", SimpleImputer(strategy=\"mean\")),\n                (\"normalizer\", StandardScaler()),\n            ]\n        ),\n        make_column_selector(dtype_include=number),\n    ),\n    (\n        Pipeline(\n            [\n                (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n                (\"encoder\", OneHotEncoder(drop=\"if_binary\", sparse_output=False)),\n            ]\n        ),\n        make_column_selector(dtype_include=\"category\"),\n    ),\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, we can use\n`~fairlearn.adversarial.AdversarialFairnessClassifier`{.interpreted-text\nrole=\"class\"} to train on the UCI Adult dataset. As our predictor and\nadversary models, we use for simplicity the default constructors for\nfully connected neural networks with sigmoid activations implemented in\nFairlearn. We initialize neural network constructors by passing a list\n$h_1, h_2, \\dots$ that indicate the number of nodes $h_i$ per hidden\nlayer $i$. You can also put strings in this list to indicate certain\nactivation functions, or just pass an initialized activation function\ndirectly.\n\nThe specific fairness objective that we choose for this example is\ndemographic parity, so we also set `objective = \"demographic_parity\"`.\nWe generally follow sklearn API, but in this case we require some extra\nkwargs. In particular, we should specify the number of epochs, batch\nsize, whether to shuffle the rows of data after every epoch, and\noptionally after how many seconds to show a progress update:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from fairlearn.adversarial import AdversarialFairnessClassifier\n\nmitigator = AdversarialFairnessClassifier(\n    backend=\"torch\",\n    predictor_model=[50, \"leaky_relu\"],\n    adversary_model=[3, \"leaky_relu\"],\n    batch_size=2**8,\n    progress_updates=0.5,\n    random_state=123,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now put the above model in a `Pipeline` with the transformation step.\nNote that we use `scikit-learn`\\'s metadata routing to pass the\nsensitive feature:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import make_pipeline\n\npipeline = make_pipeline(ct, mitigator.set_fit_request(sensitive_features=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then, we can fit the data to our model:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pipeline.fit(X_train, y_train, sensitive_features=Z_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, we evaluate the predictions. In particular, we trained the\npredictor for demographic parity, so we are not only interested in the\naccuracy, but also in the selection rate. MetricFrames are a great\nresource here:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "predictions = pipeline.predict(X_test)\n\nfrom sklearn.metrics import accuracy_score\n\nfrom fairlearn.metrics import MetricFrame, selection_rate\n\nmf = MetricFrame(\n    metrics={\"accuracy\": accuracy_score, \"selection_rate\": selection_rate},\n    y_true=y_test == pos_label,\n    y_pred=predictions == pos_label,\n    sensitive_features=Z_test,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then, to display the result:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(mf.by_group)\n\n# The above statistics tell us that the accuracy of our model is quite good,\n# 90% for females and 72% for males. However, the selection rates differ, so there\n# is a large demographic disparity here. When using adversarial fairness\n# out-of-the-box, users may not yield such\n# good training results after the first attempt. In general, training\n# adversarial networks is hard, and users may need to tweak the\n# hyperparameters continuously. Besides general scikit-learn algorithms\n# that finetune estimators,\n# :ref:`adversarial_Example_2` will demonstrate some problem-specific\n# techniques we can use such as using dynamic hyperparameters,\n# validation, and early stopping to improve adversarial training."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}