
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Frequently asked questions &#8212; Fairlearn 0.13.0.dev0 documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="_static/plot_directive.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Vibur" />
    <link rel="stylesheet" type="text/css" href="_static/jupyterlite_sphinx.css?v=e3ca86de" />
    <link rel="stylesheet" type="text/css" href="_static/css/hide_links.css?v=81b1ad43" />
    <link rel="stylesheet" type="text/css" href="_static/sg_gallery.css?v=d2d258e8" />
    <link rel="stylesheet" type="text/css" href="_static/sg_gallery-binder.css?v=f4aeca0c" />
    <link rel="stylesheet" type="text/css" href="_static/sg_gallery-dataframe.css?v=2082cf3c" />
    <link rel="stylesheet" type="text/css" href="_static/sg_gallery-rendered-html.css?v=1277b6f3" />
    <link rel="stylesheet" type="text/css" href="_static/css/custom.css?v=8f29ad4c" />
  
  <!-- So that users can add custom icons -->
  <script src="_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="_static/documentation_options.js?v=323ffc05"></script>
    <script src="_static/doctools.js?v=888ff710"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=97f0b27d"></script>
    <script src="_static/jupyterlite_sphinx.js?v=d6bdf5f8"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'faq';</script>
    <script>
        DOCUMENTATION_OPTIONS.theme_version = '0.16.1';
        DOCUMENTATION_OPTIONS.theme_switcher_json_url = 'https://fairlearn.org/main/_static/versions.json';
        DOCUMENTATION_OPTIONS.theme_switcher_version_match = 'main';
        DOCUMENTATION_OPTIONS.show_version_warning_banner =
            false;
        </script>
    <link rel="icon" href="_static/fairlearn-favicon.ico"/>
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="About Us" href="about/index.html" />
    <link rel="prev" title="Release Process" href="contributor_guide/release.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class="col-lg-3 navbar-header-items__start">
    
      <div class="navbar-item">

  
     
  

<a class="navbar-brand logo" href="https://fairlearn.org">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/fairlearn_full_color.svg" class="logo__image only-light" alt="Fairlearn 0.13.0.dev0 documentation - Home"/>
    <img src="_static/fairlearn_full_color.svg" class="logo__image only-dark pst-js-only" alt="Fairlearn 0.13.0.dev0 documentation - Home"/>
  
  
</a></div>
    
      <div class="navbar-item">
<div class="version-switcher__container dropdown pst-js-only">
  <button id="pst-version-switcher-button-2"
    type="button"
    class="version-switcher__button btn btn-sm dropdown-toggle"
    data-bs-toggle="dropdown"
    aria-haspopup="listbox"
    aria-controls="pst-version-switcher-list-2"
    aria-label="Version switcher list"
  >
    Choose version  <!-- this text may get changed later by javascript -->
    <span class="caret"></span>
  </button>
  <div id="pst-version-switcher-list-2"
    class="version-switcher__menu dropdown-menu list-group-flush py-0"
    role="listbox" aria-labelledby="pst-version-switcher-button-2">
    <!-- dropdown will be populated by javascript on page load -->
  </div>
</div></div>
    
  </div>
  
  <div class="col-lg-9 navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="quickstart.html">
    Get Started
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="user_guide/index.html">
    User Guide
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="api_reference/index.html">
    API Docs
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="auto_examples/index.html">
    Example Notebooks
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="contributor_guide/index.html">
    Contributor Guide
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="#">
    FAQ
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="about/index.html">
    About Us
  </a>
</li>

  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
      
        <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/fairlearn/fairlearn" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://twitter.com/fairlearn" title="Twitter" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-twitter fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Twitter</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://stackoverflow.com/questions/tagged/fairlearn" title="StackOverflow" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-stack-overflow fa-lg" aria-hidden="true"></i>
            <span class="sr-only">StackOverflow</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://discord.gg/R22yCfgsRn" title="Discord" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-discord fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Discord</span></a>
        </li>
</ul></div>
      
    </div>
    
  </div>
  
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="On this page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="quickstart.html">
    Get Started
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="user_guide/index.html">
    User Guide
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="api_reference/index.html">
    API Docs
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="auto_examples/index.html">
    Example Notebooks
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="contributor_guide/index.html">
    Contributor Guide
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="#">
    FAQ
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="about/index.html">
    About Us
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/fairlearn/fairlearn" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://twitter.com/fairlearn" title="Twitter" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-twitter fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Twitter</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://stackoverflow.com/questions/tagged/fairlearn" title="StackOverflow" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-stack-overflow fa-lg" aria-hidden="true"></i>
            <span class="sr-only">StackOverflow</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://discord.gg/R22yCfgsRn" title="Discord" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-discord fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Discord</span></a>
        </li>
</ul></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
        <div class="sidebar-primary-item">
<nav class="bd-docs-nav bd-links"
     aria-label="Section Navigation">
  <p class="bd-links__title" role="heading" aria-level="1">Section Navigation</p>
  <div class="bd-toc-item navbar-nav"></div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">

<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    <li class="breadcrumb-item active" aria-current="page"><span class="ellipsis">Frequently asked questions</span></li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="frequently-asked-questions">
<span id="faq"></span><h1>Frequently asked questions<a class="headerlink" href="#frequently-asked-questions" title="Link to this heading">#</a></h1>
<dl>
<dt>Where can I learn more about fairness in machine learning?</dt><dd><p>Please review <a class="reference internal" href="user_guide/further_resources.html#further-resources"><span class="std std-ref">further resources</span></a>,
where we provide links to various materials that we have found helpful.
Also, in our <a class="reference internal" href="user_guide/index.html#user-guide"><span class="std std-ref">user guide</span></a>, we link to the papers describing
the algorithms implemented in Fairlearn.</p>
</dd>
<dt>Why not just ignore the sensitive features?</dt><dd><p>If your goal is to train a model whose predictions are statistically
independent of the sensitive features, then it is not enough to simply
ignore the sensitive features.
Information is often redundantly encoded across several features, and
machine learning algorithms <em>will</em> uncover these links (it is what they
are designed to do).
For example, in the US, the ZIP code where a person lives is well
correlated with their race.
Even if the model is not provided with race as a feature, the model will
pick up on it implicitly via the ZIP code (and other features).
Worse, without having the race available in the dataset, it is hard to
assess the  model’s impact across different groups defined by race or by
race intersected with other demographic features.</p>
</dd>
<dt>The model is unfair because the data are biased. Isn’t it better to get better data?</dt><dd><p>The answer to this question depends on what is meant by ‘unfair’,
‘biased data’, and ‘better data’ in any particular context.
Consider the example of a company seeking to build a tool for screening
the resumes of job candidates.
The company is planning to use their internal job evaluation data and
train a model to predict job evaluations of the applicants; those with
higher predictions will be ranked higher by the screening tool.
This setup might present several fairness issues:</p>
<ul class="simple">
<li><p>If the company has historically hired few women, there will be fewer of
them in the training data set, and so a trained model may be less
accurate for them.</p></li>
<li><p>The choice of features also affects the accuracy of the model.
The features that are predictive for one group of applicants might not
be as predictive for another group, and so more data will not
necessarily improve the accuracy.</p></li>
<li><p>The accuracy of a model might not mean that the model is fair.
If women have received systematically poorer reviews due to biased
managers or worse workplace conditions, then the model might appear to
be accurate, but the choice of the label (in this case, job evaluation)
does not accurately reflect the applicants’ potential.</p></li>
</ul>
<p>These are just three ways how the data may be ‘biased’, and they are not
mutually exclusive. The processes for getting ‘better data’ will be
different for each. In some of these cases, obtaining ‘better data’ may
not be practical, but it might still be possible to use some mitigation
algorithms.</p>
</dd>
<dt>Why am I seeing fairness issues, even though my data are reflective of the general population?</dt><dd><p>Machine learning models often perform poorly for subgroups which are
poorly  represented.
What constitutes poor representation is context specific, and may well be
affected by historical misrepresentation (consider the example above, of a
company which had previously hired few women).
For this reason, balanced sampling is generally better for ML than
population sampling.
On a related point, this is why it is important to consider multiple
fairness metrics, and how they vary across different subgroups.</p>
</dd>
<dt>Won’t making a model fairer reduce its accuracy?</dt><dd><p>There are often many machine learning models that achieve similar levels
of accuracy or other performance metrics, but that dramatically differ in
how they affect different subgroups.
Mitigation algorithms seek to improve the fairness metrics without
strongly affecting the accuracy, or more generally to navigate the
trade-offs between performance and fairness metrics.</p>
</dd>
<dt>Can the mitigation algorithms in Fairlearn make my model fair?</dt><dd><p>There are many ways in which a model can be unfair. Fairlearn mitigation
algorithms only address some of them: those that can be quantified by our
supported fairness metrics.
However, to assess whether the new model is fairer, it is important to
consider not only the fairness metrics, but also the societal and
technical context in which the model is applied.</p>
</dd>
<dt>I’ve got improved data, trained and mitigated new models, checked all the metrics… am I done?</dt><dd><p>Firstly, always remember that there is more to fairness than technical
details such as metrics - fairness is a <em>sociotechnical</em> problem.
Even if these are all considered at training time, the ML lifecycle
doesn’t end when a model is deployed.
Models need to be monitored in production.
On a technical level, this means checking for data drift within the
vulnerable subgroups identified during the fairness analysis.
However the societal aspects need to be considered as well, for example:</p>
<ul class="simple">
<li><p>Are the actual harms as expected, both in the nature of the harms and
their distribution?</p></li>
<li><p>Have the users of the model (who may not be the subjects of the model)
adjusted their usage patterns? This is sometimes called ‘strategic
behavior.’</p></li>
</ul>
</dd>
<dt>What sort of fairness-related harms can the Fairlearn library address?</dt><dd><p>We currently focus on two kinds of harms:</p>
<ul class="simple">
<li><p><em>Allocation harms.</em>
These harms can occur when AI systems extend or withhold opportunities,
resources, or information. Some of the key applications are in hiring,
school admissions, and lending.</p></li>
<li><p><em>Quality-of-service harms.</em> Quality of service refers to whether a
system works as well for one person as it does for another, even if no
opportunities, resources, or information are extended or withheld.</p></li>
</ul>
</dd>
<dt>Can the Fairlearn library be used to detect bias in datasets?</dt><dd><p>We do not have concrete plans for this at the present time.</p>
</dd>
<dt>Can the Fairlearn library recommend ways to make my model fairer?</dt><dd><p>Right now we do not have an automated tool that would help you decide
which mitigation algorithm to use. Our focus is on expanding the
documentation and examples to highlight when each of the algorithms might
be more applicable.
Note that model training is just one step in the AI development and
deployment lifecycle, and other steps, such as data gathering and
curation, or monitoring and debugging of the deployed system, may be
better places of intervention to improve the fairness of an AI system.</p>
</dd>
<dt>What unfairness mitigation techniques does Fairlearn support?</dt><dd><p>Please see our <a class="reference internal" href="user_guide/mitigation/index.html#mitigation"><span class="std std-ref">Mitigations</span></a> section.</p>
</dd>
<dt>Which ML libraries does Fairlearn support?</dt><dd><p>We have generally followed conventions of <cite>scikit-learn</cite>.
However, our mitigation algorithms can be used to augment
any ML algorithms that provide (or can be wrapped to provide) <cite>fit()</cite> and
<cite>predict()</cite> methods. Also, any classification or regression
algorithm can be evaluated using our metrics.</p>
</dd>
<dt>Does Fairlearn support multiclass classification?</dt><dd><p>On the assessment side, Fairlearn’s <a class="reference internal" href="api_reference/generated/fairlearn.metrics.MetricFrame.html#fairlearn.metrics.MetricFrame" title="fairlearn.metrics.MetricFrame"><code class="xref py py-class docutils literal notranslate"><span class="pre">metrics.MetricFrame</span></code></a>
can be used with any metrics for supervised learning, including those for
multiclass classification.
For example, it is possible to pass
<a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score" title="(in scikit-learn v1.6)"><code class="xref py py-func docutils literal notranslate"><span class="pre">sklearn.metrics.accuracy_score()</span></code></a> or
<a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html#sklearn.metrics.confusion_matrix" title="(in scikit-learn v1.6)"><code class="xref py py-func docutils literal notranslate"><span class="pre">sklearn.metrics.confusion_matrix()</span></code></a> as the metric functions, and
supply multiclass data for <code class="code docutils literal notranslate"><span class="pre">y_true</span></code> and <code class="code docutils literal notranslate"><span class="pre">y_pred</span></code>.
We give an example with multiclass data in the <a class="reference internal" href="user_guide/assessment/index.html#assessment"><span class="std std-ref">user guide</span></a>.
There are
<a class="reference external" href="https://github.com/fairlearn/fairlearn/issues/752">ongoing discussions within the community</a>
to add more extensive support to Fairlearn’s assessment capabilities.
If you have thoughts feel free to add them to the discussion.</p>
<p>On the mitigation side, our algorithms
<a class="reference internal" href="api_reference/generated/fairlearn.reductions.ExponentiatedGradient.html#fairlearn.reductions.ExponentiatedGradient" title="fairlearn.reductions.ExponentiatedGradient"><code class="xref py py-class docutils literal notranslate"><span class="pre">reductions.ExponentiatedGradient</span></code></a> and
<a class="reference internal" href="api_reference/generated/fairlearn.reductions.GridSearch.html#fairlearn.reductions.GridSearch" title="fairlearn.reductions.GridSearch"><code class="xref py py-class docutils literal notranslate"><span class="pre">reductions.GridSearch</span></code></a>
support <a class="reference internal" href="user_guide/mitigation/reductions.html#bounded-group-loss"><span class="std std-ref">bounded group loss</span></a> constraints, which
are applicable to any supervised learning setting, including multiclass
classification.</p>
</dd>
<dt>Does Fairlearn support multiple and non-binary sensitive features?</dt><dd><p>Fairlearn’s assessment capabilities support sensitive features with more
than two values as well as multiple sensitive features.
Our <a class="reference internal" href="user_guide/assessment/index.html#assessment"><span class="std std-ref">user guide</span></a> has examples for both of
these cases.
The mitigation techniques all support mitigation with non-binary and
multiple sensitive features as well. For a full list of techniques
please refer to the <a class="reference internal" href="user_guide/mitigation/index.html#mitigation"><span class="std std-ref">user guide section on mitigation</span></a>.</p>
</dd>
<dt>Does Fairlearn work for image and text data?</dt><dd><p>We have not (yet) looked at using Fairlearn on image or text data.
However, so long as the image or text classifier provide
<code class="code docutils literal notranslate"><span class="pre">fit()</span></code> and <code class="code docutils literal notranslate"><span class="pre">predict()</span></code> methods
as required by Fairlearn, it should be possible to use them
with Fairlearn mitigation algorithms. Also, any classification or
regression algorithm can be evaluated using our metrics (regardless of the
data it is operating on).</p>
</dd>
<dt>Is Fairlearn available in languages other than Python?</dt><dd><p>For the moment, we only support Python &gt;= 3.8</p>
</dd>
<dt>Can I contribute to Fairlearn?</dt><dd><p>Absolutely! Please see our <a class="reference internal" href="contributor_guide/index.html#contributor-guide"><span class="std std-ref">contributor guide</span></a> to
see how. We welcome all contributions!</p>
</dd>
<dt>What is the relationship between Fairlearn and Microsoft?</dt><dd><p>Fairlearn has grown from a project at Microsoft Research in New York City.</p>
</dd>
<dt>What happened to the <code class="code docutils literal notranslate"><span class="pre">FairlearnDashboard</span></code>?</dt><dd><p>The Fairlearn dashboard was a Jupyter notebook widget for assessing how a
model’s predictions impact different groups as defined by sensitive features, and
also for comparing multiple models in terms of various fairness and performance
metrics.</p>
<p>The <code class="code docutils literal notranslate"><span class="pre">FairlearnDashboard</span></code> is no longer being developed as
part of Fairlearn. Instead, it has found a new home at Microsoft with the name
<code class="code docutils literal notranslate"><span class="pre">FairnessDashboard</span></code>. For more information on how to use it refer to
<a class="github reference external" href="https://github.com/microsoft/responsible-ai-toolbox">microsoft/responsible-ai-toolbox</a>.
Fairlearn provides some of the existing functionality through
<code class="code docutils literal notranslate"><span class="pre">matplotlib</span></code>-based visualizations. Refer to the <a class="reference internal" href="user_guide/assessment/plotting.html#plot-metricframe"><span class="std std-ref">Plotting</span></a> section.</p>
</dd>
</dl>
</section>


                </article>
              
              
              
              
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item"><div class="edit-example-link">
    
</div></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      © Copyright 2018 - 2025, Fairlearn contributors.
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">

  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 7.2.6.
    <br/>
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  <!-- # L10n: Setting the PST URL as an argument as this does not need to be localized -->
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.16.1.
</p></div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>