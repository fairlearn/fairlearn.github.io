
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/plot_grid_search_census.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_examples_plot_grid_search_census.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_plot_grid_search_census.py:


===========================
GridSearch with Census Data
===========================

.. GENERATED FROM PYTHON SOURCE LINES 11-26

Census dataset. This dataset is a classification problem - given a range of
data about 32,000 individuals, predict whether their annual income is above
or below fifty thousand dollars per year.

For the purposes of this notebook, we shall treat this as a loan decision
problem. We will pretend that the label indicates whether or not each
individual repaid a loan in the past. We will use the data to train a
predictor to predict whether previously unseen individuals will repay a loan
or not. The assumption is that the model predictions are used to decide
whether an individual should be offered a loan.

We will first train a fairness-unaware predictor and show that it leads to unfair
decisions under a specific notion of fairness called *demographic parity*.
We then mitigate unfairness by applying the :code:`GridSearch` algorithm from the
Fairlearn package.

.. GENERATED FROM PYTHON SOURCE LINES 28-34

Load and preprocess the data set
--------------------------------
We download the data set using `fetch_adult` function in
`fairlearn.datasets`. We start by importing the various modules we're going
to use:


.. GENERATED FROM PYTHON SOURCE LINES 34-51

.. code-block:: default


    import pandas as pd
    from sklearn import metrics as skm
    from sklearn.linear_model import LogisticRegression
    from sklearn.model_selection import train_test_split
    from sklearn.preprocessing import LabelEncoder, StandardScaler

    from fairlearn.datasets import fetch_adult
    from fairlearn.reductions import DemographicParity, ErrorRate, GridSearch
    from fairlearn.metrics import (
        MetricFrame,
        selection_rate,
        count,
        plot_model_comparison,
        selection_rate_difference,
    )








.. GENERATED FROM PYTHON SOURCE LINES 52-53

We can now load and inspect the data by using the `fairlearn.datasets` module:

.. GENERATED FROM PYTHON SOURCE LINES 53-59

.. code-block:: default


    data = fetch_adult()
    X_raw = data.data
    Y = (data.target == ">50K") * 1
    X_raw






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <div>
    <style scoped>
        .dataframe tbody tr th:only-of-type {
            vertical-align: middle;
        }

        .dataframe tbody tr th {
            vertical-align: top;
        }

        .dataframe thead th {
            text-align: right;
        }
    </style>
    <table border="1" class="dataframe">
      <thead>
        <tr style="text-align: right;">
          <th></th>
          <th>age</th>
          <th>workclass</th>
          <th>fnlwgt</th>
          <th>education</th>
          <th>education-num</th>
          <th>marital-status</th>
          <th>occupation</th>
          <th>relationship</th>
          <th>race</th>
          <th>sex</th>
          <th>capital-gain</th>
          <th>capital-loss</th>
          <th>hours-per-week</th>
          <th>native-country</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th>0</th>
          <td>25.0</td>
          <td>Private</td>
          <td>226802.0</td>
          <td>11th</td>
          <td>7.0</td>
          <td>Never-married</td>
          <td>Machine-op-inspct</td>
          <td>Own-child</td>
          <td>Black</td>
          <td>Male</td>
          <td>0.0</td>
          <td>0.0</td>
          <td>40.0</td>
          <td>United-States</td>
        </tr>
        <tr>
          <th>1</th>
          <td>38.0</td>
          <td>Private</td>
          <td>89814.0</td>
          <td>HS-grad</td>
          <td>9.0</td>
          <td>Married-civ-spouse</td>
          <td>Farming-fishing</td>
          <td>Husband</td>
          <td>White</td>
          <td>Male</td>
          <td>0.0</td>
          <td>0.0</td>
          <td>50.0</td>
          <td>United-States</td>
        </tr>
        <tr>
          <th>2</th>
          <td>28.0</td>
          <td>Local-gov</td>
          <td>336951.0</td>
          <td>Assoc-acdm</td>
          <td>12.0</td>
          <td>Married-civ-spouse</td>
          <td>Protective-serv</td>
          <td>Husband</td>
          <td>White</td>
          <td>Male</td>
          <td>0.0</td>
          <td>0.0</td>
          <td>40.0</td>
          <td>United-States</td>
        </tr>
        <tr>
          <th>3</th>
          <td>44.0</td>
          <td>Private</td>
          <td>160323.0</td>
          <td>Some-college</td>
          <td>10.0</td>
          <td>Married-civ-spouse</td>
          <td>Machine-op-inspct</td>
          <td>Husband</td>
          <td>Black</td>
          <td>Male</td>
          <td>7688.0</td>
          <td>0.0</td>
          <td>40.0</td>
          <td>United-States</td>
        </tr>
        <tr>
          <th>4</th>
          <td>18.0</td>
          <td>NaN</td>
          <td>103497.0</td>
          <td>Some-college</td>
          <td>10.0</td>
          <td>Never-married</td>
          <td>NaN</td>
          <td>Own-child</td>
          <td>White</td>
          <td>Female</td>
          <td>0.0</td>
          <td>0.0</td>
          <td>30.0</td>
          <td>United-States</td>
        </tr>
        <tr>
          <th>...</th>
          <td>...</td>
          <td>...</td>
          <td>...</td>
          <td>...</td>
          <td>...</td>
          <td>...</td>
          <td>...</td>
          <td>...</td>
          <td>...</td>
          <td>...</td>
          <td>...</td>
          <td>...</td>
          <td>...</td>
          <td>...</td>
        </tr>
        <tr>
          <th>48837</th>
          <td>27.0</td>
          <td>Private</td>
          <td>257302.0</td>
          <td>Assoc-acdm</td>
          <td>12.0</td>
          <td>Married-civ-spouse</td>
          <td>Tech-support</td>
          <td>Wife</td>
          <td>White</td>
          <td>Female</td>
          <td>0.0</td>
          <td>0.0</td>
          <td>38.0</td>
          <td>United-States</td>
        </tr>
        <tr>
          <th>48838</th>
          <td>40.0</td>
          <td>Private</td>
          <td>154374.0</td>
          <td>HS-grad</td>
          <td>9.0</td>
          <td>Married-civ-spouse</td>
          <td>Machine-op-inspct</td>
          <td>Husband</td>
          <td>White</td>
          <td>Male</td>
          <td>0.0</td>
          <td>0.0</td>
          <td>40.0</td>
          <td>United-States</td>
        </tr>
        <tr>
          <th>48839</th>
          <td>58.0</td>
          <td>Private</td>
          <td>151910.0</td>
          <td>HS-grad</td>
          <td>9.0</td>
          <td>Widowed</td>
          <td>Adm-clerical</td>
          <td>Unmarried</td>
          <td>White</td>
          <td>Female</td>
          <td>0.0</td>
          <td>0.0</td>
          <td>40.0</td>
          <td>United-States</td>
        </tr>
        <tr>
          <th>48840</th>
          <td>22.0</td>
          <td>Private</td>
          <td>201490.0</td>
          <td>HS-grad</td>
          <td>9.0</td>
          <td>Never-married</td>
          <td>Adm-clerical</td>
          <td>Own-child</td>
          <td>White</td>
          <td>Male</td>
          <td>0.0</td>
          <td>0.0</td>
          <td>20.0</td>
          <td>United-States</td>
        </tr>
        <tr>
          <th>48841</th>
          <td>52.0</td>
          <td>Self-emp-inc</td>
          <td>287927.0</td>
          <td>HS-grad</td>
          <td>9.0</td>
          <td>Married-civ-spouse</td>
          <td>Exec-managerial</td>
          <td>Wife</td>
          <td>White</td>
          <td>Female</td>
          <td>15024.0</td>
          <td>0.0</td>
          <td>40.0</td>
          <td>United-States</td>
        </tr>
      </tbody>
    </table>
    <p>48842 rows Ã— 14 columns</p>
    </div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 60-65

We are going to treat the sex of each individual as a sensitive feature
(where 0 indicates female and 1 indicates male), and in this particular case
we are going separate this feature out and drop it from the main data. We
then perform some standard data preprocessing steps to convert the data into
a format suitable for the ML algorithms

.. GENERATED FROM PYTHON SOURCE LINES 65-77

.. code-block:: default


    A = X_raw["sex"]
    X = X_raw.drop(labels=["sex"], axis=1)
    X = pd.get_dummies(X)

    sc = StandardScaler()
    X_scaled = sc.fit_transform(X)
    X_scaled = pd.DataFrame(X_scaled, columns=X.columns)

    le = LabelEncoder()
    Y = le.fit_transform(Y)








.. GENERATED FROM PYTHON SOURCE LINES 78-79

Finally, we split the data into training and test sets:

.. GENERATED FROM PYTHON SOURCE LINES 79-90

.. code-block:: default


    X_train, X_test, Y_train, Y_test, A_train, A_test = train_test_split(
        X_scaled, Y, A, test_size=0.4, random_state=0, stratify=Y
    )

    # Work around indexing bug
    X_train = X_train.reset_index(drop=True)
    A_train = A_train.reset_index(drop=True)
    X_test = X_test.reset_index(drop=True)
    A_test = A_test.reset_index(drop=True)








.. GENERATED FROM PYTHON SOURCE LINES 91-96

Training a fairness-unaware predictor
-------------------------------------
To show the effect of Fairlearn we will first train a standard ML predictor
that does not incorporate fairness. For speed of demonstration, we use the
simple :class:`sklearn.linear_model.LogisticRegression` class:

.. GENERATED FROM PYTHON SOURCE LINES 96-101

.. code-block:: default


    unmitigated_predictor = LogisticRegression(solver="liblinear", fit_intercept=True)

    unmitigated_predictor.fit(X_train, Y_train)






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: "â–¸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "â–¾";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-1" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>LogisticRegression(solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-1" type="checkbox" checked><label for="sk-estimator-id-1" class="sk-toggleable__label sk-toggleable__label-arrow">LogisticRegression</label><div class="sk-toggleable__content"><pre>LogisticRegression(solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 102-103

We can start to assess the predictor's fairness using the `MetricFrame`:

.. GENERATED FROM PYTHON SOURCE LINES 103-123

.. code-block:: default

    metric_frame = MetricFrame(
        metrics={
            "accuracy": skm.accuracy_score,
            "selection_rate": selection_rate,
            "count": count,
        },
        sensitive_features=A_test,
        y_true=Y_test,
        y_pred=unmitigated_predictor.predict(X_test),
    )
    print(metric_frame.overall)
    print(metric_frame.by_group)
    metric_frame.by_group.plot.bar(
        subplots=True,
        layout=[3, 1],
        legend=False,
        figsize=[12, 8],
        title="Accuracy and selection rate by group",
    )




.. image-sg:: /auto_examples/images/sphx_glr_plot_grid_search_census_001.png
   :alt: Accuracy and selection rate by group, accuracy, selection_rate, count
   :srcset: /auto_examples/images/sphx_glr_plot_grid_search_census_001.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    accuracy              0.851820
    selection_rate        0.194707
    count             19537.000000
    dtype: float64
            accuracy  ...    count
    sex               ...         
    Female  0.925960  ...   6537.0
    Male    0.814538  ...  13000.0

    [2 rows x 3 columns]

    array([[<Axes: title={'center': 'accuracy'}, xlabel='sex'>],
           [<Axes: title={'center': 'selection_rate'}, xlabel='sex'>],
           [<Axes: title={'center': 'count'}, xlabel='sex'>]], dtype=object)



.. GENERATED FROM PYTHON SOURCE LINES 124-133

Looking at the disparity in accuracy, we see that males have an error about
three times greater than the females. More interesting is the disparity in
opportunity - males are offered loans at three times the rate of females.

Despite the fact that we removed the feature from the training data, our
predictor still discriminates based on sex. This demonstrates that simply
ignoring a sensitive feature when fitting a predictor rarely eliminates
unfairness. There will generally be enough other features correlated with the
removed feature to lead to disparate impact.

.. GENERATED FROM PYTHON SOURCE LINES 136-151

Mitigation with GridSearch
--------------------------

The :class:`fairlearn.reductions.GridSearch` class implements a simplified
version of the exponentiated gradient reduction of `Agarwal et al. 2018
<https://arxiv.org/abs/1803.02453>`_. The user supplies a standard ML
estimator, which is treated as a blackbox. `GridSearch` works by generating a
sequence of relabellings and reweightings, and trains a predictor for each.

For this example, we specify demographic parity (on the sensitive feature of
sex) as the fairness metric. Demographic parity requires that individuals are
offered the opportunity (are approved for a loan in this example) independent
of membership in the sensitive class (i.e., females and males should be
offered loans at the same rate). We are using this metric for the sake of
simplicity; in general, the appropriate fairness metric will not be obvious.

.. GENERATED FROM PYTHON SOURCE LINES 151-158

.. code-block:: default


    sweep = GridSearch(
        LogisticRegression(solver="liblinear", fit_intercept=True),
        constraints=DemographicParity(),
        grid_size=31,
    )








.. GENERATED FROM PYTHON SOURCE LINES 159-166

Our algorithms provide :code:`fit()` and :code:`predict()` methods, so they
behave in a similar manner to other ML packages in Python. We do however have
to specify two extra arguments to :code:`fit()` - the column of sensitive
feature labels, and also the number of predictors to generate in our sweep.

After :code:`fit()` completes, we extract the full set of predictors from the
:class:`fairlearn.reductions.GridSearch` object.

.. GENERATED FROM PYTHON SOURCE LINES 166-171

.. code-block:: default


    sweep.fit(X_train, Y_train, sensitive_features=A_train)

    predictors = sweep.predictors_








.. GENERATED FROM PYTHON SOURCE LINES 172-180

We could plot performance and fairness metrics of these predictors now.
However, the plot would be somewhat confusing due to the number of models. In
this case, we are going to remove the predictors which are dominated in the
error-disparity space by others from the sweep (note that the disparity will
only be calculated for the sensitive feature; other potentially sensitive
features will not be mitigated). In general, one might not want to do this,
since there may be other considerations beyond the strict optimization of
error and disparity (of the given sensitive feature).

.. GENERATED FROM PYTHON SOURCE LINES 180-207

.. code-block:: default


    errors, disparities = [], []
    for m in predictors:

        def classifier(X):
            return m.predict(X)

        error = ErrorRate()
        error.load_data(X_train, pd.Series(Y_train), sensitive_features=A_train)
        disparity = DemographicParity()
        disparity.load_data(X_train, pd.Series(Y_train), sensitive_features=A_train)

        errors.append(error.gamma(classifier)[0])
        disparities.append(disparity.gamma(classifier).max())

    all_results = pd.DataFrame(
        {"predictor": predictors, "error": errors, "disparity": disparities}
    )

    non_dominated = []
    for row in all_results.itertuples():
        errors_for_lower_or_eq_disparity = all_results["error"][
            all_results["disparity"] <= row.disparity
        ]
        if row.error <= errors_for_lower_or_eq_disparity.min():
            non_dominated.append(row.predictor)








.. GENERATED FROM PYTHON SOURCE LINES 208-209

Finally, we can evaluate the dominant models along with the unmitigated model.

.. GENERATED FROM PYTHON SOURCE LINES 209-241

.. code-block:: default


    predictions = {"unmitigated": unmitigated_predictor.predict(X_test)}
    metric_frames = {"unmitigated": metric_frame}
    for i in range(len(non_dominated)):
        key = "dominant_model_{0}".format(i)
        predictions[key] = non_dominated[i].predict(X_test)

        metric_frames[key] = MetricFrame(
            metrics={
                "accuracy": skm.accuracy_score,
                "selection_rate": selection_rate,
                "count": count,
            },
            sensitive_features=A_test,
            y_true=Y_test,
            y_pred=predictions[key],
        )

    import matplotlib.pyplot as plt

    x = [metric_frame.overall["accuracy"] for metric_frame in metric_frames.values()]
    y = [
        metric_frame.difference()["selection_rate"]
        for metric_frame in metric_frames.values()
    ]
    keys = list(metric_frames.keys())
    plt.scatter(x, y)
    for i in range(len(x)):
        plt.annotate(keys[i], (x[i] + 0.0003, y[i]))
    plt.xlabel("accuracy")
    plt.ylabel("selection rate difference")




.. image-sg:: /auto_examples/images/sphx_glr_plot_grid_search_census_002.png
   :alt: plot grid search census
   :srcset: /auto_examples/images/sphx_glr_plot_grid_search_census_002.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    Text(25.222222222222214, 0.5, 'selection rate difference')



.. GENERATED FROM PYTHON SOURCE LINES 242-258

We see a Pareto front forming - the set of predictors which represent optimal
tradeoffs between accuracy and disparity in predictions. In the ideal case,
we would have a predictor at (1,0) - perfectly accurate and without any
unfairness under demographic parity (with respect to the sensitive feature
"sex"). The Pareto front represents the closest we can come to this ideal
based on our data and choice of estimator. Note the range of the axes - the
disparity axis covers more values than the accuracy, so we can reduce
disparity substantially for a small loss in accuracy.

In a real example, we would pick the model which represented the best trade-off
between accuracy and disparity given the relevant business constraints.

%% [markdown]
Comparing models easily
-----------------------
Fairlearn also provides functionality to compare models much more easily.

.. GENERATED FROM PYTHON SOURCE LINES 260-272

.. code-block:: default


    # Plot model comparison
    plot_model_comparison(
        x_axis_metric=skm.accuracy_score,
        y_axis_metric=selection_rate_difference,
        y_true=Y_test,
        y_preds=predictions,
        sensitive_features=A_test,
        point_labels=True,
        show_plot=True,
    )
    # End model comparison



.. image-sg:: /auto_examples/images/sphx_glr_plot_grid_search_census_003.png
   :alt: plot grid search census
   :srcset: /auto_examples/images/sphx_glr_plot_grid_search_census_003.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    No matplotlib.Axes object was provided to draw on, so we create a new one

    <Axes: xlabel='accuracy score', ylabel='selection rate difference'>




.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 1 minutes  22.594 seconds)


.. _sphx_glr_download_auto_examples_plot_grid_search_census.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example




    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_grid_search_census.py <plot_grid_search_census.py>`

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_grid_search_census.ipynb <plot_grid_search_census.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
