
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/plot_mitigation_pipeline.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_examples_plot_mitigation_pipeline.py>`
        to download the full example code. or to run this example in your browser via JupyterLite

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_plot_mitigation_pipeline.py:


==========================================
Passing pipelines to mitigation techniques
==========================================

.. GENERATED FROM PYTHON SOURCE LINES 10-16

This notebook shows how to pass :class:`sklearn.pipeline.Pipeline` to
mitigation techniques from Fairlearn. Note that the notebook is not to be
used as an example for how to assess and mitigate fairness. It is merely a
demonstration of the technical aspects of passing
:class:`sklearn.pipeline.Pipeline`. For more information around proper
fairness assessment and mitigation please refer to the :ref:`user_guide`.

.. GENERATED FROM PYTHON SOURCE LINES 16-31

.. code-block:: Python


    import json

    from sklearn.compose import ColumnTransformer
    from sklearn.compose import make_column_selector as selector
    from sklearn.impute import SimpleImputer
    from sklearn.linear_model import LogisticRegression
    from sklearn.model_selection import train_test_split
    from sklearn.pipeline import Pipeline
    from sklearn.preprocessing import OneHotEncoder, StandardScaler

    from fairlearn.datasets import fetch_adult
    from fairlearn.postprocessing import ThresholdOptimizer, plot_threshold_optimizer
    from fairlearn.reductions import DemographicParity, ExponentiatedGradient








.. GENERATED FROM PYTHON SOURCE LINES 32-34

Below we load the "Adult" census dataset and split its features, sensitive
features, and labels into train and test sets.

.. GENERATED FROM PYTHON SOURCE LINES 34-51

.. code-block:: Python


    data = fetch_adult()
    X_raw = data.data
    y = (data.target == ">50K") * 1
    A = X_raw["sex"]

    (X_train, X_test, y_train, y_test, A_train, A_test) = train_test_split(
        X_raw, y, A, test_size=0.3, random_state=12345, stratify=y
    )

    X_train = X_train.reset_index(drop=True)
    X_test = X_test.reset_index(drop=True)
    y_train = y_train.reset_index(drop=True)
    y_test = y_test.reset_index(drop=True)
    A_train = A_train.reset_index(drop=True)
    A_test = A_test.reset_index(drop=True)








.. GENERATED FROM PYTHON SOURCE LINES 52-57

To illustrate Fairlearn's compatibility with
:class:`~sklearn.pipeline.Pipeline` we first need to build our pipeline.
In the following we assemble a pipeline by combining preprocessing steps
with an estimator. The preprocessing steps include imputing, scaling for
numerical features and one-hot encoding for categorical features.

.. GENERATED FROM PYTHON SOURCE LINES 57-87

.. code-block:: Python


    numeric_transformer = Pipeline(
        steps=[
            ("impute", SimpleImputer()),
            ("scaler", StandardScaler()),
        ]
    )
    categorical_transformer = Pipeline(
        [
            ("impute", SimpleImputer(strategy="most_frequent")),
            ("ohe", OneHotEncoder(handle_unknown="ignore")),
        ]
    )
    preprocessor = ColumnTransformer(
        transformers=[
            ("num", numeric_transformer, selector(dtype_exclude="category")),
            ("cat", categorical_transformer, selector(dtype_include="category")),
        ]
    )

    pipeline = Pipeline(
        steps=[
            ("preprocessor", preprocessor),
            (
                "classifier",
                LogisticRegression(solver="liblinear", fit_intercept=True),
            ),
        ]
    )








.. GENERATED FROM PYTHON SOURCE LINES 88-90

Below we will pass the pipeline to some of our mitigation techniques,
starting with :class:`fairlearn.postprocessing.ThresholdOptimizer`:

.. GENERATED FROM PYTHON SOURCE LINES 90-108

.. code-block:: Python


    threshold_optimizer = ThresholdOptimizer(
        estimator=pipeline,
        constraints="demographic_parity",
        predict_method="predict_proba",
        prefit=False,
    )
    threshold_optimizer.fit(X_train, y_train, sensitive_features=A_train)
    print(threshold_optimizer.predict(X_test, sensitive_features=A_test))
    print(
        json.dumps(
            threshold_optimizer.interpolated_thresholder_.interpolation_dict,
            default=str,
            indent=4,
        )
    )
    plot_threshold_optimizer(threshold_optimizer)




.. image-sg:: /auto_examples/images/sphx_glr_plot_mitigation_pipeline_001.png
   :alt: plot mitigation pipeline
   :srcset: /auto_examples/images/sphx_glr_plot_mitigation_pipeline_001.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    [0 0 1 ... 0 0 1]
    {
        "Female": {
            "p0": 0.8004605263157903,
            "operation0": "[>0.20325171890519633]",
            "p1": 0.19953947368420966,
            "operation1": "[>0.1873222488873632]"
        },
        "Male": {
            "p0": 0.08521658986175128,
            "operation0": "[>0.6820821878663272]",
            "p1": 0.9147834101382487,
            "operation1": "[>0.665722231006347]"
        }
    }




.. GENERATED FROM PYTHON SOURCE LINES 109-114

Similarly, :class:`fairlearn.reductions.ExponentiatedGradient` works with
pipelines. Since it requires the :code:`sample_weight` parameter of the
underlying estimator internally we need to provide it with the correct
way of passing :code:`sample_weight` to just the :code:`"classifier"` step
using the step name followed by two underscores and :code:`sample_weight`.

.. GENERATED FROM PYTHON SOURCE LINES 114-122

.. code-block:: Python


    exponentiated_gradient = ExponentiatedGradient(
        estimator=pipeline,
        constraints=DemographicParity(),
        sample_weight_name="classifier__sample_weight",
    )
    exponentiated_gradient.fit(X_train, y_train, sensitive_features=A_train)
    print(exponentiated_gradient.predict(X_test))




.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    [0 0 1 ... 0 0 1]





.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 13.091 seconds)


.. _sphx_glr_download_auto_examples_plot_mitigation_pipeline.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: lite-badge

      .. image:: images/jupyterlite_badge_logo.svg
        :target: ../lite/lab/index.html?path=auto_examples/plot_mitigation_pipeline.ipynb
        :alt: Launch JupyterLite
        :width: 150 px

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_mitigation_pipeline.ipynb <plot_mitigation_pipeline.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_mitigation_pipeline.py <plot_mitigation_pipeline.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: plot_mitigation_pipeline.zip <plot_mitigation_pipeline.zip>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
