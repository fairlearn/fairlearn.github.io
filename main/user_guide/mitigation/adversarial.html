

<!DOCTYPE html>


<html >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Adversarial Mitigation &#8212; Fairlearn 0.10.0.dev0 documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/custom.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script>window.MathJax = {"tex": {"macros": {"E": "{\\mathbb{E}}", "P": "{\\mathbb{P}}", "given": "\\mathbin{\\vert}"}}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'user_guide/mitigation/adversarial';</script>
    <script>
        DOCUMENTATION_OPTIONS.theme_switcher_json_url = 'https://fairlearn.org/main/_static/versions.json';
        DOCUMENTATION_OPTIONS.theme_switcher_version_match = 'main';
        </script>
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Datasets" href="../datasets/index.html" />
    <link rel="prev" title="Reductions" href="reductions.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="None"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
<div class="bd-header__inner bd-page-width">
  <label class="sidebar-toggle primary-toggle" for="__primary">
    <span class="fa-solid fa-bars"></span>
  </label>
  
  <div class="navbar-header-items__start">
    
      <div class="navbar-item">
   

<a class="navbar-brand logo" href="https://fairlearn.org">
  
  
  
  
    
    
      
    
    
    <img src="../../_static/fairlearn_full_color.svg" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="../../_static/fairlearn_full_color.svg" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
    
      <div class="navbar-item">
<script>
document.write(`
  <div class="version-switcher__container dropdown">
    <button type="button" class="version-switcher__button btn btn-sm navbar-btn dropdown-toggle" data-bs-toggle="dropdown">
      main  <!-- this text may get changed later by javascript -->
      <span class="caret"></span>
    </button>
    <div class="version-switcher__menu dropdown-menu list-group-flush py-0">
    <!-- dropdown will be populated by javascript on page load -->
    </div>
  </div>
`);
</script></div>
    
  </div>
  
  
  <div class="col-lg-9 navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item"><nav class="navbar-nav">
  <p class="sidebar-header-items__title"
     role="heading"
     aria-level="1"
     aria-label="Site Navigation">
    Site Navigation
  </p>
  <ul class="bd-navbar-elements navbar-nav">
    
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../quickstart.html">
                        Get Started
                      </a>
                    </li>
                

                    <li class="nav-item current active">
                      <a class="nav-link nav-internal" href="../index.html">
                        User Guide
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../api_reference/index.html">
                        API Docs
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../auto_examples/index.html">
                        Example Notebooks
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../contributor_guide/index.html">
                        Contributor Guide
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../faq.html">
                        FAQ
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../about/index.html">
                        About Us
                      </a>
                    </li>
                
  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
      
        <div class="navbar-item">
<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links navbar-nav"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/fairlearn/fairlearn" title="GitHub" class="nav-link" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><span><i class="fa-brands fa-github"></i></span>
            <label class="sr-only">GitHub</label></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://twitter.com/fairlearn" title="Twitter" class="nav-link" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><span><i class="fa-brands fa-twitter"></i></span>
            <label class="sr-only">Twitter</label></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://stackoverflow.com/questions/tagged/fairlearn" title="StackOverflow" class="nav-link" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><span><i class="fa-brands fa-stack-overflow"></i></span>
            <label class="sr-only">StackOverflow</label></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://discord.gg/R22yCfgsRn" title="Discord" class="nav-link" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><span><i class="fa-brands fa-discord"></i></span>
            <label class="sr-only">Discord</label></a>
        </li>
</ul></div>
      
    </div>
    
  </div>
  
  

  
    <label class="sidebar-toggle secondary-toggle" for="__secondary">
      <span class="fa-solid fa-outdent"></span>
    </label>
  
</div>

    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          <div class="navbar-item"><nav class="navbar-nav">
  <p class="sidebar-header-items__title"
     role="heading"
     aria-level="1"
     aria-label="Site Navigation">
    Site Navigation
  </p>
  <ul class="bd-navbar-elements navbar-nav">
    
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../quickstart.html">
                        Get Started
                      </a>
                    </li>
                

                    <li class="nav-item current active">
                      <a class="nav-link nav-internal" href="../index.html">
                        User Guide
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../api_reference/index.html">
                        API Docs
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../auto_examples/index.html">
                        Example Notebooks
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../contributor_guide/index.html">
                        Contributor Guide
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../faq.html">
                        FAQ
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../about/index.html">
                        About Us
                      </a>
                    </li>
                
  </ul>
</nav></div>
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">
<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links navbar-nav"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/fairlearn/fairlearn" title="GitHub" class="nav-link" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><span><i class="fa-brands fa-github"></i></span>
            <label class="sr-only">GitHub</label></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://twitter.com/fairlearn" title="Twitter" class="nav-link" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><span><i class="fa-brands fa-twitter"></i></span>
            <label class="sr-only">Twitter</label></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://stackoverflow.com/questions/tagged/fairlearn" title="StackOverflow" class="nav-link" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><span><i class="fa-brands fa-stack-overflow"></i></span>
            <label class="sr-only">StackOverflow</label></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://discord.gg/R22yCfgsRn" title="Discord" class="nav-link" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><span><i class="fa-brands fa-discord"></i></span>
            <label class="sr-only">Discord</label></a>
        </li>
</ul></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
        <div class="sidebar-primary-item"><nav class="bd-docs-nav bd-links"
     aria-label="Section Navigation">
  <p class="bd-links__title" role="heading" aria-level="1">Section Navigation</p>
  <div class="bd-toc-item navbar-nav"><ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../fairness_in_machine_learning.html">Fairness in Machine Learning</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../assessment/index.html">Assessment</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../assessment/perform_fairness_assessment.html">Performing a Fairness Assessment</a></li>
<li class="toctree-l2"><a class="reference internal" href="../assessment/common_fairness_metrics.html">Common fairness metrics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../assessment/custom_fairness_metrics.html">Defining custom fairness metrics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../assessment/intersecting_groups.html">Intersecting Groups</a></li>
<li class="toctree-l2"><a class="reference internal" href="../assessment/advanced_metricframe.html">Advanced Usage of MetricFrame</a></li>
<li class="toctree-l2"><a class="reference internal" href="../assessment/plotting.html">Plotting</a></li>
<li class="toctree-l2"><a class="reference internal" href="../assessment/saving_loading_metricframe.html">Saving and loading MetricFrame</a></li>
</ul>
</li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="index.html">Mitigations</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="preprocessing.html">Preprocessing</a></li>
<li class="toctree-l2"><a class="reference internal" href="reductions.html">Reductions</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Adversarial Mitigation</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../datasets/index.html">Datasets</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../datasets/adult_data.html">Adult Census Dataset</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../datasets/acs_income.html">ACSIncome</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../datasets/boston_housing_data.html">Revisiting the Boston Housing Dataset</a></li>

<li class="toctree-l2"><a class="reference internal" href="../datasets/diabetes_hospital_data.html">Diabetes 130-Hospitals Dataset</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../installation_and_version_guide/index.html">Installation and version guide</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../installation_and_version_guide/installation_guide.html">Installation Guide</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../installation_and_version_guide/version_guide.html">Version guide</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../installation_and_version_guide/v0.1.html">v0.1</a></li>
<li class="toctree-l3"><a class="reference internal" href="../installation_and_version_guide/v0.10.0.html">v0.10.0</a></li>
<li class="toctree-l3"><a class="reference internal" href="../installation_and_version_guide/v0.2.0.html">v0.2.0</a></li>
<li class="toctree-l3"><a class="reference internal" href="../installation_and_version_guide/v0.3.0.html">v0.3.0</a></li>
<li class="toctree-l3"><a class="reference internal" href="../installation_and_version_guide/v0.4.0.html">v0.4.0</a></li>
<li class="toctree-l3"><a class="reference internal" href="../installation_and_version_guide/v0.4.1.html">v0.4.1</a></li>
<li class="toctree-l3"><a class="reference internal" href="../installation_and_version_guide/v0.4.2.html">v0.4.2</a></li>
<li class="toctree-l3"><a class="reference internal" href="../installation_and_version_guide/v0.4.3.html">v0.4.3</a></li>
<li class="toctree-l3"><a class="reference internal" href="../installation_and_version_guide/v0.4.4.html">v0.4.4</a></li>
<li class="toctree-l3"><a class="reference internal" href="../installation_and_version_guide/v0.4.5.html">v0.4.5</a></li>
<li class="toctree-l3"><a class="reference internal" href="../installation_and_version_guide/v0.4.6.html">v0.4.6</a></li>
<li class="toctree-l3"><a class="reference internal" href="../installation_and_version_guide/v0.5.0.html">v0.5.0</a></li>
<li class="toctree-l3"><a class="reference internal" href="../installation_and_version_guide/v0.6.0.html">v0.6.0</a></li>
<li class="toctree-l3"><a class="reference internal" href="../installation_and_version_guide/v0.6.1.html">v0.6.1</a></li>
<li class="toctree-l3"><a class="reference internal" href="../installation_and_version_guide/v0.6.2.html">v0.6.2</a></li>
<li class="toctree-l3"><a class="reference internal" href="../installation_and_version_guide/v0.7.0.html">v0.7.0</a></li>
<li class="toctree-l3"><a class="reference internal" href="../installation_and_version_guide/v0.8.0.html">v0.8.0</a></li>
<li class="toctree-l3"><a class="reference internal" href="../installation_and_version_guide/v0.9.0.html">v0.9.0</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../further_resources.html">Further Resources</a></li>
</ul>
</div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">



<nav aria-label="Breadcrumbs">
  <ul class="bd-breadcrumbs" role="navigation" aria-label="Breadcrumb">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="../index.html" class="nav-link">User Guide</a></li>
    
    
    <li class="breadcrumb-item"><a href="index.html" class="nav-link">Mitigations</a></li>
    
    <li class="breadcrumb-item active" aria-current="page">Adversarial Mitigation</li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section id="adversarial-mitigation">
<span id="adversarial"></span><h1>Adversarial Mitigation<a class="headerlink" href="#adversarial-mitigation" title="Permalink to this headline">#</a></h1>
<p>Fairlearn provides an implementation of the adversarial
mitigation method of Zhang <em>et al.</em><a class="footnote-reference brackets" href="#footcite-zhang2018mitigating" id="id1">1</a>.
The input to the method consists of features <span class="math notranslate nohighlight">\(X,\)</span> labels <span class="math notranslate nohighlight">\(Y,\)</span>
and sensitive features <span class="math notranslate nohighlight">\(A\)</span>. The goal is to fit an estimator that
predicts <span class="math notranslate nohighlight">\(Y\)</span> from <span class="math notranslate nohighlight">\(X\)</span> while enforcing fairness constraints with
respect to <span class="math notranslate nohighlight">\(A\)</span>. Both classification and regression
are supported (classes <a class="reference internal" href="../../api_reference/generated/fairlearn.adversarial.AdversarialFairnessClassifier.html#fairlearn.adversarial.AdversarialFairnessClassifier" title="fairlearn.adversarial.AdversarialFairnessClassifier"><code class="xref py py-class docutils literal notranslate"><span class="pre">AdversarialFairnessClassifier</span></code></a> and
<a class="reference internal" href="../../api_reference/generated/fairlearn.adversarial.AdversarialFairnessRegressor.html#fairlearn.adversarial.AdversarialFairnessRegressor" title="fairlearn.adversarial.AdversarialFairnessRegressor"><code class="xref py py-class docutils literal notranslate"><span class="pre">AdversarialFairnessRegressor</span></code></a>) with two types of
fairness constraints: demographic parity and equalized odds.</p>
<p>To train an adversarial mitigation algorithm, the user needs to provide
two neural networks, a predictor network and an adversary network,
with learnable weights <span class="math notranslate nohighlight">\(W\)</span> and <span class="math notranslate nohighlight">\(U,\)</span> respectively. The predictor
network is constructed to solve the underlying supervised learning task,
without considering fairness, by minimizing the predictor loss <span class="math notranslate nohighlight">\(L_P.\)</span>
However, to improve fairness, we do not
only minimize the predictor loss, but we also want to decrease the
adversary’s ability to predict the sensitive features from the predictor’s
predictions (when implementing demographic parity), or jointly from the predictor’s
predictions and true labels (when implementing equalized odds).</p>
<p>Suppose the adversary has the loss term <span class="math notranslate nohighlight">\(L_A.\)</span> The algorithm
updates adversary weights <span class="math notranslate nohighlight">\(U\)</span> by descending along the gradient <span class="math notranslate nohighlight">\(\nabla_U L_A\)</span>.
However, when updating the predictor weights <span class="math notranslate nohighlight">\(W\)</span>, the algorithm uses</p>
<div class="math notranslate nohighlight">
\[\nabla_W L_P - \text{proj}_{\nabla_W L_A} \nabla_W L_P - \alpha \nabla_W L_A.\]</div>
<p>instead of just gradient.
Compared with standard stochastic gradient descent, there are two additional terms
that seek to prevent the decrease of the adversary loss. The hyperparameter
<span class="math notranslate nohighlight">\(\alpha\)</span> specifies the strength of enforcing the fairness constraint.
For details, see Zhang <em>et al.</em><a class="footnote-reference brackets" href="#footcite-zhang2018mitigating" id="id2">1</a>.</p>
<p>In <a class="reference internal" href="#adversarial-models"><span class="std std-ref">Models</span></a>, we discuss the models that this implementation accepts.
In <a class="reference internal" href="#adversarial-data-types"><span class="std std-ref">Data types and loss functions</span></a>, we discuss the input format of <span class="math notranslate nohighlight">\(X,\)</span>
how <span class="math notranslate nohighlight">\(Y\)</span> and <span class="math notranslate nohighlight">\(A\)</span> are preprocessed, and
how the loss functions <span class="math notranslate nohighlight">\(L_P\)</span> and <span class="math notranslate nohighlight">\(L_A\)</span> are chosen.
Finally, in <a class="reference internal" href="#adversarial-training"><span class="std std-ref">Training</span></a> we give some
useful tips to keep in mind when training this model, as
adversarial methods such as these
can be difficult to train.</p>
<section id="models">
<span id="adversarial-models"></span><h2>Models<a class="headerlink" href="#models" title="Permalink to this headline">#</a></h2>
<p>One can implement the predictor and adversarial neural networks as
a <cite>torch.nn.Module</cite> (using PyTorch) or as a <cite>tensorflow.keras.Model</cite> (using TensorFlow).
This implementation has a soft dependency on either PyTorch or TensorFlow, and the user
needs to have installed either one of the two soft dependencies. It is not possible to
mix these dependencies, so a PyTorch predictor with a TensorFlow loss function is not
possible.</p>
<p>It is very important to define the neural network models with no activation function
or discrete prediction function on the final layer. So, for instance, when predicting
a categorical feature that is one-hot-encoded, the neural network should output a
vector of real-valued scores, not the one-hot-encoded discrete prediction:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">predictor_model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">),</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="p">])</span>
<span class="n">adversary_model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">),</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="p">])</span>
<span class="n">mitigator</span> <span class="o">=</span> <span class="n">AdversarialFairnessClassifier</span><span class="p">(</span>
    <span class="n">predictor_model</span><span class="o">=</span><span class="n">predictor_model</span><span class="p">,</span>
    <span class="n">adversary_model</span><span class="o">=</span><span class="n">adversary_model</span>
<span class="p">)</span>
</pre></div>
</div>
<p>For simple or exploratory use cases, Fairlearn provides a very basic neural
network builder.
Instead of a neural network model, it is possible to pass a list
<span class="math notranslate nohighlight">\([k_1, k_2, \dots]\)</span>, where each <span class="math notranslate nohighlight">\(k_i\)</span> either indicates
the number of nodes (if <span class="math notranslate nohighlight">\(k_i\)</span> is an integer) or
an activation function (if <span class="math notranslate nohighlight">\(k_i\)</span> is a string) or
a layer or activation function instance directly (if <span class="math notranslate nohighlight">\(k_i\)</span> is
a callable).
However, the number of nodes in the input
and output layer is automatically inferred from data, and the final
activation function (such as softmax for categorical
predictors) is also inferred from data.
So, in the following example, the predictor model is
a neural network with an input layer of
the appropriate number of nodes, a hidden layer with 50 nodes and
ReLU activations, and an output layer with an appropriate activation function.
The appropriate function in case of classification will be softmax for one
hot encoded <span class="math notranslate nohighlight">\(Y\)</span> and sigmoid for binary <span class="math notranslate nohighlight">\(Y\)</span>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">mitigator</span> <span class="o">=</span> <span class="n">AdversarialFairnessClassifier</span><span class="p">(</span>
    <span class="n">predictor_model</span><span class="o">=</span><span class="p">[</span><span class="mi">50</span><span class="p">,</span> <span class="s2">&quot;relu&quot;</span><span class="p">],</span>
    <span class="n">adversary_model</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="s2">&quot;relu&quot;</span><span class="p">]</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<section id="data-types-and-loss-functions">
<span id="adversarial-data-types"></span><h2>Data types and loss functions<a class="headerlink" href="#data-types-and-loss-functions" title="Permalink to this headline">#</a></h2>
<p>We require the provided data <span class="math notranslate nohighlight">\(X\)</span> to be provided as a matrix
(2d array-like) of floats; this data is directly passed to
neural network models.</p>
<p>Labels <span class="math notranslate nohighlight">\(Y\)</span> and sensitive features <span class="math notranslate nohighlight">\(A\)</span> are automatically
preprocessed based on their type: binary data is represented as 0/1,
categorical data is one-hot encoded, float data is left unchanged.</p>
<p>Zhang <em>et al.</em><a class="footnote-reference brackets" href="#footcite-zhang2018mitigating" id="id3">1</a> do not explicitly define loss functions.
In <a class="reference internal" href="../../api_reference/generated/fairlearn.adversarial.AdversarialFairnessClassifier.html#fairlearn.adversarial.AdversarialFairnessClassifier" title="fairlearn.adversarial.AdversarialFairnessClassifier"><code class="xref py py-class docutils literal notranslate"><span class="pre">AdversarialFairnessClassifier</span></code></a> and <a class="reference internal" href="../../api_reference/generated/fairlearn.adversarial.AdversarialFairnessRegressor.html#fairlearn.adversarial.AdversarialFairnessRegressor" title="fairlearn.adversarial.AdversarialFairnessRegressor"><code class="xref py py-class docutils literal notranslate"><span class="pre">AdversarialFairnessRegressor</span></code></a>,
the loss functions are automatically inferred based on
the data type of the label and sensitive features.
For binary and categorical target variables, the training loss is cross-entropy.
For float targets variables, the training loss is the mean squared error.</p>
<p>To summarize:</p>
<table class="colwidths-given table">
<colgroup>
<col style="width: 16%" />
<col style="width: 11%" />
<col style="width: 16%" />
<col style="width: 16%" />
<col style="width: 26%" />
<col style="width: 16%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>label <span class="math notranslate nohighlight">\(Y\)</span></p></th>
<th class="head"><p>derived label <span class="math notranslate nohighlight">\(Y'\)</span></p></th>
<th class="head"><p>network output <span class="math notranslate nohighlight">\(Z\)</span></p></th>
<th class="head"><p>probabilistic prediction</p></th>
<th class="head"><p>loss function</p></th>
<th class="head"><p>prediction</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>binary</strong></p></td>
<td><p>0/1</p></td>
<td><p><span class="math notranslate nohighlight">\(\mathbb{R}\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\mathbb{P}(Y'=1)\)</span>
<span class="math notranslate nohighlight">\(\;\;=1/(1+e^{-Z})\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(-Y'\log\mathbb{P}(Y'=1)\)</span>
<span class="math notranslate nohighlight">\(\;\;-(1-Y')\log\mathbb{P}(Y'=0)\)</span></p></td>
<td><p>1 if <span class="math notranslate nohighlight">\(Z\ge 0\)</span>, else 0</p></td>
</tr>
<tr class="row-odd"><td><p><strong>categorical</strong>
(<span class="math notranslate nohighlight">\(k\)</span> values)</p></td>
<td><p>one-hot encoding</p></td>
<td><p><span class="math notranslate nohighlight">\(\mathbb{R}^k\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\mathbb{P}(Y'=\mathbf{e}_j)\)</span>
<span class="math notranslate nohighlight">\(\;\;=e^{Z_j}/\sum_{\ell=1}^k e^{Z_{\ell}}\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(-\sum_{j=1}^k Y'_j\log\mathbb{P}(Y'=\mathbf{e}_j)\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\text{argmax}_j\,Z_j\)</span></p></td>
</tr>
<tr class="row-even"><td><p><strong>continuous</strong>
(in <span class="math notranslate nohighlight">\(\mathbb{R}^k\)</span>)</p></td>
<td><p>unchanged</p></td>
<td><p><span class="math notranslate nohighlight">\(\mathbb{R}^k\)</span></p></td>
<td><p>not available</p></td>
<td><p><span class="math notranslate nohighlight">\(\Vert Z-Y\Vert^2\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(Z\)</span></p></td>
</tr>
</tbody>
</table>
<p>The label is treated as binary if it takes on two distinct <code class="code docutils literal notranslate"><span class="pre">int</span></code> or <code class="code docutils literal notranslate"><span class="pre">str</span></code> values,
as categorical if it takes on <span class="math notranslate nohighlight">\(k\)</span> distinct <code class="code docutils literal notranslate"><span class="pre">int</span></code> or <code class="code docutils literal notranslate"><span class="pre">str</span></code> values (with <span class="math notranslate nohighlight">\(k&gt;2\)</span>),
and as continuous if it is a float or a vector of floats. Sensitive features are treated similarly.</p>
<p><em>Note: currently, all data needs to be passed to the model in the first call
to fit.</em></p>
</section>
<section id="training">
<span id="adversarial-training"></span><h2>Training<a class="headerlink" href="#training" title="Permalink to this headline">#</a></h2>
<p>Adversarial learning is inherently difficult because of various issues,
such as mode collapse, divergence, and diminishing gradients. Mode collapse
is the scenario where the predictor learns to produce one output, and because
it does this relatively well, it will never learn any other output. Diminishing
gradients are common as well, and could be due to an adversary that is trained
too well in comparison to the predictor.
Such problems
have been studied extensively by others, so we encourage the user to find remedies
elsewhere from more extensive sources. As a general rule of thumb,
training adversarially is best done with a lower and possibly decaying learning
rate while ensuring the
losses remain balanced, and keeping track of validation accuracies every few
iterations may save you a lot of headaches if the model suddenly diverges or
collapses.</p>
<p>Some pieces of advice regarding training with adversarial fairness:</p>
<ol class="arabic simple">
<li><p>For some tabular datasets, we found that single hidden layer neural
networks are easier to train than deeper networks.</p></li>
<li><p>Validate your model! Provide this model with a callback function in
the constructor’s keyword <code class="code docutils literal notranslate"><span class="pre">callbacks</span></code> (see <a class="reference internal" href="#adversarial-example-2"><span class="std std-ref">Example 2: Finetuning training</span></a>).
Optionally, have this function return <code class="code docutils literal notranslate"><span class="pre">True</span></code>
to indicate early stopping.</p></li>
<li><p>Zhang <em>et al.</em><a class="footnote-reference brackets" href="#footcite-zhang2018mitigating" id="id4">1</a> have found it to be useful to maintain a global step
count and gradually increase <span class="math notranslate nohighlight">\(\alpha\)</span> while decreasing the learning
rate <span class="math notranslate nohighlight">\(\eta\)</span> and taking <span class="math notranslate nohighlight">\(\alpha \eta \rightarrow 0\)</span>
as the global step count increases. In particular, use a callback function to perform
these hyperparameter updates. An example can be seen in the example notebook.</p></li>
</ol>
</section>
<section id="example-1-basics-model-specification">
<span id="adversarial-example-1"></span><h2>Example 1: Basics &amp; model specification<a class="headerlink" href="#example-1-basics-model-specification" title="Permalink to this headline">#</a></h2>
<p>First, we cover a most basic application of adversarial mitigation.
We start by loading and preprocessing the dataset:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">fairlearn.datasets</span> <span class="kn">import</span> <span class="n">fetch_adult</span>

<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">fetch_adult</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">pos_label</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="n">z</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="s2">&quot;sex&quot;</span><span class="p">]</span> <span class="c1"># In this example, we consider &#39;sex&#39; the sensitive feature.</span>
</pre></div>
</div>
<p>The UCI adult dataset cannot be fed into a neural network (yet),
as we have many columns that are not numerical in nature. To resolve this
issue, we could for instance use one-hot encodings to preprocess categorical
columns. Additionally, let’s preprocess the numeric columns to a
standardized range. For these tasks, we can use functionality from
scikit-learn (<a class="reference external" href="https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing" title="(in scikit-learn v1.3)"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.preprocessing</span></code></a>). We also use an imputer
to get rid of NaN’s:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.compose</span> <span class="kn">import</span> <span class="n">make_column_transformer</span><span class="p">,</span> <span class="n">make_column_selector</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">OneHotEncoder</span><span class="p">,</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.impute</span> <span class="kn">import</span> <span class="n">SimpleImputer</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="kn">from</span> <span class="nn">numpy</span> <span class="kn">import</span> <span class="n">number</span>

<span class="n">ct</span> <span class="o">=</span> <span class="n">make_column_transformer</span><span class="p">(</span>
    <span class="p">(</span>
        <span class="n">Pipeline</span><span class="p">(</span>
            <span class="p">[</span>
                <span class="p">(</span><span class="s2">&quot;imputer&quot;</span><span class="p">,</span> <span class="n">SimpleImputer</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s2">&quot;mean&quot;</span><span class="p">)),</span>
                <span class="p">(</span><span class="s2">&quot;normalizer&quot;</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">()),</span>
            <span class="p">]</span>
        <span class="p">),</span>
        <span class="n">make_column_selector</span><span class="p">(</span><span class="n">dtype_include</span><span class="o">=</span><span class="n">number</span><span class="p">),</span>
    <span class="p">),</span>
    <span class="p">(</span>
        <span class="n">Pipeline</span><span class="p">(</span>
            <span class="p">[</span>
                <span class="p">(</span><span class="s2">&quot;imputer&quot;</span><span class="p">,</span> <span class="n">SimpleImputer</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s2">&quot;most_frequent&quot;</span><span class="p">)),</span>
                <span class="p">(</span><span class="s2">&quot;encoder&quot;</span><span class="p">,</span> <span class="n">OneHotEncoder</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="s2">&quot;if_binary&quot;</span><span class="p">,</span> <span class="n">sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">)),</span>
            <span class="p">]</span>
        <span class="p">),</span>
        <span class="n">make_column_selector</span><span class="p">(</span><span class="n">dtype_include</span><span class="o">=</span><span class="s2">&quot;category&quot;</span><span class="p">),</span>
    <span class="p">),</span>
<span class="p">)</span>
</pre></div>
</div>
<p>As with other machine learning methods, it is wise to take a train-test split
of the data in order to validate the model on unseen data:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">,</span> <span class="n">Z_train</span><span class="p">,</span> <span class="n">Z_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">12345</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">y</span>
<span class="p">)</span>

<span class="n">X_prep_train</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span> <span class="c1"># Only fit on training data!</span>
<span class="n">X_prep_test</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</pre></div>
</div>
<p>Now, we can use <a class="reference internal" href="../../api_reference/generated/fairlearn.adversarial.AdversarialFairnessClassifier.html#fairlearn.adversarial.AdversarialFairnessClassifier" title="fairlearn.adversarial.AdversarialFairnessClassifier"><code class="xref py py-class docutils literal notranslate"><span class="pre">AdversarialFairnessClassifier</span></code></a>
to train on the
UCI Adult dataset. As our predictor and adversary models, we use for
simplicity the default constructors for fully connected neural
networks with sigmoid activations implemented in Fairlearn. We initialize
neural network constructors
by passing a list <span class="math notranslate nohighlight">\(h_1, h_2, \dots\)</span> that indicate the number of nodes
<span class="math notranslate nohighlight">\(h_i\)</span> per hidden layer <span class="math notranslate nohighlight">\(i\)</span>. You can also put strings in this list
to indicate certain activation functions, or just pass an initialized
activation function directly.</p>
<p>The specific fairness
objective that we choose for this example is demographic parity, so we also
set <code class="code docutils literal notranslate"><span class="pre">objective</span> <span class="pre">=</span> <span class="pre">&quot;demographic_parity&quot;</span></code>. We generally follow sklearn API,
but in this case we require some extra kwargs. In particular, we should
specify the number of epochs, batch size, whether to shuffle the rows of data
after every epoch, and optionally after how many seconds to show a progress
update:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">fairlearn.adversarial</span> <span class="kn">import</span> <span class="n">AdversarialFairnessClassifier</span>

<span class="n">mitigator</span> <span class="o">=</span> <span class="n">AdversarialFairnessClassifier</span><span class="p">(</span>
    <span class="n">backend</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span>
    <span class="n">predictor_model</span><span class="o">=</span><span class="p">[</span><span class="mi">50</span><span class="p">,</span> <span class="s2">&quot;leaky_relu&quot;</span><span class="p">],</span>
    <span class="n">adversary_model</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="s2">&quot;leaky_relu&quot;</span><span class="p">],</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">2</span> <span class="o">**</span> <span class="mi">8</span><span class="p">,</span>
    <span class="n">progress_updates</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
    <span class="n">random_state</span><span class="o">=</span><span class="mi">123</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<p>Then, we can fit the data to our model:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">mitigator</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_prep_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">,</span> <span class="n">sensitive_features</span><span class="o">=</span><span class="n">Z_train</span><span class="p">)</span>
</pre></div>
</div>
<p>Finally, we evaluate the predictions. In particular, we trained the
predictor for demographic parity, so we are not only interested in
the accuracy, but also in the selection rate. MetricFrames are a great resource
here:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">predictions</span> <span class="o">=</span> <span class="n">mitigator</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_prep_test</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">fairlearn.metrics</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">MetricFrame</span><span class="p">,</span>
    <span class="n">selection_rate</span><span class="p">,</span>
    <span class="n">demographic_parity_difference</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>

<span class="n">mf</span> <span class="o">=</span> <span class="n">MetricFrame</span><span class="p">(</span>
    <span class="n">metrics</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;accuracy&quot;</span><span class="p">:</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="s2">&quot;selection_rate&quot;</span><span class="p">:</span> <span class="n">selection_rate</span><span class="p">},</span>
    <span class="n">y_true</span><span class="o">=</span><span class="n">Y_test</span> <span class="o">==</span> <span class="n">pos_label</span><span class="p">,</span>
    <span class="n">y_pred</span><span class="o">=</span><span class="n">predictions</span> <span class="o">==</span> <span class="n">pos_label</span><span class="p">,</span>
    <span class="n">sensitive_features</span><span class="o">=</span><span class="n">Z_test</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<p>Then, to display the result:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">mf</span><span class="o">.</span><span class="n">by_group</span><span class="p">)</span>
<span class="go">        accuracy selection_rate</span>
<span class="go">sex</span>
<span class="go">Female  0.906308       0.978664</span>
<span class="go">Male    0.723336       0.484927</span>
</pre></div>
</div>
<p>The above statistics tell us that the accuracy of our model is quite good,
90% for females and 72% for males. However, the selection rates differ, so there
is a large demographic disparity here. When using adversarial fairness
out-of-the-box, users may not yield such
good training results after the first attempt. In general, training
adversarial networks is hard, and users may need to tweak the
hyperparameters continuously. Besides general scikit-learn algorithms
that finetune estimators,
<a class="reference internal" href="#adversarial-example-2"><span class="std std-ref">Example 2: Finetuning training</span></a> will demonstrate some problem-specific
techniques we can use such as using dynamic hyperparameters,
validation, and early stopping to improve adversarial training.</p>
</section>
<section id="example-2-finetuning-training">
<span id="adversarial-example-2"></span><h2>Example 2: Finetuning training<a class="headerlink" href="#example-2-finetuning-training" title="Permalink to this headline">#</a></h2>
<p>Adversarial learning is inherently difficult because of various issues,
such as mode collapse, divergence, and diminishing gradients.
In particular, mode collapse seems a real problem on this dataset: the
predictor and adversary trap themselves in a local minimum by favoring one
class (mode). Problems with diverging parameters may also occur, which
may be an indication of a bad choice of hyperparameters, such as a
learning rate that is too large. The problems that a user may encounter are
of course case specific, but general good practices when training
such models are: train slowly, ensuring the
losses remain balanced, and keep track of validation accuracies.
Additionally, we found that single hidden layer neural
networks work best for this use case.</p>
<p>In this example, we demonstrate some of these good practices.
We start by defining our
predictor neural network explicitly so that it is more apparent.
We will be using PyTorch, but the same can be achieved using Tensorflow:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>

<span class="k">class</span> <span class="nc">PredictorModel</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">PredictorModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">X_prep_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">200</span><span class="p">),</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(),</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">200</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">(),</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>


<span class="n">predictor_model</span> <span class="o">=</span> <span class="n">PredictorModel</span><span class="p">()</span>
</pre></div>
</div>
<p>We also take a look at some validation
metrics. Most importantly, we chose the demographic parity difference
to check to what
extent the constraint (demographic parity in this case) is satisfied.
We also look at the selection rate to observe whether our model is
suffering from mode collapse, and we also calculate the accuracy on the
validation set as well.
We will pass this validation step to our model later:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">numpy</span> <span class="kn">import</span> <span class="n">mean</span>

<span class="k">def</span> <span class="nf">validate</span><span class="p">(</span><span class="n">mitigator</span><span class="p">):</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="n">mitigator</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_prep_test</span><span class="p">)</span>
    <span class="n">dp_diff</span> <span class="o">=</span> <span class="n">demographic_parity_difference</span><span class="p">(</span>
        <span class="n">Y_test</span> <span class="o">==</span> <span class="n">pos_label</span><span class="p">,</span>
        <span class="n">predictions</span> <span class="o">==</span> <span class="n">pos_label</span><span class="p">,</span>
        <span class="n">sensitive_features</span><span class="o">=</span><span class="n">Z_test</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">mean</span><span class="p">(</span><span class="n">predictions</span><span class="o">.</span><span class="n">values</span> <span class="o">==</span> <span class="n">Y_test</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
    <span class="n">selection_rate</span> <span class="o">=</span> <span class="n">mean</span><span class="p">(</span><span class="n">predictions</span> <span class="o">==</span> <span class="n">pos_label</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span>
        <span class="s2">&quot;DP diff: </span><span class="si">{:.4f}</span><span class="s2">, accuracy: </span><span class="si">{:.4f}</span><span class="s2">, selection_rate: </span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
            <span class="n">dp_diff</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">,</span> <span class="n">selection_rate</span>
        <span class="p">)</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">dp_diff</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">,</span> <span class="n">selection_rate</span>
</pre></div>
</div>
<p>We may define the optimizers however we like. In this case, we use the
suggestion from the paper to set the hyperparameters <span class="math notranslate nohighlight">\(\alpha\)</span> and learning
rate <span class="math notranslate nohighlight">\(\eta\)</span> to depend on the timestep such that <span class="math notranslate nohighlight">\(\alpha \eta
\rightarrow 0\)</span> as the timestep grows:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">schedulers</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">def</span> <span class="nf">optimizer_constructor</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
    <span class="k">global</span> <span class="n">schedulers</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
    <span class="n">schedulers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">ExponentialLR</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.995</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">optimizer</span>

<span class="n">step</span> <span class="o">=</span> <span class="mi">1</span>
</pre></div>
</div>
<p>We make use of a callback function to both update the hyperparameters and to
validate the model. We update these hyperparameters at every 10 steps, and we
validate every 100 steps. Additionally, we can implement early stopping
easily by calling <code class="code docutils literal notranslate"><span class="pre">return</span> <span class="pre">True</span></code> in a callback function:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">math</span> <span class="kn">import</span> <span class="n">sqrt</span>

<span class="k">def</span> <span class="nf">callbacks</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">):</span>
    <span class="k">global</span> <span class="n">step</span>
    <span class="k">global</span> <span class="n">schedulers</span>
    <span class="n">step</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="c1"># Update hyperparameters</span>
    <span class="n">model</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.3</span> <span class="o">*</span> <span class="n">sqrt</span><span class="p">(</span><span class="n">step</span> <span class="o">//</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">scheduler</span> <span class="ow">in</span> <span class="n">schedulers</span><span class="p">:</span>
        <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
    <span class="c1"># Validate (and early stopping) every 50 steps</span>
    <span class="k">if</span> <span class="n">step</span> <span class="o">%</span> <span class="mi">50</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">dp_diff</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">,</span> <span class="n">selection_rate</span> <span class="o">=</span> <span class="n">validate</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
        <span class="c1"># Early stopping condition:</span>
        <span class="c1"># Good accuracy + low dp_diff + no mode collapse</span>
        <span class="k">if</span> <span class="p">(</span>
            <span class="n">dp_diff</span> <span class="o">&lt;</span> <span class="mf">0.03</span>
            <span class="ow">and</span> <span class="n">accuracy</span> <span class="o">&gt;</span> <span class="mf">0.8</span>
            <span class="ow">and</span> <span class="n">selection_rate</span> <span class="o">&gt;</span> <span class="mf">0.01</span>
            <span class="ow">and</span> <span class="n">selection_rate</span> <span class="o">&lt;</span> <span class="mf">0.99</span>
        <span class="p">):</span>
            <span class="k">return</span> <span class="kc">True</span>
</pre></div>
</div>
<p>Then, the instance itself. Notice that we do not explicitly define loss
functions, because adversarial fairness is able to infer the loss function
on its own in this example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">mitigator</span> <span class="o">=</span> <span class="n">AdversarialFairnessClassifier</span><span class="p">(</span>
    <span class="n">predictor_model</span><span class="o">=</span><span class="n">predictor_model</span><span class="p">,</span>
    <span class="n">adversary_model</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="s2">&quot;leaky_relu&quot;</span><span class="p">],</span>
    <span class="n">predictor_optimizer</span><span class="o">=</span><span class="n">optimizer_constructor</span><span class="p">,</span>
    <span class="n">adversary_optimizer</span><span class="o">=</span><span class="n">optimizer_constructor</span><span class="p">,</span>
    <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">2</span> <span class="o">**</span> <span class="mi">7</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">,</span>
    <span class="n">random_state</span><span class="o">=</span><span class="mi">123</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<p>Then, we fit the model:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">mitigator</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_prep_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">,</span> <span class="n">sensitive_features</span><span class="o">=</span><span class="n">Z_train</span><span class="p">)</span>
</pre></div>
</div>
<p>Finally, we validate as before, and take a look at the results:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">validate</span><span class="p">(</span><span class="n">mitigator</span><span class="p">)</span> <span class="c1"># to see DP difference, accuracy, and selection_rate</span>
<span class="go">(0.12749738693557688, 0.8005937148121609, 0.8286416214556249)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">mitigator</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_prep_test</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mf</span> <span class="o">=</span> <span class="n">MetricFrame</span><span class="p">(</span>
<span class="go">        metrics={&quot;accuracy&quot;: accuracy_score, &quot;selection_rate&quot;: selection_rate},</span>
<span class="go">        y_true=Y_test == pos_label,</span>
<span class="go">        y_pred=predictions == pos_label,</span>
<span class="go">        sensitive_features=Z_test,</span>
<span class="go">    )</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">mf</span><span class="o">.</span><span class="n">by_group</span><span class="p">)</span>
<span class="go">        accuracy selection_rate</span>
<span class="go">sex</span>
<span class="go">Female  0.823129       0.743352</span>
<span class="go">Male    0.789441       0.870849</span>
</pre></div>
</div>
<p>Notice we achieve a much lower demographic parity
difference than in Exercise 1! This may come at the cost of some accuracy,
but such a tradeoff is to be expected as we are purposely mitigating
the unfairness that was present in the data.</p>
</section>
<section id="example-3-scikit-learn-applications">
<span id="adversarial-example-3"></span><h2>Example 3: Scikit-learn applications<a class="headerlink" href="#example-3-scikit-learn-applications" title="Permalink to this headline">#</a></h2>
<p>AdversarialFairness is quite compliant with scikit-learn API, so functions
such as pipelining and model selection are applicable here. In particular,
applying pipelining might seem complicated as scikit-learn only pipelines
<code class="code docutils literal notranslate"><span class="pre">X</span></code> and <code class="code docutils literal notranslate"><span class="pre">Y</span></code>, not the <code class="code docutils literal notranslate"><span class="pre">sensitive_features</span></code>.
We overcome this issue by passing the sensitive features through the
pipeline as keyword-argument <code class="code docutils literal notranslate"><span class="pre">[name</span> <span class="pre">of</span> <span class="pre">model]__sensitive_features</span></code>
to fit:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span>
<span class="go">        [</span>
<span class="go">            (&quot;preprocessor&quot;, ct),</span>
<span class="go">            (</span>
<span class="go">                &quot;classifier&quot;,</span>
<span class="go">                AdversarialFairnessClassifier(</span>
<span class="go">                    backend=&quot;torch&quot;,</span>
<span class="go">                    predictor_model=[50, &quot;leaky_relu&quot;],</span>
<span class="go">                    adversary_model=[3, &quot;leaky_relu&quot;],</span>
<span class="go">                    batch_size=2 ** 8,</span>
<span class="go">                    random_state=123,</span>
<span class="go">                ),</span>
<span class="go">            ),</span>
<span class="go">        ]</span>
<span class="go">    )</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pipeline</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">,</span> <span class="n">classifier__sensitive_features</span><span class="o">=</span><span class="n">Z_train</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">pipeline</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mf</span> <span class="o">=</span> <span class="n">MetricFrame</span><span class="p">(</span>
<span class="go">        metrics={&quot;accuracy&quot;: accuracy_score, &quot;selection_rate&quot;: selection_rate},</span>
<span class="go">        y_true=Y_test == pos_label,</span>
<span class="go">        y_pred=predictions == pos_label,</span>
<span class="go">        sensitive_features=Z_test,</span>
<span class="go">    )</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">mf</span><span class="o">.</span><span class="n">by_group</span><span class="p">)</span>
<span class="go">        accuracy selection_rate</span>
<span class="go">sex</span>
<span class="go">Female  0.906308       0.978664</span>
<span class="go">Male    0.723336       0.484927</span>
</pre></div>
</div>
<p>Notice how the same result is obtained as in <a class="reference internal" href="#adversarial-example-1"><span class="std std-ref">Example 1: Basics &amp; model specification</span></a>.</p>
</section>
<section id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this headline">#</a></h2>
<div class="docutils container" id="id5">
<dl class="footnote brackets">
<dt class="label" id="footcite-zhang2018mitigating"><span class="brackets">1</span><span class="fn-backref">(<a href="#id1">1</a>,<a href="#id2">2</a>,<a href="#id3">3</a>,<a href="#id4">4</a>)</span></dt>
<dd><p>Brian Hu Zhang, Blake Lemoine, and Margaret Mitchell. Mitigating unwanted biases with adversarial learning. In <em>Proceedings of the 2018 AAAI/ACM Conference on AI, Ethics, and Society</em>, 335–340. 2018.</p>
</dd>
</dl>
</div>
</section>
</section>


                </article>
              
              
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#models">Models</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-types-and-loss-functions">Data types and loss functions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#training">Training</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#example-1-basics-model-specification">Example 1: Basics &amp; model specification</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#example-2-finetuning-training">Example 2: Finetuning training</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#example-3-scikit-learn-applications">Example 3: Scikit-learn applications</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#references">References</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">
  <p class="copyright">
    
      © Copyright 2018 - 2023, Fairlearn contributors.
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">
  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 4.5.0.
    <br/>
  </p>
</div>
      
    </div>
  
  
    <div class="footer-items__end">
      
        <div class="footer-item"><p class="theme-version">
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.13.3.
</p></div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>