
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Assessment &#8212; Fairlearn 0.8.0.dev0 documentation</title>
<script>
  document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
  document.documentElement.dataset.theme = localStorage.getItem("theme") || "light"
</script>

  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=92025949c220c2e29695" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=92025949c220c2e29695" rel="stylesheet">


  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/custom.css" />

  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=92025949c220c2e29695">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script>window.MathJax = {"tex": {"macros": {"E": "{\\mathbb{E}}", "P": "{\\mathbb{P}}", "given": "\\mathbin{\\vert}"}}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Mitigation" href="mitigation.html" />
    <link rel="prev" title="Fairness in Machine Learning" href="fairness_in_machine_learning.html" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta name="docsearch:language" content="None">
  </head>
  
  
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="180" data-default-mode="">
    <div class="bd-header-announcement container-fluid" id="banner">
      

    </div>

    
    <nav class="bd-header navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="bd-header__inner container-xl">

  <div id="navbar-start">
    
    
  
  


<a class="navbar-brand logo" href="../https%3A//fairlearn.org.html">
  
  
  
  
    <img src="../_static/fairlearn_full_color.svg" class="logo__image only-light" alt="Logo image">
    <img src="../_static/fairlearn_full_color.svg" class="logo__image only-dark" alt="Logo image">
  
  
</a>
    
    <div class="dropdown" id="version_switcher">
    <button type="button" class="btn btn-sm navbar-btn dropdown-toggle" id="version_switcher_button" data-toggle="dropdown">
        main  <!-- this text may get changed later by javascript -->
        <span class="caret"></span>
    </button>
    <div id="version_switcher_menu" class="dropdown-menu list-group-flush py-0" aria-labelledby="version_switcher_button">
    <!-- dropdown will be populated by javascript on page load -->
    </div>
</div>

<!-- NOTE: this JS must live here (not in our global JS file) because it relies
     on being processed by Jinja before it is run (specifically for replacing
     variables user_guide/assessment and {'json_url': 'https://fairlearn.org/main/_static/versions.json', 'version_match': 'main'}.
-->

<script type="text/javascript">
// Check if corresponding page path exists in other version of docs
// and, if so, go there instead of the homepage of the other docs version
function checkPageExistsAndRedirect(event) {
    const currentFilePath = "user_guide/assessment.html",
          tryUrl = event.target.getAttribute("href");
    let otherDocsHomepage = tryUrl.replace(currentFilePath, "");
    $.ajax({
        type: 'HEAD',
        url: tryUrl,
        // if the page exists, go there
        success: function() {
            location.href = tryUrl;
        }
    }).fail(function() {
        location.href = otherDocsHomepage;
    });
    // this prevents the browser from following the href of the clicked node
    // (which is fine because this function takes care of redirecting)
    return false;
}

// Populate the version switcher from the JSON config file
(function () {
    $.getJSON("https://fairlearn.org/main/_static/versions.json", function(data, textStatus, jqXHR) {
        const currentFilePath = "user_guide/assessment.html";
        let btn = document.getElementById("version_switcher_button");
        // Set empty strings by default so that these attributes exist and can be used in CSS selectors
        btn.dataset["activeVersionName"] = "";
        btn.dataset["activeVersion"] = "";
        // create links to the corresponding page in the other docs versions
        $.each(data, function(index, entry) {
            // if no custom name specified (e.g., "latest"), use version string
            if (!("name" in entry)) {
                entry.name = entry.version;
            }
            // create the node
            const node = document.createElement("a");
            node.setAttribute("class", "list-group-item list-group-item-action py-1");
            node.textContent = `${entry.name}`;
            node.setAttribute("href", `${entry.url}${currentFilePath}`);
            // on click, AJAX calls will check if the linked page exists before
            // trying to redirect, and if not, will redirect to the homepage
            // for that version of the docs.
            node.onclick = checkPageExistsAndRedirect;
            // Add dataset values for the version and name in case people want
            // to apply CSS styling based on this information.
            node.dataset["versionName"] = entry.name;
            node.dataset["version"] = entry.version;

            $("#version_switcher_menu").append(node);
            // replace dropdown button text with the preferred display name of
            // this version, rather than using sphinx's  variable.
            // also highlight the dropdown entry for the currently-viewed
            // version's entry
            if (entry.version == "main") {
                node.classList.add("active");
                btn.innerText = btn.dataset["activeVersionName"] = entry.name;
                btn.dataset["activeVersion"] = entry.version;
            }
        });
    });
})();
</script>
    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="fas fa-bars"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../quickstart.html">
  Get Started
 </a>
</li>

<li class="toctree-l1 current active nav-item">
 <a class="reference internal nav-link" href="index.html">
  User Guide
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../api_reference/index.html">
  API Docs
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../auto_examples/index.html">
  Example Notebooks
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../contributor_guide/index.html">
  Contributor Guide
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../faq.html">
  FAQ
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../about/index.html">
  About Us
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <span id="theme-switch" class="btn btn-sm btn-outline-primary navbar-btn rounded-circle">
    <a class="theme-switch" data-mode="light"><i class="fas fa-sun"></i></a>
    <a class="theme-switch" data-mode="dark"><i class="far fa-moon"></i></a>
    <a class="theme-switch" data-mode="auto"><i class="fas fa-adjust"></i></a>
</span>
      </div>
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/fairlearn/fairlearn" rel="noopener" target="_blank" title="GitHub"><span><i class="fab fa-github"></i></span>
            <label class="sr-only">GitHub</label></a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="https://twitter.com/fairlearn" rel="noopener" target="_blank" title="Twitter"><span><i class="fab fa-twitter"></i></span>
            <label class="sr-only">Twitter</label></a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="https://stackoverflow.com/questions/tagged/fairlearn" rel="noopener" target="_blank" title="StackOverflow"><span><i class="fab fa-stack-overflow"></i></span>
            <label class="sr-only">StackOverflow</label></a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="https://discord.gg/R22yCfgsRn" rel="noopener" target="_blank" title="Discord"><span><i class="fab fa-discord"></i></span>
            <label class="sr-only">Discord</label></a>
        </li>
      </ul>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="bd-container container-xl">
      <div class="bd-container__inner row">
          

<!-- Only show if we have sidebars configured, else just a small margin  -->
<div class="bd-sidebar-primary col-12 col-md-3 bd-sidebar">
  <div class="sidebar-start-items"><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="fairness_in_machine_learning.html">
   Fairness in Machine Learning
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Assessment
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="mitigation.html">
   Mitigation
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="datasets/index.html">
   Datasets
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="datasets/adult_data.html">
     Adult Census Dataset
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
    <label for="toctree-checkbox-2">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="datasets/acs_income.html">
       ACSIncome
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="datasets/boston_housing_data.html">
     Revisiting the Boston Housing Dataset
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="datasets/diabetes_hospital_data.html">
     Diabetes 130-Hospitals Dataset
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="installation_and_version_guide/index.html">
   Installation and version guide
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="installation_and_version_guide/installation_guide.html">
     Installation Guide
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="installation_and_version_guide/version_guide.html">
     Version guide
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
    <label for="toctree-checkbox-4">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="installation_and_version_guide/v0.1.html">
       v0.1
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="installation_and_version_guide/v0.2.0.html">
       v0.2.0
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="installation_and_version_guide/v0.3.0.html">
       v0.3.0
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="installation_and_version_guide/v0.4.0.html">
       v0.4.0
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="installation_and_version_guide/v0.4.1.html">
       v0.4.1
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="installation_and_version_guide/v0.4.2.html">
       v0.4.2
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="installation_and_version_guide/v0.4.3.html">
       v0.4.3
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="installation_and_version_guide/v0.4.4.html">
       v0.4.4
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="installation_and_version_guide/v0.4.5.html">
       v0.4.5
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="installation_and_version_guide/v0.4.6.html">
       v0.4.6
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="installation_and_version_guide/v0.5.0.html">
       v0.5.0
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="installation_and_version_guide/v0.6.0.html">
       v0.6.0
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="installation_and_version_guide/v0.6.1.html">
       v0.6.1
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="installation_and_version_guide/v0.6.2.html">
       v0.6.2
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="installation_and_version_guide/v0.7.0.html">
       v0.7.0
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="installation_and_version_guide/v0.8.0.html">
       v0.8.0
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="further_resources.html">
   Further Resources
  </a>
 </li>
</ul>

  </div>
</nav>
  </div>
  <div class="sidebar-end-items">
  </div>
</div>


          


<div class="bd-sidebar-secondary d-none d-xl-block col-xl-2 bd-toc">
  
    
    <div class="toc-item">
      
<div class="tocsection onthispage mt-5 pt-1 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#introduction">
   Introduction
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#identify-types-of-harms">
     Identify types of harms
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#identify-the-groups-that-might-be-harmed">
     Identify the groups that might be harmed
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#quantify-harms">
     Quantify harms
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#compare-quantified-harms-across-the-groups">
     Compare quantified harms across the groups
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#disaggregated-metrics">
   Disaggregated metrics
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#disaggregated-metrics-using-metricframe">
   Disaggregated metrics using
   <code class="code docutils literal notranslate">
    <span class="pre">
     MetricFrame
    </span>
   </code>
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#common-fairness-metrics">
   Common fairness metrics
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#demographic-parity">
     Demographic parity
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#equalized-odds">
     Equalized odds
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#equal-opportunity">
     Equal opportunity
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#multiple-metrics-in-a-single-metricframe">
   Multiple metrics in a single
   <code class="code docutils literal notranslate">
    <span class="pre">
     MetricFrame
    </span>
   </code>
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#non-sample-parameters">
     Non-sample parameters
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#multiclass-metrics">
     Multiclass metrics
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#multiple-sensitive-features">
     Multiple sensitive features
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#scalar-results-from-metricframe">
     Scalar results from
     <code class="code docutils literal notranslate">
      <span class="pre">
       MetricFrame
      </span>
     </code>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#control-features-for-grouped-metrics">
     Control features for grouped metrics
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#plotting">
   Plotting
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#plotting-grouped-metrics">
     Plotting grouped metrics
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#customize-plots-ylim">
       Customize Plots:
       <code class="code docutils literal notranslate">
        <span class="pre">
         ylim
        </span>
       </code>
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#customize-plots-colormap">
       Customize Plots:
       <code class="code docutils literal notranslate">
        <span class="pre">
         colormap
        </span>
       </code>
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#customize-plots-kind">
       Customize Plots:
       <code class="code docutils literal notranslate">
        <span class="pre">
         kind
        </span>
       </code>
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#fairlearn-dashboard">
   Fairlearn dashboard
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#references">
   References
  </a>
 </li>
</ul>

</nav>
    </div>
    
    <div class="toc-item">
      
    </div>
    
  
</div>


          
          
          <div class="bd-content col-12 col-md-9 col-xl-7">
              
              <article class="bd-article" role="main">
                
  <section id="assessment">
<h1>Assessment<a class="headerlink" href="#assessment" title="Permalink to this headline">#</a></h1>
<section id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">#</a></h2>
<p>The goal of fairness assessment is to answer the question: Which groups of
people may be disproportionately negatively impacted by an AI system and in
what ways?</p>
<p>The steps of the assesment are as follows:</p>
<ol class="arabic simple">
<li><p>Identify types of harms</p></li>
<li><p>Identify the groups that might be harmed</p></li>
<li><p>Quantify harms</p></li>
<li><p>Compare quantified harms across the groups</p></li>
</ol>
<p>We next examine these four steps in more detail.</p>
<section id="identify-types-of-harms">
<h3>Identify types of harms<a class="headerlink" href="#identify-types-of-harms" title="Permalink to this headline">#</a></h3>
<p>See <a class="reference internal" href="fairness_in_machine_learning.html#types-of-harms"><span class="std std-ref">Types of harms</span></a> for a guide to types of fairness-related harms.
For example, in a system for screening job applications, qualified candidates
that are automatically rejected experience an allocation harm. In a
speech-to-text transcription system, disparities in word error rates for
different groups may result in harms due to differences in the quality of service.
Note that one system can lead to multiple harms, and different types of
harms are not mutually exclusive. For more information, review
Fairlearn’s <a class="reference external" href="https://github.com/fairlearn/talks/blob/main/2021_scipy_tutorial/overview.pdf">2021 SciPy tutorial</a>.</p>
</section>
<section id="identify-the-groups-that-might-be-harmed">
<h3>Identify the groups that might be harmed<a class="headerlink" href="#identify-the-groups-that-might-be-harmed" title="Permalink to this headline">#</a></h3>
<p>In most applications, we consider demographic groups including historically
marginalized groups (e.g., based on gender, race, ethnicity). We should also
consider groups that are relevant to a particular use case or deployment context. For example, for
speech-to-text transcription, this might include groups who speak a regional dialect or people who are a
native or a non-native speaker.</p>
<p>It is also important to consider group intersections, for example, in addition
to considering groups according to gender and groups according to race, it is
also important to consider their intersections (e.g., Black women, Latinx
nonbinary people, etc.). Crenshaw<a class="footnote-reference brackets" href="#footcite-crenshaw1991intersectionality" id="id1">1</a>
offers a thorough background on the topic of intersectionality.</p>
</section>
<section id="quantify-harms">
<h3>Quantify harms<a class="headerlink" href="#quantify-harms" title="Permalink to this headline">#</a></h3>
<p>Define metrics that quantify harms or benefits:</p>
<ul class="simple">
<li><p>In a job screening scenario, we need to quantify the number of candidates that are classified as “negative” (not recommended for the job), but whose true label is “positive” (they are “qualified”). One possible metric is the false negative rate: fraction of qualified candidates that are screened out. Note that before we attempt to classify candidates, we need to determine the construct validity of the “qualified” status; more information on construct validity can be found in <a class="reference internal" href="fairness_in_machine_learning.html#id6"><span class="std std-ref">What is construct validity?</span></a></p></li>
<li><p>For a speech-to-text application, the harm could be measured by disparities in the word error rate for different group, measured by the number of mistakes in a transcript divided by the overall number of words.</p></li>
</ul>
<p>Note that in some cases, the outcome we seek to measure is not
directly available.
Occasionally, another variable in our dataset provides a close
approximation to the phenomenon we seek to measure.
In these cases, we might choose to use that closely related variable,
often called a “proxy”, to stand in for the missing variable.
For example, suppose that in the job screening scenario,
we have data on whether the candidate passes the first two stages,
but not if they are ultimately recommended for the job.</p>
<p>As an alternative to the unobserved final recommendation, we could
therefore measure the harm using the proxy variable indicating whether
the candidate passes the first stage of the screen.
If you choose to use a proxy variable to
represent the harm, check the proxy variable regularly to ensure it
remains useful over time. Our section on <a class="reference internal" href="fairness_in_machine_learning.html#id6"><span class="std std-ref">What is construct validity?</span></a>
describes how to determine whether a
proxy variable measures the intended construct in a meaningful
and useful way. It is important to ensure that the proxy is suitable
for the social context of the problem you seek to solve.
In particular, be careful of falling into one of the :ref:abstraction_traps.</p>
</section>
<section id="compare-quantified-harms-across-the-groups">
<h3>Compare quantified harms across the groups<a class="headerlink" href="#compare-quantified-harms-across-the-groups" title="Permalink to this headline">#</a></h3>
<p>The centerpiece of fairness assessment in Fairlearn are disaggregated metrics,
which are metrics evaluated on slices of data. For example, to measure harms due to
errors, we would begin by evaluating the errors on each slice of the data that
corresponds to a group. If some of the groups are seeing much larger errors
than other groups, we would flag this as a fairness harm.</p>
<p>To summarize the disparities in errors (or other metrics), we may want to
report quantities such as the difference or ratio of the metric values between
the best and the worst slice. In settings where the goal is to guarantee
certain minimum quality of service across all groups (such as speech recognition),
it is also meaningful to report the worst performance across all considered groups.</p>
<p>For example, when comparing the false negative rate across groups defined by race,
we may summarize our findings with a table. Note that the these statistics must
be drawn from a large enough sample size to draw meaningful conclusions.</p>
<table class="colwidths-given table">
<colgroup>
<col style="width: 10%" />
<col style="width: 45%" />
<col style="width: 45%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head stub"></th>
<th class="head"><p>false negative rate (FNR)</p></th>
<th class="head"><p>sample size</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><th class="stub"><p>AfricanAmerican</p></th>
<td><p>0.43</p></td>
<td><p>126</p></td>
</tr>
<tr class="row-odd"><th class="stub"><p>Caucasian</p></th>
<td><p>0.44</p></td>
<td><p>620</p></td>
</tr>
<tr class="row-even"><th class="stub"><p>Other</p></th>
<td><p>0.52</p></td>
<td><p>200</p></td>
</tr>
<tr class="row-odd"><th class="stub"><p>Unknown</p></th>
<td><p>0.67</p></td>
<td><p>60</p></td>
</tr>
<tr class="row-even"><th class="stub"><p>largest difference</p></th>
<td><p>0.24 (best is 0.0)</p></td>
<td><p>N/A</p></td>
</tr>
<tr class="row-odd"><th class="stub"><p>smallest ratio</p></th>
<td><p>0.64 (best is 1.0)</p></td>
<td><p>N/A</p></td>
</tr>
<tr class="row-even"><th class="stub"><p>maximum (worst-case) FNR</p></th>
<td><p>0.67</p></td>
<td><p>N/A</p></td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="disaggregated-metrics">
<h2>Disaggregated metrics<a class="headerlink" href="#disaggregated-metrics" title="Permalink to this headline">#</a></h2>
<p>The <a class="reference internal" href="../api_reference/fairlearn.metrics.html#module-fairlearn.metrics" title="fairlearn.metrics"><code class="xref py py-mod docutils literal notranslate"><span class="pre">fairlearn.metrics</span></code></a> module provides the means to assess
fairness-related metrics for models. This applies for any kind of model that
users may already use, but also for models created with mitigation techniques
from the <a class="reference internal" href="mitigation.html#mitigation"><span class="std std-ref">Mitigation</span></a> section.</p>
<p>At their simplest, metrics take a set of ‘true’ values <span class="math notranslate nohighlight">\(Y_{true}\)</span> (from
the input data) and predicted values <span class="math notranslate nohighlight">\(Y_{pred}\)</span> (by applying the model
to the input data), and use these to compute a measure. For example, the
<em>recall</em> or <em>true positive rate</em> is given by</p>
<div class="math notranslate nohighlight">
\[P( Y_{pred}=1 \given Y_{true}=1 )\]</div>
<p>That is, a measure of whether the model finds all the positive cases in the
input data. The <cite>scikit-learn</cite> package implements this in
<a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html#sklearn.metrics.recall_score" title="(in scikit-learn v1.1)"><code class="xref py py-func docutils literal notranslate"><span class="pre">sklearn.metrics.recall_score()</span></code></a>.</p>
<p>Suppose we have the following data we can see that the prediction is <cite>1</cite> in five
of the ten cases where the true value is <cite>1</cite>, so we expect the recall to be 0.5:</p>
<div class="highlight-pycon3 notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">sklearn.metrics</span> <span class="k">as</span> <span class="nn">skm</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">skm</span><span class="o">.</span><span class="n">recall_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="go">0.5</span>
</pre></div>
</div>
</section>
<section id="disaggregated-metrics-using-metricframe">
<span id="metrics-with-grouping"></span><h2>Disaggregated metrics using <code class="code docutils literal notranslate"><span class="pre">MetricFrame</span></code><a class="headerlink" href="#disaggregated-metrics-using-metricframe" title="Permalink to this headline">#</a></h2>
<p>In a typical fairness assessment, each row of input data will have an associated
group label <span class="math notranslate nohighlight">\(g \in G\)</span>, and we will want to know how the metric behaves
for each group <span class="math notranslate nohighlight">\(g\)</span>. To help with this, Fairlearn provides a class that takes
an existing (disaggregated) metric function, like
<a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score" title="(in scikit-learn v1.1)"><code class="xref py py-func docutils literal notranslate"><span class="pre">sklearn.metrics.roc_auc_score()</span></code></a> or <a class="reference internal" href="../api_reference/fairlearn.metrics.html#fairlearn.metrics.false_positive_rate" title="fairlearn.metrics.false_positive_rate"><code class="xref py py-func docutils literal notranslate"><span class="pre">fairlearn.metrics.false_positive_rate()</span></code></a>,
and applies it to each group within a set of data.</p>
<p>This data structure, <a class="reference internal" href="../api_reference/fairlearn.metrics.html#fairlearn.metrics.MetricFrame" title="fairlearn.metrics.MetricFrame"><code class="xref py py-class docutils literal notranslate"><span class="pre">fairlearn.metrics.MetricFrame</span></code></a>, enables evaluation
of disaggregated metrics. In its simplest form <a class="reference internal" href="../api_reference/fairlearn.metrics.html#fairlearn.metrics.MetricFrame" title="fairlearn.metrics.MetricFrame"><code class="xref py py-class docutils literal notranslate"><span class="pre">fairlearn.metrics.MetricFrame</span></code></a>
takes four arguments:</p>
<ul class="simple">
<li><p>metric_function with signature <code class="code docutils literal notranslate"><span class="pre">metric_function(y_true,</span> <span class="pre">y_pred)</span></code></p></li>
<li><p>y_true: array of labels</p></li>
<li><p>y_pred: array of predictions</p></li>
<li><p>sensitive_features: array of sensitive feature values</p></li>
</ul>
<p>The code chunk below displays a case where in addition to the <span class="math notranslate nohighlight">\(Y_{true}\)</span>
and <span class="math notranslate nohighlight">\(Y_{pred}\)</span> above, the dataset also contains the following set of
labels, denoted by the “group_membership_data” column:</p>
<div class="highlight-pycon3 notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">group_membership_data</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;d&#39;</span><span class="p">,</span> <span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;c&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="s1">&#39;c&#39;</span><span class="p">,</span> <span class="s1">&#39;c&#39;</span><span class="p">,</span> <span class="s1">&#39;c&#39;</span><span class="p">,</span>
<span class="gp">... </span>                         <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="s1">&#39;d&#39;</span><span class="p">,</span> <span class="s1">&#39;c&#39;</span><span class="p">,</span> <span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="s1">&#39;d&#39;</span><span class="p">,</span> <span class="s1">&#39;c&#39;</span><span class="p">,</span> <span class="s1">&#39;c&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;display.max_columns&#39;</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;display.width&#39;</span><span class="p">,</span> <span class="mi">80</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span> <span class="s1">&#39;y_true&#39;</span><span class="p">:</span> <span class="n">y_true</span><span class="p">,</span>
<span class="gp">... </span>               <span class="s1">&#39;y_pred&#39;</span><span class="p">:</span> <span class="n">y_pred</span><span class="p">,</span>
<span class="gp">... </span>               <span class="s1">&#39;group_membership_data&#39;</span><span class="p">:</span> <span class="n">group_membership_data</span><span class="p">})</span>
<span class="go">    y_true  y_pred group_membership_data</span>
<span class="go">0        0       0                     d</span>
<span class="go">1        1       0                     a</span>
<span class="go">2        1       1                     c</span>
<span class="go">3        1       0                     b</span>
<span class="go">4        1       1                     b</span>
<span class="go">5        0       1                     c</span>
<span class="go">6        1       1                     c</span>
<span class="go">7        0       0                     c</span>
<span class="go">8        1       0                     b</span>
<span class="go">9        0       1                     d</span>
<span class="go">10       0       1                     c</span>
<span class="go">11       0       1                     a</span>
<span class="go">12       1       1                     b</span>
<span class="go">13       1       0                     d</span>
<span class="go">14       1       0                     c</span>
<span class="go">15       1       1                     c</span>
</pre></div>
</div>
<p>We then calculate a metric which shows the subgroups:</p>
<div class="highlight-pycon3 notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">fairlearn.metrics</span> <span class="kn">import</span> <span class="n">MetricFrame</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">grouped_metric</span> <span class="o">=</span> <span class="n">MetricFrame</span><span class="p">(</span><span class="n">metrics</span><span class="o">=</span><span class="n">skm</span><span class="o">.</span><span class="n">recall_score</span><span class="p">,</span>
<span class="gp">... </span>                             <span class="n">y_true</span><span class="o">=</span><span class="n">y_true</span><span class="p">,</span>
<span class="gp">... </span>                             <span class="n">y_pred</span><span class="o">=</span><span class="n">y_pred</span><span class="p">,</span>
<span class="gp">... </span>                             <span class="n">sensitive_features</span><span class="o">=</span><span class="n">group_membership_data</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Overall recall = &quot;</span><span class="p">,</span> <span class="n">grouped_metric</span><span class="o">.</span><span class="n">overall</span><span class="p">)</span>
<span class="go">Overall recall =  0.5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;recall by groups = &quot;</span><span class="p">,</span> <span class="n">grouped_metric</span><span class="o">.</span><span class="n">by_group</span><span class="o">.</span><span class="n">to_dict</span><span class="p">())</span>
<span class="go">recall by groups =  {&#39;a&#39;: 0.0, &#39;b&#39;: 0.5, &#39;c&#39;: 0.75, &#39;d&#39;: 0.0}</span>
</pre></div>
</div>
<p>The disaggregated metrics are stored in a <a class="reference external" href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html#pandas.Series" title="(in pandas v1.4.3)"><code class="xref py py-class docutils literal notranslate"><span class="pre">pandas.Series</span></code></a>
<code class="code docutils literal notranslate"><span class="pre">grouped_metric.by_group</span></code>. Note that the overall recall is the same
as that calculated above in the Ungrouped Metric section, while the ‘by_group’
dictionary can be checked against the table above.</p>
<p>In addition to these basic scores, Fairlearn provides
convenience functions to recover the maximum and minimum values of the metric
across groups and also the difference and ratio between the maximum and minimum:</p>
<div class="highlight-pycon3 notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;min recall over groups = &quot;</span><span class="p">,</span> <span class="n">grouped_metric</span><span class="o">.</span><span class="n">group_min</span><span class="p">())</span>
<span class="go">min recall over groups =  0.0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;max recall over groups = &quot;</span><span class="p">,</span> <span class="n">grouped_metric</span><span class="o">.</span><span class="n">group_max</span><span class="p">())</span>
<span class="go">max recall over groups =  0.75</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;difference in recall = &quot;</span><span class="p">,</span> <span class="n">grouped_metric</span><span class="o">.</span><span class="n">difference</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s1">&#39;between_groups&#39;</span><span class="p">))</span>
<span class="go">difference in recall =  0.75</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;ratio in recall = &quot;</span><span class="p">,</span> <span class="n">grouped_metric</span><span class="o">.</span><span class="n">ratio</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s1">&#39;between_groups&#39;</span><span class="p">))</span>
<span class="go">ratio in recall =  0.0</span>
</pre></div>
</div>
</section>
<section id="common-fairness-metrics">
<h2>Common fairness metrics<a class="headerlink" href="#common-fairness-metrics" title="Permalink to this headline">#</a></h2>
<p>In the sections below, we review the most common fairness metrics, as well
as their underlying assumptions and suggestions for use. Each metric requires
that some aspects of the predictor behavior be comparable across groups. In
the mathematical definitions below, <span class="math notranslate nohighlight">\(X\)</span> denotes a feature vector
used for predictions, <span class="math notranslate nohighlight">\(A\)</span> be a single sensitive feature (such as age
or race), and <span class="math notranslate nohighlight">\(Y\)</span> be the true label. Fairness metrics are phrased in
terms of expectations with respect to the distribution over <span class="math notranslate nohighlight">\((X,A,Y)\)</span>.</p>
<section id="demographic-parity">
<span id="id2"></span><h3>Demographic parity<a class="headerlink" href="#demographic-parity" title="Permalink to this headline">#</a></h3>
<p>Demographic parity is a fairness metric whose goal is to ensure a machine
learning model’s predictions are independent of membership in a sensitive
group. In other words, demographic parity is achieved when the probability
of a certain prediction is not dependent on sensitive group membership. In
the binary classification scenario, demographic parity refers to equal
selection rates across groups. For example, in the context of a resume
screening model, equal selection would mean that the proportion of
applicants selected for a job interview should be equal across groups.</p>
<p>We mathematically define demographic parity using the following
set of equations.
A classifier <span class="math notranslate nohighlight">\(h\)</span> satisfies demographic parity under a distribution
over <span class="math notranslate nohighlight">\((X, A, Y)\)</span> if its prediction <span class="math notranslate nohighlight">\(h(X)\)</span> is statistically
independent of the sensitive feature <span class="math notranslate nohighlight">\(A\)</span>.
Agarwal, Beygelzimer, Dudík, Langford, and Wallach<a class="footnote-reference brackets" href="#footcite-agarwal2018reductions" id="id3">2</a> show that this is equivalent to
<span class="math notranslate nohighlight">\(\E[h(X) \given A=a] = \E[h(X)] \quad \forall a\)</span>.</p>
<p>In the case of regression, a predictor <span class="math notranslate nohighlight">\(f\)</span> satisfies demographic parity
under a distribution over <span class="math notranslate nohighlight">\((X, A, Y)\)</span> if <span class="math notranslate nohighlight">\(f(X)\)</span> is independent
of the sensitive feature <span class="math notranslate nohighlight">\(A\)</span>.
Agarwal, Dudík, and Wu<a class="footnote-reference brackets" href="#footcite-agarwal2019fair" id="id4">3</a> show that this is equivalent to
<span class="math notranslate nohighlight">\(\P[f(X) \geq z \given A=a] = \P[f(X) \geq z] \quad \forall a, z\)</span>.
Another way to think of demographic parity in a
regression scenario is to compare the average predicted value across groups.
Note that in the Fairlearn API, <a class="reference internal" href="../api_reference/fairlearn.metrics.html#fairlearn.metrics.demographic_parity_difference" title="fairlearn.metrics.demographic_parity_difference"><code class="xref py py-func docutils literal notranslate"><span class="pre">fairlearn.metrics.demographic_parity_difference()</span></code></a>
is only defined for classification.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Demographic parity is also sometimes referred to as <em>independence</em>, <em>group fairness</em>, <em>statistical parity</em>, and <em>disparate impact</em>.</p>
</div>
<p>Failing to achieve demographic parity could generate allocation harms.
Allocation harms occur when AI systems allocate
opportunities, resources, or information differently across different
groups (for example, an AI hiring system that is more likely to advance resumes
of male applicants than resumes of female applicants regardless of qualification).
Demographic parity can be used to assess the extent of allocation harms because it
reflects an assumption that resources should be allocated proportionally
across groups. Of the metrics described in this section, it can be the easiest
to implement. However, operationalizing fairness using demographic parity
rests on a few assumptions: that either the dataset is not a good representation
of what the world actually looks like (e.g., a resume assessment system that is
more likely to filter out qualified female applicants due to an organizational
bias towards male applicants, regardless of skill level), or that the dataset
is an accurate representation of the phenomena being modeled, but the
phenomena itself is unjust (e.g., consider the case of predictive policing,
where a system created to predict crime rates may correctly predict higher crime
rates for certain areas, but simultaneously fail to consider that those higher
rates may be caused by disproportionate policing and overcriminimalization of those areas).
In reality, these assumptions may not be the true. The
dataset might be an accurate representation of the phenomena itself,
or the phenomena being modeled may not be unjust.
If either assumption is not true, then demographic parity may not provide
a meaningful or useful measurement of the fairness of a model’s predictions.</p>
<p>Fairness metrics like demographic parity can also be used as optimization
constraints during the machine learning model training process. However,
demographic parity may not be well-suited for this purpose because
it does not place requirements on the exact distribution of predictions with
respect to other important variables. To understand this concept further,
consider an example from the Fairness in Machine Learning textbook
by Barocas, Hardt, and Narayanan<a class="footnote-reference brackets" href="#footcite-barocas2019fairness" id="id5">4</a>:</p>
<blockquote>
<div><p>“However, decisions based on a classifier that satisfies independence can
have undesirable properties (and similar arguments apply to other
statistical critiera). Here is one way in which this can happen,
which is easiest to illustrate if we imagine a callous or ill-intentioned
decision maker. Imagine a company that in <em>group A</em> hires diligently
selected applicants at some rate p&gt;0. In <em>group B</em>, the company
hires carelessly selected applicants at the same rate p. Even though
the acceptance rates in both groups are identical, it is far more likely
that unqualified applicants are selected in one group than in the other.
As a result, it will appear in hindsight that members of <em>group B</em>
performed worse than members of <em>group A</em>, thus establishing a negative
track record for group B.”</p>
</div></blockquote>
<p>It’s also worth considering whether the assumptions underlying demographic
parity maintain construct validity (see <a class="reference internal" href="fairness_in_machine_learning.html#id6"><span class="std std-ref">What is construct validity?</span></a>).
Construct validity is a concept in the social sciences that assesses the
extent to which the ways we choose to measure abstract
phenomena are valid. For demographic parity, one relevant question would be
whether demographic parity meets the criteria for establishing “fairness”,
itself an unobservable theoretical construct. Further, it’s important
to ask whether satisfying demographic parity actually brings us closer
to the world we’d like to see.</p>
<p id="conditional-group-fairness">In some cases, we may observe a trend in data from multiple demographic groups,
but that trend may disappear or reverse when groups are combined. Known as
<a class="reference external" href="https://en.wikipedia.org/wiki/Simpson%27s_paradox">Simpson’s Paradox</a>, this
outcome may appear when observing disparate outcomes across groups. A
famous example of Simpson’s Paradox is a study of 1973 graduate school
admissions to the University of California, Berkley <a class="footnote-reference brackets" href="#footcite-bickel1975biasinadmissions" id="id6">5</a>.
The study showed that when observing admissions by gender, men applying were
more likely than women to be accepted. However, drilling down into admissions
by department revealed that women tended to apply to departments with more
competitive admissions requirements, whereas men tended to apply to less
competitive departments. The more granular analysis showed only four out of
85 departments exhibited bias against women, and six departments exhibited
bias towards men. In general, the data indicated departments exhibited a bias
in favor of minority-gendered applicants, which is opposite from the trend
observed in the aggregate data.</p>
<p>This phenomenon is important to fairness evaluation because metrics like
demographic parity may be different when calculated at an aggregate level and
within more granular categories. In the case of demographic parity, we might
need to review
<span class="math notranslate nohighlight">\(\E[h(X) \given A=a, D=d] = \E[h(X) \given D=d] \quad \forall a\)</span>
where D represents the feature(s) within X across which members of the groups
within A are distributed.
Demographic parity would then require that the prediction of the target
variable is statistically independent of sensitive attributes conditional
on D. Simply aggregating outcomes across high-level categories can be
misleading when the data can be further disaggregated.
It’s important to review metrics across these more graular categories,
if they exist, to verify that disparate outcomes persist across all levels
of aggregation.</p>
<p>However, more granular categories generally contain smaller sample sizes, and
it can be more difficult to establish that trends seen in very small
samples are not due to random chance.
We also recommend watching out for the <a class="reference external" href="https://stats.libretexts.org/Bookshelves/Applied_Statistics/Book%3A_Biological_Statistics_(McDonald)/06%3A_Multiple_Tests/6.01%3A_Multiple_Comparisons">multiple comparisons problem</a>,
which states that the more statistical inferences are made, the
more erroneous those inferences will become. For example, in the case
of evaluating fairness metrics on multiple groups, as we break the
groups down into more granular categories and evaluate those smaller
groups, it will become more likely that these subgroups will
differ enough to fail one of the metrics. For dealing with the multiple
comparisons problem, we recommend investigating <a class="reference external" href="https://www.statology.org/bonferroni-correction/">statistical techniques</a>
meant to correct the errors produced by individual statistical tests.</p>
</section>
<section id="equalized-odds">
<span id="id7"></span><h3>Equalized odds<a class="headerlink" href="#equalized-odds" title="Permalink to this headline">#</a></h3>
<p>The goal of the equalized odds fairness metric is to ensure a machine
learning model performs equally well for different groups. It is stricter
than demographic parity because it requires that the machine learning
model’s predictions are not only independent of sensitive group membership,
but that groups have the same false positive rates and and true positive
rates. This distinction is important because a model could achieve
demographic parity (i.e., its predictions could be independent of
sensitive group membership), but still generate more false positive
predictions for one group versus others. Equalized odds does not create
the selection issue discussed in the demographic parity section above.
For example, in the hiring scenario where the goal is to choose applicants
from <em>group A</em> and <em>group B</em>, ensuring the model performs equally well at
choosing applicants from <em>group A</em> and <em>group B</em> can circumvent the issue of
the model optimizing by selecting applicants from one group at random.</p>
<p>We mathematically define equalized odds using the following
set of equations. A classifier <span class="math notranslate nohighlight">\(h\)</span> satisfies equalized
odds under a distribution over <span class="math notranslate nohighlight">\((X, A, Y)\)</span> if its
prediction <span class="math notranslate nohighlight">\(h(X)\)</span> is
conditionally independent of the sensitive feature <span class="math notranslate nohighlight">\(A\)</span> given the label
<span class="math notranslate nohighlight">\(Y\)</span>.
Agarwal, Beygelzimer, Dudík, Langford, and Wallach<a class="footnote-reference brackets" href="#footcite-agarwal2018reductions" id="id8">2</a> show that this is equivalent to
<span class="math notranslate nohighlight">\(\E[h(X) \given A=a, Y=y] = \E[h(X) \given Y=y] \quad \forall a, y\)</span>.
Equalized odds requires that the true
positive rate, <span class="math notranslate nohighlight">\(\P(h(X)=1 | Y=1\)</span>, and the false positive rate,
<span class="math notranslate nohighlight">\(\P(h(X)=1 | Y=0\)</span>, be equal across groups.</p>
<p>The inclusion of false positive rates acknowledges that different groups
experience different costs from misclassification. For example, in the case of
a model predicting a negative outcome (e.g., probability of recidivating)
that already disproportionately affects members of minority communities,
false positive predictions reflect pre-existing disparities in outcomes
across minority and majority groups. Equalized odds further enforces that the
accuracy is equally high across all groups, punishing models that only
perform well on majority groups.</p>
<p>If a machine learning model does not perform equally well for all groups,
then it could generate allocation or quality-of-service harms.
Equalized odds can be used to diagnose both allocation harms as well as
quality-of-service harms. Allocation harms are discussed in detail in the
demographic parity section above. Quality-of-service harms occur when an
AI system does not work as well for one group versus another (for example,
facial recognition systems that are more likely to fail for dark-skinned
individuals). For more information on AI harms, see <a class="reference internal" href="fairness_in_machine_learning.html#types-of-harms"><span class="std std-ref">Types of harms</span></a>.</p>
<p>Equalized odds can be useful for diagnosing allocation harms
because its goal is to ensure that a machine learning model works equally
well for different groups. Another way to think about equalized odds is to
contrast it with demographic parity. While demographic parity assesses the
allocation of resources generally, equalized odds focuses on the allocation
of resources that were actually distributed to
members of that group (indicated by the positive target variable Y=1).
However, equalized odds makes the assumption
that the target variable <span class="math notranslate nohighlight">\(Y\)</span> is a good measurement of the phenomena
being modeled, but that assumption may not hold if the measurement does not
satisfy the requirements of construct validity.</p>
</section>
<section id="equal-opportunity">
<span id="id9"></span><h3>Equal opportunity<a class="headerlink" href="#equal-opportunity" title="Permalink to this headline">#</a></h3>
<p>Equal opportunity is a relaxed version of equalized odds that only considers
conditional expectations with respect to positive labels, i.e., <span class="math notranslate nohighlight">\(Y=1\)</span>.
<a class="footnote-reference brackets" href="#footcite-hardt2016equality" id="id10">6</a>
Another way of thinking about this metric is
requiring equal outcomes only within the subset of records belonging to the
positive class. For example, in the hiring example, equal opportunity
requires that the individuals who are actually hired have an equal opportunity
of being hired in the first place. However, by not considering whether false
positive rates are equivalent across groups, equal opportunity does not
capture the costs of missclassification disparities.</p>
</section>
</section>
<section id="multiple-metrics-in-a-single-metricframe">
<h2>Multiple metrics in a single <code class="code docutils literal notranslate"><span class="pre">MetricFrame</span></code><a class="headerlink" href="#multiple-metrics-in-a-single-metricframe" title="Permalink to this headline">#</a></h2>
<p>A single instance of <a class="reference internal" href="../api_reference/fairlearn.metrics.html#fairlearn.metrics.MetricFrame" title="fairlearn.metrics.MetricFrame"><code class="xref py py-class docutils literal notranslate"><span class="pre">fairlearn.metrics.MetricFrame</span></code></a> can evaluate multiple
metrics simultaneously by providing the <cite>metrics</cite> argument with a
dictionary of desired metrics. The disaggregated metrics are then stored in a
pandas DataFrame. Note that <a class="reference external" href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="(in pandas v1.4.3)"><code class="xref py py-class docutils literal notranslate"><span class="pre">pandas.DataFrame</span></code></a> can
be used to show each group’s size:</p>
<div class="highlight-pycon3 notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">fairlearn.metrics</span> <span class="kn">import</span> <span class="n">count</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">multi_metric</span> <span class="o">=</span> <span class="n">MetricFrame</span><span class="p">({</span><span class="s1">&#39;precision&#39;</span><span class="p">:</span><span class="n">skm</span><span class="o">.</span><span class="n">precision_score</span><span class="p">,</span>
<span class="gp">... </span>                            <span class="s1">&#39;recall&#39;</span><span class="p">:</span><span class="n">skm</span><span class="o">.</span><span class="n">recall_score</span><span class="p">,</span>
<span class="gp">... </span>                            <span class="s1">&#39;count&#39;</span><span class="p">:</span> <span class="n">count</span><span class="p">},</span>
<span class="gp">... </span>                            <span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span>
<span class="gp">... </span>                            <span class="n">sensitive_features</span><span class="o">=</span><span class="n">group_membership_data</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">multi_metric</span><span class="o">.</span><span class="n">overall</span>
<span class="go">precision    0.5555...</span>
<span class="go">recall       0.5...</span>
<span class="go">dtype: float64</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">multi_metric</span><span class="o">.</span><span class="n">by_group</span>
<span class="go">                     precision  recall  count</span>
<span class="go">sensitive_feature_0</span>
<span class="go">a                          0.0    0.00    2.0</span>
<span class="go">b                          1.0    0.50    4.0</span>
<span class="go">c                          0.6    0.75    7.0</span>
<span class="go">d                          0.0    0.00    3.0</span>
</pre></div>
</div>
<p>If there are per-sample arguments (such as sample weights), these can also be
provided in a dictionary via the <code class="docutils literal notranslate"><span class="pre">sample_params</span></code> argument.:</p>
<div class="highlight-pycon3 notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">s_w</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">s_p</span> <span class="o">=</span> <span class="p">{</span> <span class="s1">&#39;sample_weight&#39;</span><span class="p">:</span><span class="n">s_w</span> <span class="p">}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">weighted</span> <span class="o">=</span> <span class="n">MetricFrame</span><span class="p">(</span><span class="n">metrics</span><span class="o">=</span><span class="n">skm</span><span class="o">.</span><span class="n">recall_score</span><span class="p">,</span>
<span class="gp">... </span>                       <span class="n">y_true</span><span class="o">=</span><span class="n">y_true</span><span class="p">,</span>
<span class="gp">... </span>                       <span class="n">y_pred</span><span class="o">=</span><span class="n">y_pred</span><span class="p">,</span>
<span class="gp">... </span>                       <span class="n">sensitive_features</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">group_membership_data</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;SF 0&#39;</span><span class="p">),</span>
<span class="gp">... </span>                       <span class="n">sample_params</span><span class="o">=</span><span class="n">s_p</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">weighted</span><span class="o">.</span><span class="n">overall</span>
<span class="go">0.45</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">weighted</span><span class="o">.</span><span class="n">by_group</span>
<span class="go">SF 0</span>
<span class="go">a    0...</span>
<span class="go">b    0.5...</span>
<span class="go">c    0.7142...</span>
<span class="go">d    0...</span>
<span class="go">Name: recall_score, dtype: float64</span>
</pre></div>
</div>
<p>If multiple metrics are being evaluated, then <code class="docutils literal notranslate"><span class="pre">sample_params</span></code> becomes a
dictionary of dictionaries, with the first key corresponding matching that in
the dictionary holding the desired underlying metric functions.</p>
<section id="non-sample-parameters">
<h3>Non-sample parameters<a class="headerlink" href="#non-sample-parameters" title="Permalink to this headline">#</a></h3>
<p>We do not support non-sample parameters at the current time. If these are
required, then use <a class="reference external" href="https://docs.python.org/3/library/functools.html#functools.partial" title="(in Python v3.10)"><code class="xref py py-func docutils literal notranslate"><span class="pre">functools.partial()</span></code></a> to prebind the required arguments
to the metric function:</p>
<div class="highlight-pycon3 notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">functools</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">fbeta_06</span> <span class="o">=</span> <span class="n">functools</span><span class="o">.</span><span class="n">partial</span><span class="p">(</span><span class="n">skm</span><span class="o">.</span><span class="n">fbeta_score</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">0.6</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metric_beta</span> <span class="o">=</span> <span class="n">MetricFrame</span><span class="p">(</span><span class="n">metrics</span><span class="o">=</span><span class="n">fbeta_06</span><span class="p">,</span>
<span class="gp">... </span>                          <span class="n">y_true</span><span class="o">=</span><span class="n">y_true</span><span class="p">,</span>
<span class="gp">... </span>                          <span class="n">y_pred</span><span class="o">=</span><span class="n">y_pred</span><span class="p">,</span>
<span class="gp">... </span>                          <span class="n">sensitive_features</span><span class="o">=</span><span class="n">group_membership_data</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metric_beta</span><span class="o">.</span><span class="n">overall</span>
<span class="go">0.5396825396825397</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metric_beta</span><span class="o">.</span><span class="n">by_group</span>
<span class="go">sensitive_feature_0</span>
<span class="go">a    0...</span>
<span class="go">b    0.7906...</span>
<span class="go">c    0.6335...</span>
<span class="go">d    0...</span>
<span class="go">Name: metric, dtype: float64</span>
</pre></div>
</div>
</section>
<section id="multiclass-metrics">
<h3>Multiclass metrics<a class="headerlink" href="#multiclass-metrics" title="Permalink to this headline">#</a></h3>
<p>We may also be interested in multiclass classification. However, typical group
fairness metrics such as equalized odds and demographic parity are only defined
for binary classification. One way to measure fairness in the multiclass
scenario is to define one-to-one or one-to-rest classifications for each group
and calculate the metrics on this instead. Alternatively, we can use predefined
metrics for multiclass classification. For example, accuracy is a multiclass
metric that we can use through scikit-learn’s <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score" title="(in scikit-learn v1.1)"><code class="xref py py-func docutils literal notranslate"><span class="pre">sklearn.metrics.accuracy_score()</span></code></a>
in combination with a <code class="code docutils literal notranslate"><span class="pre">MetricFrame</span></code> as follows:</p>
<div class="highlight-pycon3 notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">fairlearn.metrics</span> <span class="kn">import</span> <span class="n">MetricFrame</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_mult_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_mult_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mf</span> <span class="o">=</span> <span class="n">MetricFrame</span><span class="p">(</span><span class="n">metric</span><span class="o">=</span><span class="n">accuracy_score</span><span class="p">,</span>
<span class="gp">... </span>                 <span class="n">y_true</span><span class="o">=</span><span class="n">y_mult_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">=</span><span class="n">y_mult_pred</span><span class="p">,</span>
<span class="gp">... </span>                 <span class="n">sensitive_features</span><span class="o">=</span><span class="n">group_membership_data</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">mf</span><span class="o">.</span><span class="n">by_group</span><span class="p">)</span> <span class="c1"># series with accuracy for each sensitive group</span>
<span class="go">sensitive_feature_0</span>
<span class="go">a    1.000000</span>
<span class="go">b    0.500000</span>
<span class="go">c    0.428571</span>
<span class="go">d    1.000000</span>
<span class="go">Name: accuracy_score, dtype: float64</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">mf</span><span class="o">.</span><span class="n">difference</span><span class="p">())</span> <span class="c1"># difference in accuracy between the max and min of all groups</span>
<span class="go">0.5714285714285714</span>
</pre></div>
</div>
</section>
<section id="multiple-sensitive-features">
<h3>Multiple sensitive features<a class="headerlink" href="#multiple-sensitive-features" title="Permalink to this headline">#</a></h3>
<p>Finally, multiple sensitive features can be specified. The <code class="docutils literal notranslate"><span class="pre">by_groups</span></code>
property then holds the intersections of these groups:</p>
<div class="highlight-pycon3 notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">g_2</span> <span class="o">=</span> <span class="p">[</span> <span class="mi">8</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">6</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">s_f_frame</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">group_membership_data</span><span class="p">,</span> <span class="n">g_2</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
<span class="gp">... </span>                         <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;SF 0&#39;</span><span class="p">,</span> <span class="s1">&#39;SF 1&#39;</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metric_2sf</span> <span class="o">=</span> <span class="n">MetricFrame</span><span class="p">(</span><span class="n">metrics</span><span class="o">=</span><span class="n">skm</span><span class="o">.</span><span class="n">recall_score</span><span class="p">,</span>
<span class="gp">... </span>                         <span class="n">y_true</span><span class="o">=</span><span class="n">y_true</span><span class="p">,</span>
<span class="gp">... </span>                         <span class="n">y_pred</span><span class="o">=</span><span class="n">y_pred</span><span class="p">,</span>
<span class="gp">... </span>                         <span class="n">sensitive_features</span><span class="o">=</span><span class="n">s_f_frame</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metric_2sf</span><span class="o">.</span><span class="n">overall</span>  <span class="c1"># Same as before</span>
<span class="go">0.5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metric_2sf</span><span class="o">.</span><span class="n">by_group</span>
<span class="go">SF 0  SF 1</span>
<span class="go">a     6       0.0</span>
<span class="go">      8       NaN</span>
<span class="go">b     6       0.5</span>
<span class="go">      8       0.5</span>
<span class="go">c     6       1.0</span>
<span class="go">      8       0.5</span>
<span class="go">d     6       0.0</span>
<span class="go">      8       0.0</span>
<span class="go">Name: recall_score, dtype: float64</span>
</pre></div>
</div>
<p>With such a small number of samples, we are obviously running into cases where
there are no members in a particular combination of sensitive features. In this
case we see that the subgroup <code class="docutils literal notranslate"><span class="pre">(a,</span> <span class="pre">8)</span></code> has a result of <code class="docutils literal notranslate"><span class="pre">NaN</span></code>, indicating
that there were no samples in it.</p>
</section>
<section id="scalar-results-from-metricframe">
<span id="scalar-metric-results"></span><h3>Scalar results from <code class="code docutils literal notranslate"><span class="pre">MetricFrame</span></code><a class="headerlink" href="#scalar-results-from-metricframe" title="Permalink to this headline">#</a></h3>
<p>Higher level machine learning algorithms (such as hyperparameter tuners) often
make use of metric functions to guide their optimisations.
Such algorithms generally work with scalar results, so if we want the tuning
to be done on the basis of our fairness metrics, we need to perform aggregations
over the <a class="reference internal" href="../api_reference/fairlearn.metrics.html#fairlearn.metrics.MetricFrame" title="fairlearn.metrics.MetricFrame"><code class="xref py py-class docutils literal notranslate"><span class="pre">MetricFrame</span></code></a>.</p>
<p>We provide a convenience function, <a class="reference internal" href="../api_reference/fairlearn.metrics.html#fairlearn.metrics.make_derived_metric" title="fairlearn.metrics.make_derived_metric"><code class="xref py py-func docutils literal notranslate"><span class="pre">fairlearn.metrics.make_derived_metric()</span></code></a>,
to generate scalar-producing metric functions based on the aggregation methods
mentioned above (<a class="reference internal" href="../api_reference/fairlearn.metrics.html#fairlearn.metrics.MetricFrame.group_min" title="fairlearn.metrics.MetricFrame.group_min"><code class="xref py py-meth docutils literal notranslate"><span class="pre">MetricFrame.group_min()</span></code></a>, <a class="reference internal" href="../api_reference/fairlearn.metrics.html#fairlearn.metrics.MetricFrame.group_max" title="fairlearn.metrics.MetricFrame.group_max"><code class="xref py py-meth docutils literal notranslate"><span class="pre">MetricFrame.group_max()</span></code></a>,
<a class="reference internal" href="../api_reference/fairlearn.metrics.html#fairlearn.metrics.MetricFrame.difference" title="fairlearn.metrics.MetricFrame.difference"><code class="xref py py-meth docutils literal notranslate"><span class="pre">MetricFrame.difference()</span></code></a>, and <a class="reference internal" href="../api_reference/fairlearn.metrics.html#fairlearn.metrics.MetricFrame.ratio" title="fairlearn.metrics.MetricFrame.ratio"><code class="xref py py-meth docutils literal notranslate"><span class="pre">MetricFrame.ratio()</span></code></a>).
This takes an underlying metric function, the name of the desired transformation, and
optionally a list of parameter names which should be treated as sample aligned parameters
(such as <cite>sample_weight</cite>).
Other parameters will be passed to the underlying metric function normally (unlike
<a class="reference internal" href="../api_reference/fairlearn.metrics.html#fairlearn.metrics.MetricFrame" title="fairlearn.metrics.MetricFrame"><code class="xref py py-class docutils literal notranslate"><span class="pre">MetricFrame</span></code></a> where <a class="reference external" href="https://docs.python.org/3/library/functools.html#functools.partial" title="(in Python v3.10)"><code class="xref py py-func docutils literal notranslate"><span class="pre">functools.partial()</span></code></a> must be used, as noted above).
The result is a function which builds the <a class="reference internal" href="../api_reference/fairlearn.metrics.html#fairlearn.metrics.MetricFrame" title="fairlearn.metrics.MetricFrame"><code class="xref py py-class docutils literal notranslate"><span class="pre">MetricFrame</span></code></a> internally and performs
the requested aggregation. For example:</p>
<div class="highlight-pycon3 notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">fairlearn.metrics</span> <span class="kn">import</span> <span class="n">make_derived_metric</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">fbeta_difference</span> <span class="o">=</span> <span class="n">make_derived_metric</span><span class="p">(</span><span class="n">metric</span><span class="o">=</span><span class="n">skm</span><span class="o">.</span><span class="n">fbeta_score</span><span class="p">,</span>
<span class="gp">... </span>                                       <span class="n">transform</span><span class="o">=</span><span class="s1">&#39;difference&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Don&#39;t need functools.partial for make_derived_metric</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">fbeta_difference</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span>
<span class="gp">... </span>                 <span class="n">sensitive_features</span><span class="o">=</span><span class="n">group_membership_data</span><span class="p">)</span>
<span class="go">0.752525...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># But as noted above, functools.partial is needed for MetricFrame</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">fbeta_07</span> <span class="o">=</span> <span class="n">functools</span><span class="o">.</span><span class="n">partial</span><span class="p">(</span><span class="n">skm</span><span class="o">.</span><span class="n">fbeta_score</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">MetricFrame</span><span class="p">(</span><span class="n">metrics</span><span class="o">=</span><span class="n">fbeta_07</span><span class="p">,</span>
<span class="gp">... </span>            <span class="n">y_true</span><span class="o">=</span><span class="n">y_true</span><span class="p">,</span>
<span class="gp">... </span>            <span class="n">y_pred</span><span class="o">=</span><span class="n">y_pred</span><span class="p">,</span>
<span class="gp">... </span>            <span class="n">sensitive_features</span><span class="o">=</span><span class="n">group_membership_data</span><span class="p">)</span><span class="o">.</span><span class="n">difference</span><span class="p">()</span>
<span class="go">0.752525...</span>
</pre></div>
</div>
<p>We use <a class="reference internal" href="../api_reference/fairlearn.metrics.html#fairlearn.metrics.make_derived_metric" title="fairlearn.metrics.make_derived_metric"><code class="xref py py-func docutils literal notranslate"><span class="pre">fairlearn.metrics.make_derived_metric()</span></code></a> to manufacture a number
of such functions which will be commonly used:</p>
<table class="table">
<colgroup>
<col style="width: 42%" />
<col style="width: 15%" />
<col style="width: 15%" />
<col style="width: 16%" />
<col style="width: 12%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Base metric</p></th>
<th class="head"><p><code class="code docutils literal notranslate"><span class="pre">group_min</span></code></p></th>
<th class="head"><p><code class="code docutils literal notranslate"><span class="pre">group_max</span></code></p></th>
<th class="head"><p><code class="code docutils literal notranslate"><span class="pre">difference</span></code></p></th>
<th class="head"><p><code class="code docutils literal notranslate"><span class="pre">ratio</span></code></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><a class="reference internal" href="../api_reference/fairlearn.metrics.html#fairlearn.metrics.false_negative_rate" title="fairlearn.metrics.false_negative_rate"><code class="xref py py-func docutils literal notranslate"><span class="pre">false_negative_rate()</span></code></a></p></td>
<td><p>.</p></td>
<td><p>.</p></td>
<td><p>Y</p></td>
<td><p>Y</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="../api_reference/fairlearn.metrics.html#fairlearn.metrics.false_positive_rate" title="fairlearn.metrics.false_positive_rate"><code class="xref py py-func docutils literal notranslate"><span class="pre">false_positive_rate()</span></code></a></p></td>
<td><p>.</p></td>
<td><p>.</p></td>
<td><p>Y</p></td>
<td><p>Y</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="../api_reference/fairlearn.metrics.html#fairlearn.metrics.selection_rate" title="fairlearn.metrics.selection_rate"><code class="xref py py-func docutils literal notranslate"><span class="pre">selection_rate()</span></code></a></p></td>
<td><p>.</p></td>
<td><p>.</p></td>
<td><p>Y</p></td>
<td><p>Y</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="../api_reference/fairlearn.metrics.html#fairlearn.metrics.true_negative_rate" title="fairlearn.metrics.true_negative_rate"><code class="xref py py-func docutils literal notranslate"><span class="pre">true_negative_rate()</span></code></a></p></td>
<td><p>.</p></td>
<td><p>.</p></td>
<td><p>Y</p></td>
<td><p>Y</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="../api_reference/fairlearn.metrics.html#fairlearn.metrics.true_positive_rate" title="fairlearn.metrics.true_positive_rate"><code class="xref py py-func docutils literal notranslate"><span class="pre">true_positive_rate()</span></code></a></p></td>
<td><p>.</p></td>
<td><p>.</p></td>
<td><p>Y</p></td>
<td><p>Y</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score" title="(in scikit-learn v1.1)"><code class="xref py py-func docutils literal notranslate"><span class="pre">sklearn.metrics.accuracy_score()</span></code></a></p></td>
<td><p>Y</p></td>
<td><p>.</p></td>
<td><p>Y</p></td>
<td><p>Y</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.balanced_accuracy_score.html#sklearn.metrics.balanced_accuracy_score" title="(in scikit-learn v1.1)"><code class="xref py py-func docutils literal notranslate"><span class="pre">sklearn.metrics.balanced_accuracy_score()</span></code></a></p></td>
<td><p>Y</p></td>
<td><p>.</p></td>
<td><p>.</p></td>
<td><p>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score" title="(in scikit-learn v1.1)"><code class="xref py py-func docutils literal notranslate"><span class="pre">sklearn.metrics.f1_score()</span></code></a></p></td>
<td><p>Y</p></td>
<td><p>.</p></td>
<td><p>.</p></td>
<td><p>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.log_loss.html#sklearn.metrics.log_loss" title="(in scikit-learn v1.1)"><code class="xref py py-func docutils literal notranslate"><span class="pre">sklearn.metrics.log_loss()</span></code></a></p></td>
<td><p>.</p></td>
<td><p>Y</p></td>
<td><p>.</p></td>
<td><p>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html#sklearn.metrics.mean_absolute_error" title="(in scikit-learn v1.1)"><code class="xref py py-func docutils literal notranslate"><span class="pre">sklearn.metrics.mean_absolute_error()</span></code></a></p></td>
<td><p>.</p></td>
<td><p>Y</p></td>
<td><p>.</p></td>
<td><p>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html#sklearn.metrics.mean_squared_error" title="(in scikit-learn v1.1)"><code class="xref py py-func docutils literal notranslate"><span class="pre">sklearn.metrics.mean_squared_error()</span></code></a></p></td>
<td><p>.</p></td>
<td><p>Y</p></td>
<td><p>.</p></td>
<td><p>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html#sklearn.metrics.precision_score" title="(in scikit-learn v1.1)"><code class="xref py py-func docutils literal notranslate"><span class="pre">sklearn.metrics.precision_score()</span></code></a></p></td>
<td><p>Y</p></td>
<td><p>.</p></td>
<td><p>.</p></td>
<td><p>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html#sklearn.metrics.r2_score" title="(in scikit-learn v1.1)"><code class="xref py py-func docutils literal notranslate"><span class="pre">sklearn.metrics.r2_score()</span></code></a></p></td>
<td><p>Y</p></td>
<td><p>.</p></td>
<td><p>.</p></td>
<td><p>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html#sklearn.metrics.recall_score" title="(in scikit-learn v1.1)"><code class="xref py py-func docutils literal notranslate"><span class="pre">sklearn.metrics.recall_score()</span></code></a></p></td>
<td><p>Y</p></td>
<td><p>.</p></td>
<td><p>.</p></td>
<td><p>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score" title="(in scikit-learn v1.1)"><code class="xref py py-func docutils literal notranslate"><span class="pre">sklearn.metrics.roc_auc_score()</span></code></a></p></td>
<td><p>Y</p></td>
<td><p>.</p></td>
<td><p>.</p></td>
<td><p>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.zero_one_loss.html#sklearn.metrics.zero_one_loss" title="(in scikit-learn v1.1)"><code class="xref py py-func docutils literal notranslate"><span class="pre">sklearn.metrics.zero_one_loss()</span></code></a></p></td>
<td><p>.</p></td>
<td><p>Y</p></td>
<td><p>Y</p></td>
<td><p>Y</p></td>
</tr>
</tbody>
</table>
<p>The names of the generated functions are of the form
<code class="code docutils literal notranslate"><span class="pre">fairlearn.metrics.&lt;base_metric&gt;_&lt;transformation&gt;</span></code>.
For example <code class="code docutils literal notranslate"><span class="pre">fairlearn.metrics.accuracy_score_difference</span></code> and
<code class="code docutils literal notranslate"><span class="pre">fairlearn.metrics.precision_score_group_min</span></code>.</p>
</section>
<section id="control-features-for-grouped-metrics">
<span id="control-features-metrics"></span><h3>Control features for grouped metrics<a class="headerlink" href="#control-features-for-grouped-metrics" title="Permalink to this headline">#</a></h3>
<p>Control features (sometimes called ‘conditional’ features) enable more detailed
fairness insights by providing a further means of splitting the data into
subgroups.
When the data are split into subgroups, control features (if provided) act
similarly to sensitive features.
However, the ‘overall’ value for the metric is now computed for each subgroup
of the control feature(s).
Similarly, the aggregation functions (such as <code class="code docutils literal notranslate"><span class="pre">MetricFrame.group_max</span></code>) are
performed for each subgroup in the conditional feature(s), rather than across
them (as happens with the sensitive features).</p>
<p>Control features are useful for cases where there is some expected variation with
a feature, so we need to compute disparities while controlling for that feature.
For example, in a loan scenario we would expect people of differing incomes to
be approved at different rates, but within each income band we would still
want to measure disparities between different sensitive features. However, it
should be borne in mind that due to historic discrimination, the income band
might be correlated with various sensitive features. Because of this, control
features should be used with particular caution.</p>
<p>The <a class="reference internal" href="../api_reference/fairlearn.metrics.html#fairlearn.metrics.MetricFrame" title="fairlearn.metrics.MetricFrame"><code class="xref py py-class docutils literal notranslate"><span class="pre">MetricFrame</span></code></a> constructor allows us to specify control features in
a manner similar to sensitive features, using a <code class="code docutils literal notranslate"><span class="pre">control_features=</span></code>
parameter:</p>
<div class="highlight-pycon3 notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">decision</span> <span class="o">=</span> <span class="p">[</span>
<span class="gp">... </span>   <span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span>
<span class="gp">... </span>   <span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span>
<span class="gp">... </span>   <span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span>
<span class="gp">... </span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">prediction</span> <span class="o">=</span> <span class="p">[</span>
<span class="gp">... </span>   <span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span>
<span class="gp">... </span>   <span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span>
<span class="gp">... </span>   <span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span>
<span class="gp">... </span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">control_feature</span> <span class="o">=</span> <span class="p">[</span>
<span class="gp">... </span>   <span class="s1">&#39;H&#39;</span><span class="p">,</span><span class="s1">&#39;L&#39;</span><span class="p">,</span><span class="s1">&#39;H&#39;</span><span class="p">,</span><span class="s1">&#39;L&#39;</span><span class="p">,</span><span class="s1">&#39;H&#39;</span><span class="p">,</span><span class="s1">&#39;L&#39;</span><span class="p">,</span><span class="s1">&#39;L&#39;</span><span class="p">,</span><span class="s1">&#39;H&#39;</span><span class="p">,</span><span class="s1">&#39;H&#39;</span><span class="p">,</span><span class="s1">&#39;L&#39;</span><span class="p">,</span>
<span class="gp">... </span>   <span class="s1">&#39;L&#39;</span><span class="p">,</span><span class="s1">&#39;H&#39;</span><span class="p">,</span><span class="s1">&#39;H&#39;</span><span class="p">,</span><span class="s1">&#39;L&#39;</span><span class="p">,</span><span class="s1">&#39;L&#39;</span><span class="p">,</span><span class="s1">&#39;H&#39;</span><span class="p">,</span><span class="s1">&#39;L&#39;</span><span class="p">,</span><span class="s1">&#39;L&#39;</span><span class="p">,</span><span class="s1">&#39;H&#39;</span><span class="p">,</span><span class="s1">&#39;H&#39;</span><span class="p">,</span>
<span class="gp">... </span>   <span class="s1">&#39;L&#39;</span><span class="p">,</span><span class="s1">&#39;H&#39;</span><span class="p">,</span><span class="s1">&#39;L&#39;</span><span class="p">,</span><span class="s1">&#39;L&#39;</span><span class="p">,</span><span class="s1">&#39;H&#39;</span><span class="p">,</span><span class="s1">&#39;H&#39;</span><span class="p">,</span><span class="s1">&#39;L&#39;</span><span class="p">,</span><span class="s1">&#39;L&#39;</span><span class="p">,</span><span class="s1">&#39;H&#39;</span><span class="p">,</span><span class="s1">&#39;L&#39;</span>
<span class="gp">... </span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sensitive_feature</span> <span class="o">=</span> <span class="p">[</span>
<span class="gp">... </span>   <span class="s1">&#39;A&#39;</span><span class="p">,</span><span class="s1">&#39;B&#39;</span><span class="p">,</span><span class="s1">&#39;B&#39;</span><span class="p">,</span><span class="s1">&#39;C&#39;</span><span class="p">,</span><span class="s1">&#39;C&#39;</span><span class="p">,</span><span class="s1">&#39;B&#39;</span><span class="p">,</span><span class="s1">&#39;A&#39;</span><span class="p">,</span><span class="s1">&#39;A&#39;</span><span class="p">,</span><span class="s1">&#39;B&#39;</span><span class="p">,</span><span class="s1">&#39;A&#39;</span><span class="p">,</span>
<span class="gp">... </span>   <span class="s1">&#39;C&#39;</span><span class="p">,</span><span class="s1">&#39;B&#39;</span><span class="p">,</span><span class="s1">&#39;C&#39;</span><span class="p">,</span><span class="s1">&#39;A&#39;</span><span class="p">,</span><span class="s1">&#39;C&#39;</span><span class="p">,</span><span class="s1">&#39;C&#39;</span><span class="p">,</span><span class="s1">&#39;B&#39;</span><span class="p">,</span><span class="s1">&#39;B&#39;</span><span class="p">,</span><span class="s1">&#39;C&#39;</span><span class="p">,</span><span class="s1">&#39;A&#39;</span><span class="p">,</span>
<span class="gp">... </span>   <span class="s1">&#39;B&#39;</span><span class="p">,</span><span class="s1">&#39;B&#39;</span><span class="p">,</span><span class="s1">&#39;C&#39;</span><span class="p">,</span><span class="s1">&#39;A&#39;</span><span class="p">,</span><span class="s1">&#39;B&#39;</span><span class="p">,</span><span class="s1">&#39;A&#39;</span><span class="p">,</span><span class="s1">&#39;B&#39;</span><span class="p">,</span><span class="s1">&#39;B&#39;</span><span class="p">,</span><span class="s1">&#39;A&#39;</span><span class="p">,</span><span class="s1">&#39;A&#39;</span>
<span class="gp">... </span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metric_c_f</span> <span class="o">=</span> <span class="n">MetricFrame</span><span class="p">(</span><span class="n">metrics</span><span class="o">=</span><span class="n">skm</span><span class="o">.</span><span class="n">accuracy_score</span><span class="p">,</span>
<span class="gp">... </span>                         <span class="n">y_true</span><span class="o">=</span><span class="n">decision</span><span class="p">,</span>
<span class="gp">... </span>                         <span class="n">y_pred</span><span class="o">=</span><span class="n">prediction</span><span class="p">,</span>
<span class="gp">... </span>                         <span class="n">sensitive_features</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;SF&#39;</span> <span class="p">:</span> <span class="n">sensitive_feature</span><span class="p">},</span>
<span class="gp">... </span>                         <span class="n">control_features</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;CF&#39;</span> <span class="p">:</span> <span class="n">control_feature</span><span class="p">})</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># The &#39;overall&#39; property is now split based on the control feature</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metric_c_f</span><span class="o">.</span><span class="n">overall</span>
<span class="go">CF</span>
<span class="go">H    0.4285...</span>
<span class="go">L    0.375...</span>
<span class="go">Name: accuracy_score, dtype: float64</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># The &#39;by_group&#39; property looks similar to how it would if we had two sensitive features</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metric_c_f</span><span class="o">.</span><span class="n">by_group</span>
<span class="go">CF  SF</span>
<span class="go">H   A     0.2...</span>
<span class="go">    B     0.4...</span>
<span class="go">    C     0.75...</span>
<span class="go">L   A     0.4...</span>
<span class="go">    B     0.2857...</span>
<span class="go">    C     0.5...</span>
<span class="go">Name: accuracy_score, dtype: float64</span>
</pre></div>
</div>
<p>Note how the <a class="reference internal" href="../api_reference/fairlearn.metrics.html#fairlearn.metrics.MetricFrame.overall" title="fairlearn.metrics.MetricFrame.overall"><code class="xref py py-attr docutils literal notranslate"><span class="pre">MetricFrame.overall</span></code></a> property is stratified based on the
supplied control feature. The <a class="reference internal" href="../api_reference/fairlearn.metrics.html#fairlearn.metrics.MetricFrame.by_group" title="fairlearn.metrics.MetricFrame.by_group"><code class="xref py py-attr docutils literal notranslate"><span class="pre">MetricFrame.by_group</span></code></a> property allows
us to see disparities between the groups in the sensitive feature for each
group in the control feature.
When displayed like this, <a class="reference internal" href="../api_reference/fairlearn.metrics.html#fairlearn.metrics.MetricFrame.by_group" title="fairlearn.metrics.MetricFrame.by_group"><code class="xref py py-attr docutils literal notranslate"><span class="pre">MetricFrame.by_group</span></code></a> looks similar to
how it would if we had specified two sensitive features (although the
control features will always be at the top level of the hierarchy).</p>
<p>With the <a class="reference internal" href="../api_reference/fairlearn.metrics.html#fairlearn.metrics.MetricFrame" title="fairlearn.metrics.MetricFrame"><code class="xref py py-class docutils literal notranslate"><span class="pre">MetricFrame</span></code></a> computed, we can perform aggregations:</p>
<div class="highlight-pycon3 notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># See the maximum accuracy for each value of the control feature</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metric_c_f</span><span class="o">.</span><span class="n">group_max</span><span class="p">()</span>
<span class="go">CF</span>
<span class="go">H    0.75</span>
<span class="go">L    0.50</span>
<span class="go">Name: accuracy_score, dtype: float64</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># See the maximum difference in accuracy for each value of the control feature</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metric_c_f</span><span class="o">.</span><span class="n">difference</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s1">&#39;between_groups&#39;</span><span class="p">)</span>
<span class="go">CF</span>
<span class="go">H    0.55...</span>
<span class="go">L    0.2142...</span>
<span class="go">Name: accuracy_score, dtype: float64</span>
</pre></div>
</div>
<p>In each case, rather than a single scalar, we receive one result for each
subgroup identified by the conditional feature. The call
<code class="code docutils literal notranslate"><span class="pre">metric_c_f.group_max()</span></code> call shows the maximum value of the metric across
the subgroups of the sensitive feature within each value of the control feature.
Similarly, <code class="code docutils literal notranslate"><span class="pre">metric_c_f.difference(method='between_groups')</span></code> call shows the
maximum difference between the subgroups of the sensitive feature within
each value of the control feature.
For more examples, please
see the <a class="reference internal" href="../auto_examples/plot_new_metrics.html#sphx-glr-auto-examples-plot-new-metrics-py"><span class="std std-ref">Metrics with Multiple Features</span></a> notebook in the
<a class="reference internal" href="../auto_examples/index.html#examples"><span class="std std-ref">Example Notebooks</span></a>.</p>
</section>
</section>
<section id="plotting">
<span id="plot"></span><h2>Plotting<a class="headerlink" href="#plotting" title="Permalink to this headline">#</a></h2>
<section id="plotting-grouped-metrics">
<h3>Plotting grouped metrics<a class="headerlink" href="#plotting-grouped-metrics" title="Permalink to this headline">#</a></h3>
<p>The simplest way to visualize grouped metrics from the <a class="reference internal" href="../api_reference/fairlearn.metrics.html#fairlearn.metrics.MetricFrame" title="fairlearn.metrics.MetricFrame"><code class="xref py py-class docutils literal notranslate"><span class="pre">MetricFrame</span></code></a> is
to take advantage of the inherent plotting capabilities of
<a class="reference external" href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="(in pandas v1.4.3)"><code class="xref py py-class docutils literal notranslate"><span class="pre">pandas.DataFrame</span></code></a>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">metrics</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;accuracy&quot;</span><span class="p">:</span> <span class="n">accuracy_score</span><span class="p">,</span>
    <span class="s2">&quot;precision&quot;</span><span class="p">:</span> <span class="n">precision_score</span><span class="p">,</span>
    <span class="s2">&quot;false positive rate&quot;</span><span class="p">:</span> <span class="n">false_positive_rate</span><span class="p">,</span>
    <span class="s2">&quot;false negative rate&quot;</span><span class="p">:</span> <span class="n">false_negative_rate</span><span class="p">,</span>
    <span class="s2">&quot;selection rate&quot;</span><span class="p">:</span> <span class="n">selection_rate</span><span class="p">,</span>
    <span class="s2">&quot;count&quot;</span><span class="p">:</span> <span class="n">count</span><span class="p">,</span>
<span class="p">}</span>
<span class="n">metric_frame</span> <span class="o">=</span> <span class="n">MetricFrame</span><span class="p">(</span>
    <span class="n">metrics</span><span class="o">=</span><span class="n">metrics</span><span class="p">,</span> <span class="n">y_true</span><span class="o">=</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">=</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">sensitive_features</span><span class="o">=</span><span class="n">sex</span>
<span class="p">)</span>
<span class="n">metric_frame</span><span class="o">.</span><span class="n">by_group</span><span class="o">.</span><span class="n">plot</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span>
    <span class="n">subplots</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">layout</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
    <span class="n">legend</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">figsize</span><span class="o">=</span><span class="p">[</span><span class="mi">12</span><span class="p">,</span> <span class="mi">8</span><span class="p">],</span>
    <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Show all metrics&quot;</span><span class="p">,</span>
<span class="p">)</span>

</pre></div>
</div>
<figure class="align-center">
<a class="reference external image-reference" href="auto_examples/plot_quickstart.html"><img alt="../_images/sphx_glr_plot_quickstart_001.png" src="../_images/sphx_glr_plot_quickstart_001.png" /></a>
</figure>
<p>It is possible to customize the plots. Here are some common examples.</p>
<section id="customize-plots-ylim">
<h4>Customize Plots: <code class="code docutils literal notranslate"><span class="pre">ylim</span></code><a class="headerlink" href="#customize-plots-ylim" title="Permalink to this headline">#</a></h4>
<p>The y-axis range is automatically set, which can be misleading, therefore it is
sometimes useful to set the <cite>ylim</cite> argument to define the yaxis range.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">metric_frame</span><span class="o">.</span><span class="n">by_group</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
    <span class="n">kind</span><span class="o">=</span><span class="s2">&quot;bar&quot;</span><span class="p">,</span>
    <span class="n">ylim</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
    <span class="n">subplots</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">layout</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
    <span class="n">legend</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">figsize</span><span class="o">=</span><span class="p">[</span><span class="mi">12</span><span class="p">,</span> <span class="mi">8</span><span class="p">],</span>
    <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Show all metrics with assigned y-axis range&quot;</span><span class="p">,</span>
<span class="p">)</span>

</pre></div>
</div>
<figure class="align-center">
<img alt="../_images/sphx_glr_plot_quickstart_002.png" src="../_images/sphx_glr_plot_quickstart_002.png" />
</figure>
</section>
<section id="customize-plots-colormap">
<h4>Customize Plots: <code class="code docutils literal notranslate"><span class="pre">colormap</span></code><a class="headerlink" href="#customize-plots-colormap" title="Permalink to this headline">#</a></h4>
<p>To change the color scheme, we can use the <cite>colormap</cite> argument. A list of colorschemes
can be found <a class="reference external" href="https://matplotlib.org/stable/tutorials/colors/colormaps.html">here</a>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">metric_frame</span><span class="o">.</span><span class="n">by_group</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
    <span class="n">kind</span><span class="o">=</span><span class="s2">&quot;bar&quot;</span><span class="p">,</span>
    <span class="n">subplots</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">layout</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
    <span class="n">legend</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">figsize</span><span class="o">=</span><span class="p">[</span><span class="mi">12</span><span class="p">,</span> <span class="mi">8</span><span class="p">],</span>
    <span class="n">colormap</span><span class="o">=</span><span class="s2">&quot;Accent&quot;</span><span class="p">,</span>
    <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Show all metrics in Accent colormap&quot;</span><span class="p">,</span>
<span class="p">)</span>

</pre></div>
</div>
<figure class="align-center">
<img alt="../_images/sphx_glr_plot_quickstart_003.png" src="../_images/sphx_glr_plot_quickstart_003.png" />
</figure>
</section>
<section id="customize-plots-kind">
<h4>Customize Plots: <code class="code docutils literal notranslate"><span class="pre">kind</span></code><a class="headerlink" href="#customize-plots-kind" title="Permalink to this headline">#</a></h4>
<p>There are different types of charts (e.g. pie, bar, line) which can be defined by the <cite>kind</cite>
argument. Here is an example of a pie chart.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">metric_frame</span><span class="o">.</span><span class="n">by_group</span><span class="p">[[</span><span class="s2">&quot;count&quot;</span><span class="p">]]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
    <span class="n">kind</span><span class="o">=</span><span class="s2">&quot;pie&quot;</span><span class="p">,</span>
    <span class="n">subplots</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">layout</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
    <span class="n">legend</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">figsize</span><span class="o">=</span><span class="p">[</span><span class="mi">12</span><span class="p">,</span> <span class="mi">8</span><span class="p">],</span>
    <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Show count metric in pie chart&quot;</span><span class="p">,</span>
<span class="p">)</span>

</pre></div>
</div>
<figure class="align-center">
<img alt="../_images/sphx_glr_plot_quickstart_004.png" src="../_images/sphx_glr_plot_quickstart_004.png" />
</figure>
<p>There are many other customizations that can be done. More information can be found in
<a class="reference external" href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.plot.html#pandas.DataFrame.plot" title="(in pandas v1.4.3)"><code class="xref py py-meth docutils literal notranslate"><span class="pre">pandas.DataFrame.plot()</span></code></a>.</p>
<p>In order to save a plot, access the <a class="reference external" href="https://matplotlib.org/stable/api/figure_api.html#matplotlib.figure.Figure" title="(in Matplotlib v3.5.3)"><code class="xref py py-class docutils literal notranslate"><span class="pre">matplotlib.figure.Figure</span></code></a> as below and save it with your
desired filename.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span> <span class="o">=</span> <span class="n">metric_frame</span><span class="o">.</span><span class="n">by_group</span><span class="p">[[</span><span class="s2">&quot;count&quot;</span><span class="p">]]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
    <span class="n">kind</span><span class="o">=</span><span class="s2">&quot;pie&quot;</span><span class="p">,</span>
    <span class="n">subplots</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">layout</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
    <span class="n">legend</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">figsize</span><span class="o">=</span><span class="p">[</span><span class="mi">12</span><span class="p">,</span> <span class="mi">8</span><span class="p">],</span>
    <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Show count metric in pie chart&quot;</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">fig</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">figure</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s2">&quot;filename.png&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
</section>
<section id="fairlearn-dashboard">
<span id="dashboard"></span><h2>Fairlearn dashboard<a class="headerlink" href="#fairlearn-dashboard" title="Permalink to this headline">#</a></h2>
<p>The Fairlearn dashboard was a Jupyter notebook widget for assessing how a
model’s predictions impact different groups (e.g., different ethnicities), and
also for comparing multiple models along different fairness and performance
metrics.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The <code class="code docutils literal notranslate"><span class="pre">FairlearnDashboard</span></code> is no longer being developed as
part of Fairlearn.
For more information on how to use it refer to
<a class="reference external" href="https://github.com/microsoft/responsible-ai-widgets">https://github.com/microsoft/responsible-ai-widgets</a>.
Fairlearn provides some of the existing functionality through
<code class="code docutils literal notranslate"><span class="pre">matplotlib</span></code>-based visualizations. Refer to the <a class="reference internal" href="#plot"><span class="std std-ref">Plotting</span></a> section.</p>
</div>
</section>
<section id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this headline">#</a></h2>
<div class="docutils container" id="id11">
<dl class="footnote brackets">
<dt class="label" id="footcite-crenshaw1991intersectionality"><span class="brackets"><a class="fn-backref" href="#id1">1</a></span></dt>
<dd><p>Kimberlé Crenshaw. Mapping the margins: intersectionality, identity politics, and violence against women of color. <em>Stanford Law Review</em>, 43(6):1241–1299, 1991. URL: <a class="reference external" href="https://www.jstor.org/stable/1229039">https://www.jstor.org/stable/1229039</a>, <a class="reference external" href="https://arxiv.org/abs/https://www.jstor.org/stable/1229039">arXiv:https://www.jstor.org/stable/1229039</a>, <a class="reference external" href="https://doi.org/https://doi.org/10.2307/1229039">doi:https://doi.org/10.2307/1229039</a>.</p>
</dd>
<dt class="label" id="footcite-agarwal2018reductions"><span class="brackets">2</span><span class="fn-backref">(<a href="#id3">1</a>,<a href="#id8">2</a>)</span></dt>
<dd><p>Alekh Agarwal, Alina Beygelzimer, Miroslav Dudík, John Langford, and Hanna M. Wallach. A reductions approach to fair classification. In <em>ICML</em>, volume 80 of Proceedings of Machine Learning Research, 60–69. PMLR, 2018. URL: <a class="reference external" href="http://proceedings.mlr.press/v80/agarwal18a.html">http://proceedings.mlr.press/v80/agarwal18a.html</a>.</p>
</dd>
<dt class="label" id="footcite-agarwal2019fair"><span class="brackets"><a class="fn-backref" href="#id4">3</a></span></dt>
<dd><p>Alekh Agarwal, Miroslav Dudík, and Zhiwei Steven Wu. Fair regression: quantitative definitions and reduction-based algorithms. In <em>ICML</em>, volume 97 of Proceedings of Machine Learning Research, 120–129. PMLR, 2019. URL: <a class="reference external" href="http://proceedings.mlr.press/v97/agarwal19d.html">http://proceedings.mlr.press/v97/agarwal19d.html</a>.</p>
</dd>
<dt class="label" id="footcite-barocas2019fairness"><span class="brackets"><a class="fn-backref" href="#id5">4</a></span></dt>
<dd><p>Solon Barocas, Moritz Hardt, and Arvind Narayanan. <em>Fairness and Machine Learning</em>. fairmlbook.org, 2019. <a class="reference external" href="http://www.fairmlbook.org/">http://www.fairmlbook.org/</a>.</p>
</dd>
<dt class="label" id="footcite-bickel1975biasinadmissions"><span class="brackets"><a class="fn-backref" href="#id6">5</a></span></dt>
<dd><p>P.J. Bickel, E.A. Hammel, and E.W. and O’Connell. Sex bias in graduate admissions: data from berkeley. <em>Science</em>, 187(4175):398–404, 1975. URL: <a class="reference external" href="https://doi.org/10.1126%2Fscience.187.4175.398">https://doi.org/10.1126%2Fscience.187.4175.398</a>, <a class="reference external" href="https://doi.org/10.1126%2Fscience.187.4175.398">doi:10.1126%2Fscience.187.4175.398</a>.</p>
</dd>
<dt class="label" id="footcite-hardt2016equality"><span class="brackets"><a class="fn-backref" href="#id10">6</a></span></dt>
<dd><p>Moritz Hardt, Eric Price, and Nati Srebro. Equality of opportunity in supervised learning. In <em>NeurIPS</em>, 3315–3323. 2016. URL: <a class="reference external" href="https://proceedings.neurips.cc/paper/2016/hash/9d2682367c3935defcb1f9e247a97c0d-Abstract.html">https://proceedings.neurips.cc/paper/2016/hash/9d2682367c3935defcb1f9e247a97c0d-Abstract.html</a>.</p>
</dd>
</dl>
</div>
</section>
</section>


              </article>
              

              
          </div>
          
      </div>
    </div>

  
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=92025949c220c2e29695"></script>

<footer class="bd-footer"><div class="bd-footer__inner container">
  
  <div class="footer-item">
    <p class="copyright">
    &copy; Copyright 2018 - 2022, Fairlearn contributors.<br>
</p>
  </div>
  
  <div class="footer-item">
    <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 4.5.0.<br>
</p>
  </div>
  
</div>
</footer>
  </body>
</html>