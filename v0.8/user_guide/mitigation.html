
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Mitigation &#8212; Fairlearn 0.8.0 documentation</title>
<script>
  document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
  document.documentElement.dataset.theme = localStorage.getItem("theme") || "light"
</script>

  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=92025949c220c2e29695" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=92025949c220c2e29695" rel="stylesheet">


  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/custom.css" />

  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=92025949c220c2e29695">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script>window.MathJax = {"tex": {"macros": {"E": "{\\mathbb{E}}", "P": "{\\mathbb{P}}", "given": "\\mathbin{\\vert}"}}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Datasets" href="datasets/index.html" />
    <link rel="prev" title="Plotting" href="assessment/plotting.html" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta name="docsearch:language" content="None">
  </head>
  
  
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="180" data-default-mode="">
    <div class="bd-header-announcement container-fluid" id="banner">
      

    </div>

    
    <nav class="bd-header navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="bd-header__inner container-xl">

  <div id="navbar-start">
    
    
  
  


<a class="navbar-brand logo" href="../https%3A//fairlearn.org.html">
  
  
  
  
    <img src="../_static/fairlearn_full_color.svg" class="logo__image only-light" alt="Logo image">
    <img src="../_static/fairlearn_full_color.svg" class="logo__image only-dark" alt="Logo image">
  
  
</a>
    
    <div class="dropdown" id="version_switcher">
    <button type="button" class="btn btn-sm navbar-btn dropdown-toggle" id="version_switcher_button" data-toggle="dropdown">
        0.8.0  <!-- this text may get changed later by javascript -->
        <span class="caret"></span>
    </button>
    <div id="version_switcher_menu" class="dropdown-menu list-group-flush py-0" aria-labelledby="version_switcher_button">
    <!-- dropdown will be populated by javascript on page load -->
    </div>
</div>

<!-- NOTE: this JS must live here (not in our global JS file) because it relies
     on being processed by Jinja before it is run (specifically for replacing
     variables user_guide/mitigation and {'json_url': 'https://fairlearn.org/main/_static/versions.json', 'version_match': '0.8.0'}.
-->

<script type="text/javascript">
// Check if corresponding page path exists in other version of docs
// and, if so, go there instead of the homepage of the other docs version
function checkPageExistsAndRedirect(event) {
    const currentFilePath = "user_guide/mitigation.html",
          tryUrl = event.target.getAttribute("href");
    let otherDocsHomepage = tryUrl.replace(currentFilePath, "");
    $.ajax({
        type: 'HEAD',
        url: tryUrl,
        // if the page exists, go there
        success: function() {
            location.href = tryUrl;
        }
    }).fail(function() {
        location.href = otherDocsHomepage;
    });
    // this prevents the browser from following the href of the clicked node
    // (which is fine because this function takes care of redirecting)
    return false;
}

// Populate the version switcher from the JSON config file
(function () {
    $.getJSON("https://fairlearn.org/main/_static/versions.json", function(data, textStatus, jqXHR) {
        const currentFilePath = "user_guide/mitigation.html";
        let btn = document.getElementById("version_switcher_button");
        // Set empty strings by default so that these attributes exist and can be used in CSS selectors
        btn.dataset["activeVersionName"] = "";
        btn.dataset["activeVersion"] = "";
        // create links to the corresponding page in the other docs versions
        $.each(data, function(index, entry) {
            // if no custom name specified (e.g., "latest"), use version string
            if (!("name" in entry)) {
                entry.name = entry.version;
            }
            // create the node
            const node = document.createElement("a");
            node.setAttribute("class", "list-group-item list-group-item-action py-1");
            node.textContent = `${entry.name}`;
            node.setAttribute("href", `${entry.url}${currentFilePath}`);
            // on click, AJAX calls will check if the linked page exists before
            // trying to redirect, and if not, will redirect to the homepage
            // for that version of the docs.
            node.onclick = checkPageExistsAndRedirect;
            // Add dataset values for the version and name in case people want
            // to apply CSS styling based on this information.
            node.dataset["versionName"] = entry.name;
            node.dataset["version"] = entry.version;

            $("#version_switcher_menu").append(node);
            // replace dropdown button text with the preferred display name of
            // this version, rather than using sphinx's  variable.
            // also highlight the dropdown entry for the currently-viewed
            // version's entry
            if (entry.version == "0.8.0") {
                node.classList.add("active");
                btn.innerText = btn.dataset["activeVersionName"] = entry.name;
                btn.dataset["activeVersion"] = entry.version;
            }
        });
    });
})();
</script>
    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="fas fa-bars"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../quickstart.html">
  Get Started
 </a>
</li>

<li class="toctree-l1 current active nav-item">
 <a class="reference internal nav-link" href="index.html">
  User Guide
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../api_reference/index.html">
  API Docs
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../auto_examples/index.html">
  Example Notebooks
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../contributor_guide/index.html">
  Contributor Guide
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../faq.html">
  FAQ
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../about/index.html">
  About Us
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <span id="theme-switch" class="btn btn-sm btn-outline-primary navbar-btn rounded-circle">
    <a class="theme-switch" data-mode="light"><i class="fas fa-sun"></i></a>
    <a class="theme-switch" data-mode="dark"><i class="far fa-moon"></i></a>
    <a class="theme-switch" data-mode="auto"><i class="fas fa-adjust"></i></a>
</span>
      </div>
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/fairlearn/fairlearn" rel="noopener" target="_blank" title="GitHub"><span><i class="fab fa-github"></i></span>
            <label class="sr-only">GitHub</label></a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="https://twitter.com/fairlearn" rel="noopener" target="_blank" title="Twitter"><span><i class="fab fa-twitter"></i></span>
            <label class="sr-only">Twitter</label></a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="https://stackoverflow.com/questions/tagged/fairlearn" rel="noopener" target="_blank" title="StackOverflow"><span><i class="fab fa-stack-overflow"></i></span>
            <label class="sr-only">StackOverflow</label></a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="https://discord.gg/R22yCfgsRn" rel="noopener" target="_blank" title="Discord"><span><i class="fab fa-discord"></i></span>
            <label class="sr-only">Discord</label></a>
        </li>
      </ul>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="bd-container container-xl">
      <div class="bd-container__inner row">
          

<!-- Only show if we have sidebars configured, else just a small margin  -->
<div class="bd-sidebar-primary col-12 col-md-3 bd-sidebar">
  <div class="sidebar-start-items"><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="fairness_in_machine_learning.html">
   Fairness in Machine Learning
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="assessment/index.html">
   Assessment
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="assessment/perform_fairness_assessment.html">
     Performing a Fairness Assessment
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="assessment/common_fairness_metrics.html">
     Common fairness metrics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="assessment/custom_fairness_metrics.html">
     Defining custom fairness metrics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="assessment/intersecting_groups.html">
     Intersecting Groups
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="assessment/advanced_metricframe.html">
     Advanced Usage of MetricFrame
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="assessment/plotting.html">
     Plotting
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Mitigation
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="datasets/index.html">
   Datasets
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="datasets/adult_data.html">
     Adult Census Dataset
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
    <label for="toctree-checkbox-3">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="datasets/acs_income.html">
       ACSIncome
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="datasets/boston_housing_data.html">
     Revisiting the Boston Housing Dataset
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="datasets/diabetes_hospital_data.html">
     Diabetes 130-Hospitals Dataset
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="installation_and_version_guide/index.html">
   Installation and version guide
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="installation_and_version_guide/installation_guide.html">
     Installation Guide
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="installation_and_version_guide/version_guide.html">
     Version guide
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
    <label for="toctree-checkbox-5">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="installation_and_version_guide/v0.1.html">
       v0.1
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="installation_and_version_guide/v0.2.0.html">
       v0.2.0
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="installation_and_version_guide/v0.3.0.html">
       v0.3.0
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="installation_and_version_guide/v0.4.0.html">
       v0.4.0
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="installation_and_version_guide/v0.4.1.html">
       v0.4.1
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="installation_and_version_guide/v0.4.2.html">
       v0.4.2
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="installation_and_version_guide/v0.4.3.html">
       v0.4.3
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="installation_and_version_guide/v0.4.4.html">
       v0.4.4
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="installation_and_version_guide/v0.4.5.html">
       v0.4.5
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="installation_and_version_guide/v0.4.6.html">
       v0.4.6
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="installation_and_version_guide/v0.5.0.html">
       v0.5.0
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="installation_and_version_guide/v0.6.0.html">
       v0.6.0
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="installation_and_version_guide/v0.6.1.html">
       v0.6.1
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="installation_and_version_guide/v0.6.2.html">
       v0.6.2
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="installation_and_version_guide/v0.7.0.html">
       v0.7.0
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="installation_and_version_guide/v0.8.0.html">
       v0.8.0
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="further_resources.html">
   Further Resources
  </a>
 </li>
</ul>

  </div>
</nav>
  </div>
  <div class="sidebar-end-items">
  </div>
</div>


          


<div class="bd-sidebar-secondary d-none d-xl-block col-xl-2 bd-toc">
  
    
    <div class="toc-item">
      
<div class="tocsection onthispage mt-5 pt-1 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#preprocessing">
   Preprocessing
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#correlation-remover">
     Correlation Remover
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#postprocessing">
   Postprocessing
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#reductions">
   Reductions
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#fairness-constraints-for-binary-classification">
     Fairness constraints for binary classification
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#demographic-parity">
       Demographic Parity
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#true-positive-rate-parity-and-false-positive-rate-parity">
       True Positive Rate Parity and False Positive Rate Parity
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#equalized-odds">
       Equalized Odds
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#error-rate-parity">
       Error Rate Parity
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#control-features">
       Control features
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#fairness-constraints-for-multiclass-classification">
     Fairness constraints for multiclass classification
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#fairness-constraints-for-regression">
     Fairness constraints for regression
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#bounded-group-loss">
       Bounded Group Loss
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#exponentiated-gradient">
     Exponentiated Gradient
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#grid-search">
     Grid Search
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#adversarial-mitigation">
   Adversarial Mitigation
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#models">
     Models
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#data-types-and-loss-functions">
     Data types and loss functions
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#training">
     Training
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#example-1-basics-model-specification">
     Example 1: Basics &amp; model specification
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#example-2-finetuning-training">
     Example 2: Finetuning training
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#example-3-scikit-learn-applications">
     Example 3: Scikit-learn applications
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#references">
     References
    </a>
   </li>
  </ul>
 </li>
</ul>

</nav>
    </div>
    
    <div class="toc-item">
      
    </div>
    
  
</div>


          
          
          <div class="bd-content col-12 col-md-9 col-xl-7">
              
              <article class="bd-article" role="main">
                
  <section id="mitigation">
<span id="id1"></span><h1>Mitigation<a class="headerlink" href="#mitigation" title="Permalink to this headline">#</a></h1>
<p>Fairlearn contains the following algorithms for mitigating unfairness:</p>
<table class="colwidths-given table">
<colgroup>
<col style="width: 12%" />
<col style="width: 47%" />
<col style="width: 12%" />
<col style="width: 12%" />
<col style="width: 19%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head stub"><p>algorithm</p></th>
<th class="head"><p>description</p></th>
<th class="head"><p>binary classification</p></th>
<th class="head"><p>regression</p></th>
<th class="head"><p>supported fairness definitions</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><th class="stub"><p><a class="reference internal" href="../api_reference/fairlearn.reductions.html#fairlearn.reductions.ExponentiatedGradient" title="fairlearn.reductions.ExponentiatedGradient"><code class="xref py py-class docutils literal notranslate"><span class="pre">ExponentiatedGradient</span></code></a></p></th>
<td><p>A wrapper (reduction) approach to fair classification described in <em>A Reductions</em>
<em>Approach to Fair Classification</em> <a class="footnote-reference brackets" href="#footcite-agarwal2018reductions" id="id2">1</a>.</p></td>
<td><p>✔</p></td>
<td><p>✔</p></td>
<td><p>DP, EO, TPRP, FPRP, ERP, BGL</p></td>
</tr>
<tr class="row-odd"><th class="stub"><p><a class="reference internal" href="../api_reference/fairlearn.reductions.html#fairlearn.reductions.GridSearch" title="fairlearn.reductions.GridSearch"><code class="xref py py-class docutils literal notranslate"><span class="pre">GridSearch</span></code></a></p></th>
<td><p>A wrapper (reduction) approach described in Section 3.4 of <em>A Reductions</em>
<em>Approach to Fair Classification</em> <a class="footnote-reference brackets" href="#footcite-agarwal2018reductions" id="id3">1</a>. For regression it acts as a
grid-search variant of the algorithm described in Section 5 of
<em>Fair Regression: Quantitative Definitions and Reduction-based</em>
<em>Algorithms</em> <a class="footnote-reference brackets" href="#footcite-agarwal2019fair" id="id4">2</a>.</p></td>
<td><p>✔</p></td>
<td><p>✔</p></td>
<td><p>DP, EO, TPRP, FPRP, ERP, BGL</p></td>
</tr>
<tr class="row-even"><th class="stub"><p><a class="reference internal" href="../api_reference/fairlearn.postprocessing.html#fairlearn.postprocessing.ThresholdOptimizer" title="fairlearn.postprocessing.ThresholdOptimizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">ThresholdOptimizer</span></code></a></p></th>
<td><p>Postprocessing algorithm based on the paper <em>Equality of Opportunity</em>
<em>in Supervised Learning</em> <a class="footnote-reference brackets" href="#footcite-hardt2016equality" id="id5">3</a>. This technique takes as input an
existing classifier and the sensitive feature, and derives a monotone
transformation of the classifier’s prediction to enforce the specified
parity constraints.</p></td>
<td><p>✔</p></td>
<td><p>✘</p></td>
<td><p>DP, EO, TPRP, FPRP</p></td>
</tr>
<tr class="row-odd"><th class="stub"><p><a class="reference internal" href="../api_reference/fairlearn.preprocessing.html#fairlearn.preprocessing.CorrelationRemover" title="fairlearn.preprocessing.CorrelationRemover"><code class="xref py py-class docutils literal notranslate"><span class="pre">CorrelationRemover</span></code></a></p></th>
<td><p>Preprocessing algorithm that removes correlation between sensitive
features and non-sensitive features through linear transformations.</p></td>
<td><p>✔</p></td>
<td><p>✔</p></td>
<td><p>✘</p></td>
</tr>
<tr class="row-even"><th class="stub"><p><a class="reference internal" href="../api_reference/fairlearn.adversarial.html#fairlearn.adversarial.AdversarialFairnessClassifier" title="fairlearn.adversarial.AdversarialFairnessClassifier"><code class="xref py py-class docutils literal notranslate"><span class="pre">AdversarialFairnessClassifier</span></code></a></p></th>
<td><p>An optimization algorithm based on the paper <em>Mitigating Unwanted Biases</em>
<em>with Adversarial Learning</em> <a class="footnote-reference brackets" href="#footcite-zhang2018mitigating" id="id6">4</a>. This method trains a neural
network classifier that minimizes training error while
preventing an adversarial network from inferring sensitive features.
The neural networks can be defined either as a <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html">PyTorch module</a> or
<a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/keras/Model">TensorFlow2 model</a>.</p></td>
<td><p>✔</p></td>
<td><p>✘</p></td>
<td><p>DP, EO</p></td>
</tr>
<tr class="row-odd"><th class="stub"><p><a class="reference internal" href="../api_reference/fairlearn.adversarial.html#fairlearn.adversarial.AdversarialFairnessRegressor" title="fairlearn.adversarial.AdversarialFairnessRegressor"><code class="xref py py-class docutils literal notranslate"><span class="pre">AdversarialFairnessRegressor</span></code></a></p></th>
<td><p>The regressor variant of the above <a class="reference internal" href="../api_reference/fairlearn.adversarial.html#fairlearn.adversarial.AdversarialFairnessClassifier" title="fairlearn.adversarial.AdversarialFairnessClassifier"><code class="xref py py-class docutils literal notranslate"><span class="pre">AdversarialFairnessClassifier</span></code></a>.
Useful to train a neural network with continuous valued output(s).</p></td>
<td><p>✘</p></td>
<td><p>✔</p></td>
<td><p>DP, EO</p></td>
</tr>
</tbody>
</table>
<p>DP refers to <em>demographic parity</em>, EO to <em>equalized odds</em>, TPRP to <em>true positive
rate parity</em>, FPRP to <em>false positive rate parity</em>, ERP to <em>error rate parity</em>, and
BGL to <em>bounded group loss</em>. For
more information on the definitions refer to
<a class="reference internal" href="fairness_in_machine_learning.html#fairness-in-machine-learning"><span class="std std-ref">Fairness in Machine Learning</span></a>. To request additional algorithms or
fairness definitions, please open a
<a class="reference external" href="https://github.com/fairlearn/fairlearn/issues">new issue</a> on GitHub.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Fairlearn mitigation algorithms largely follow the
<a class="reference external" href="https://scikit-learn.org/stable/developers/contributing.html#different-objects">conventions of scikit-learn</a>,
meaning that they implement the <code class="code docutils literal notranslate"><span class="pre">fit</span></code> method to train a model and the <code class="code docutils literal notranslate"><span class="pre">predict</span></code> method
to make predictions. However, in contrast with
<a class="reference external" href="https://scikit-learn.org/stable/glossary.html#term-estimator">scikit-learn</a>,
Fairlearn algorithms can produce randomized predictors. Randomization of
predictions is required to satisfy many definitions of fairness. Because of
randomization, it is possible to get different outputs from the predictor’s
<code class="code docutils literal notranslate"><span class="pre">predict</span></code> method on identical data. For each of our algorithms, we provide
explicit access to the probability distribution used for randomization.</p>
</div>
<section id="preprocessing">
<span id="id7"></span><h2>Preprocessing<a class="headerlink" href="#preprocessing" title="Permalink to this headline">#</a></h2>
<p>Preprocessing algorithms transform the dataset to mitigate possible unfairness
present in the data.
Preprocessing algorithms in Fairlearn follow the <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.base.TransformerMixin.html#sklearn.base.TransformerMixin" title="(in scikit-learn v1.1)"><code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.base.TransformerMixin</span></code></a>
class, meaning that they can <code class="code docutils literal notranslate"><span class="pre">fit</span></code> to the dataset and <code class="code docutils literal notranslate"><span class="pre">transform</span></code> it
(or <code class="code docutils literal notranslate"><span class="pre">fit_transform</span></code> to fit and transform in one go).</p>
<section id="correlation-remover">
<span id="id8"></span><h3>Correlation Remover<a class="headerlink" href="#correlation-remover" title="Permalink to this headline">#</a></h3>
<p>Sensitive features can be correlated with non-sensitive features in the dataset.
By applying the <code class="code docutils literal notranslate"><span class="pre">CorrelationRemover</span></code>, these correlations are projected away
while details from the original data are retained as much as possible (as measured
by the least-squares error). The user can control the level of projection via the
<code class="code docutils literal notranslate"><span class="pre">alpha</span></code> parameter. In mathematical terms, assume we have the original dataset
<span class="math notranslate nohighlight">\(X\)</span> which contains a set of sensitive attributes <span class="math notranslate nohighlight">\(S\)</span> and a set of
non-sensitive attributes <span class="math notranslate nohighlight">\(Z\)</span>. The removal of correlation is then
described as:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\min _{\mathbf{z}_{1}, \ldots, \mathbf{z}_{n}} \sum_{i=1}^{n}\left\|\mathbf{z}_{i}
-\mathbf{x}_{i}\right\|^{2} \\
\text{subject to} \\
\frac{1}{n} \sum_{i=1}^{n} \mathbf{z}_{i}\left(\mathbf{s}_{i}-\overline{\mathbf{s}}
\right)^{T}=\mathbf{0}\end{split}\]</div>
<p>The solution to this problem is found by centering sensitive features, fitting a
linear regression model to the non-sensitive features and reporting the residual.
The columns in <span class="math notranslate nohighlight">\(S\)</span> will be dropped from the dataset <span class="math notranslate nohighlight">\(X\)</span>.
The amount of correlation that is removed can be controlled using the
<code class="code docutils literal notranslate"><span class="pre">alpha</span></code> parameter. This is described as follows:</p>
<div class="math notranslate nohighlight">
\[X_{\text{tfm}} = \alpha X_{\text{filtered}} + (1-\alpha) X_{\text{orig}}\]</div>
<p>Note that the lack of correlation does not imply anything about statistical dependence.
In particular, since correlation measures linear relationships, it might still be
possible that non-linear relationships exist in the data. Therefore, we expect this
to be most appropriate as a preprocessing step for (generalized) linear models.</p>
<p>In the example below, the <a class="reference external" href="https://www.openml.org/d/43874">Diabetes 130-Hospitals</a>
is loaded and the correlation between the African American race and
the non-sensitive features is removed. This dataset contains more races,
but in example we will only focus on the African American race.
The <code class="code docutils literal notranslate"><span class="pre">CorrelationRemover</span></code> will drop the sensitive features from the dataset.</p>
<div class="highlight-pycon3 notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">fairlearn.preprocessing</span> <span class="kn">import</span> <span class="n">CorrelationRemover</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">fetch_openml</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">fetch_openml</span><span class="p">(</span><span class="n">data_id</span><span class="o">=</span><span class="mi">43874</span><span class="p">,</span> <span class="n">as_frame</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">data</span><span class="p">[[</span><span class="s2">&quot;race&quot;</span><span class="p">,</span> <span class="s2">&quot;time_in_hospital&quot;</span><span class="p">,</span> <span class="s2">&quot;had_inpatient_days&quot;</span><span class="p">,</span> <span class="s2">&quot;medicare&quot;</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s2">&quot;race_Asian&quot;</span><span class="p">,</span>
<span class="gp">... </span>                    <span class="s2">&quot;race_Caucasian&quot;</span><span class="p">,</span>
<span class="gp">... </span>                    <span class="s2">&quot;race_Hispanic&quot;</span><span class="p">,</span>
<span class="gp">... </span>                    <span class="s2">&quot;race_Other&quot;</span><span class="p">,</span>
<span class="gp">... </span>                    <span class="s2">&quot;race_Unknown&quot;</span><span class="p">,</span>
<span class="gp">... </span>                    <span class="s2">&quot;had_inpatient_days_False&quot;</span><span class="p">,</span>
<span class="gp">... </span>                    <span class="s2">&quot;medicare_False&quot;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cr</span> <span class="o">=</span> <span class="n">CorrelationRemover</span><span class="p">(</span><span class="n">sensitive_feature_ids</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;race_AfricanAmerican&#39;</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cr</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="go">CorrelationRemover(sensitive_feature_ids=[&#39;race_AfricanAmerican&#39;])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_transform</span> <span class="o">=</span> <span class="n">cr</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
<p>In the visualization below, we see the correlation values in the
original dataset. We are particularly interested in the correlations
between the ‘race_AfricanAmerican’ column and the three non-sensitive attributes
‘time_in_hospital’, ‘had_inpatient_days’ and ‘medicare_True’. The target
variable is also included in these visualization for completeness, and it is
defined as a binary feature which indicated whether the readmission of a patient
occurred within 30 days of the release. We see that ‘race_AfricanAmerican’ is
not highly correlated with the three mentioned attributes, but we want to remove
these correlations nonetheless. The code for generating the correlation matrix
can be found in
<a class="reference external" href="../auto_examples/plot_correlationremover_before_after.html">this example notebook</a>.</p>
<figure class="align-center">
<a class="reference external image-reference" href="../auto_examples/plot_correlationremover_before_after.html"><img alt="../_images/sphx_glr_plot_correlationremover_before_after_001.png" src="../_images/sphx_glr_plot_correlationremover_before_after_001.png" /></a>
</figure>
<p>In order to see the effect of <a class="reference internal" href="../api_reference/fairlearn.preprocessing.html#fairlearn.preprocessing.CorrelationRemover" title="fairlearn.preprocessing.CorrelationRemover"><code class="xref py py-class docutils literal notranslate"><span class="pre">CorrelationRemover</span></code></a>, we visualize
how the correlation matrix has changed after the transformation of the
dataset. Due to rounding, some of the 0.0 values appear as -0.0. Either
way, the <code class="code docutils literal notranslate"><span class="pre">CorrelationRemover</span></code> successfully removed all correlation
between ‘race_AfricanAmerican’ and the other columns while retaining
the correlation between the other features.</p>
<figure class="align-center">
<a class="reference external image-reference" href="../auto_examples/plot_correlationremover_before_after.html"><img alt="../_images/sphx_glr_plot_correlationremover_before_after_002.png" src="../_images/sphx_glr_plot_correlationremover_before_after_002.png" /></a>
</figure>
<p>We can also use the <code class="code docutils literal notranslate"><span class="pre">alpha</span></code> parameter with for instance <span class="math notranslate nohighlight">\(\alpha=0.5\)</span>
to control the level of filtering between the sensitive and non-sensitive features.</p>
<div class="highlight-pycon3 notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">cr</span> <span class="o">=</span> <span class="n">CorrelationRemover</span><span class="p">(</span><span class="n">sensitive_feature_ids</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;race_AfricanAmerican&#39;</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cr</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="go">CorrelationRemover(alpha=0.5, sensitive_feature_ids=[&#39;race_AfricanAmerican&#39;])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_transform</span> <span class="o">=</span> <span class="n">cr</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
<p>As we can see in the visulization below, not all correlation between
‘race_AfricanAmerican’ and the other columns was removed. This is exactly what
we would expect with <span class="math notranslate nohighlight">\(\alpha=0.5\)</span>.</p>
<figure class="align-center">
<a class="reference external image-reference" href="../auto_examples/plot_correlationremover_before_after.html"><img alt="../_images/sphx_glr_plot_correlationremover_before_after_003.png" src="../_images/sphx_glr_plot_correlationremover_before_after_003.png" /></a>
</figure>
</section>
</section>
<section id="postprocessing">
<span id="id9"></span><h2>Postprocessing<a class="headerlink" href="#postprocessing" title="Permalink to this headline">#</a></h2>
</section>
<section id="reductions">
<span id="id10"></span><h2>Reductions<a class="headerlink" href="#reductions" title="Permalink to this headline">#</a></h2>
<p>On a high level, the reduction algorithms within Fairlearn
enable unfairness mitigation for an arbitrary machine learning model with
respect to user-provided fairness constraints. All of the constraints currently supported
by reduction algorithms are group-fairness constraints. For more information on the
supported fairness constraints refer to <a class="reference internal" href="#constraints-binary-classification"><span class="std std-ref">Fairness constraints for binary classification</span></a>
and <a class="reference internal" href="#constraints-regression"><span class="std std-ref">Fairness constraints for regression</span></a>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The choice of a fairness metric and fairness constraints is a crucial
step in the AI development and deployment, and
choosing an unsuitable constraint can lead to more harms.
For a broader discussion of fairness as a
sociotechnical challenge and how to view Fairlearn in this context refer to
<a class="reference internal" href="fairness_in_machine_learning.html#fairness-in-machine-learning"><span class="std std-ref">Fairness in Machine Learning</span></a>.</p>
</div>
<p>The reductions approach for classification seeks to reduce binary
classification subject to fairness constraints to a sequence of weighted
classification problems (see <a class="footnote-reference brackets" href="#footcite-agarwal2018reductions" id="id11">1</a>), and similarly for regression (see <a class="footnote-reference brackets" href="#footcite-agarwal2019fair" id="id12">2</a>).
As a result, the reduction algorithms
in Fairlearn only require a wrapper access to any “base” learning algorithm.
By this we mean that the “base” algorithm only needs to implement <code class="code docutils literal notranslate"><span class="pre">fit</span></code> and
<code class="code docutils literal notranslate"><span class="pre">predict</span></code> methods, as any standard scikit-learn estimator, but it
does not need to have any knowledge of the desired fairness constraints or sensitive features.</p>
<p>From an API perspective this looks as follows in all situations</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">reduction</span> <span class="o">=</span> <span class="n">Reduction</span><span class="p">(</span><span class="n">base_estimator</span><span class="p">,</span> <span class="n">constraints</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>  
<span class="gp">&gt;&gt;&gt; </span><span class="n">reduction</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">sensitive_features</span><span class="o">=</span><span class="n">sensitive_features</span><span class="p">)</span>  
<span class="gp">&gt;&gt;&gt; </span><span class="n">reduction</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>  
</pre></div>
</div>
<p>Fairlearn doesn’t impose restrictions on the referenced <code class="code docutils literal notranslate"><span class="pre">base_estimator</span></code>
other than the existence of <code class="code docutils literal notranslate"><span class="pre">fit</span></code> and <code class="code docutils literal notranslate"><span class="pre">predict</span></code> methods.
At the moment, the <code class="code docutils literal notranslate"><span class="pre">base_estimator</span></code>’s <code class="code docutils literal notranslate"><span class="pre">fit</span></code> method also needs to
provide a <code class="code docutils literal notranslate"><span class="pre">sample_weight</span></code> argument which the reductions techniques use
to reweight samples.
In the future Fairlearn will provide functionality to handle this even
without a <code class="code docutils literal notranslate"><span class="pre">sample_weight</span></code> argument.</p>
<p>Before looking more into reduction algorithms, this section
reviews the supported fairness constraints. All of them
are expressed as objects inheriting from the base class <code class="code docutils literal notranslate"><span class="pre">Moment</span></code>.
<code class="code docutils literal notranslate"><span class="pre">Moment</span></code>’s main purpose is to calculate the constraint violation of a
current set of predictions through its <code class="code docutils literal notranslate"><span class="pre">gamma</span></code> function as well as to
provide <code class="code docutils literal notranslate"><span class="pre">signed_weights</span></code> that are used to relabel and reweight samples.</p>
<section id="fairness-constraints-for-binary-classification">
<span id="constraints-binary-classification"></span><h3>Fairness constraints for binary classification<a class="headerlink" href="#fairness-constraints-for-binary-classification" title="Permalink to this headline">#</a></h3>
<p>All supported fairness constraints for binary classification inherit from
<code class="code docutils literal notranslate"><span class="pre">UtilityParity</span></code>. They are based on some underlying metric called
<em>utility</em>, which can be evaluated on individual data points and is averaged
over various groups of data points to form the <em>utility parity</em> constraint
of the form</p>
<div class="math notranslate nohighlight">
\[\text{utility}_{a,e} = \text{utility}_e \quad \forall a, e\]</div>
<p>where <span class="math notranslate nohighlight">\(a\)</span> is a sensitive feature value and <span class="math notranslate nohighlight">\(e\)</span> is an <em>event</em>
identifier. Each data point has only one value of a sensitive feature,
and belongs to at most one event. In many examples, there is only
a single event <span class="math notranslate nohighlight">\(*\)</span>, which includes all the data points. Other
examples of events include <span class="math notranslate nohighlight">\(Y=0\)</span> and <span class="math notranslate nohighlight">\(Y=1\)</span>. The utility
parity requires that the mean utility within each event equals
the mean utility of each group whose sensitive feature is <span class="math notranslate nohighlight">\(a\)</span>
within that event.</p>
<p>The class <code class="code docutils literal notranslate"><span class="pre">UtilityParity</span></code> implements constraints that allow
some amount of violation of the utility parity constraints, where
the maximum allowed violation is specified either as a difference
or a ratio.</p>
<p>The <em>difference-based relaxation</em> starts out by representing
the utility parity constraints as pairs of
inequalities</p>
<div class="math notranslate nohighlight">
\[\begin{split}\text{utility}_{a,e} - \text{utility}_{e} \leq 0 \quad \forall a, e\\
-\text{utility}_{a,e} + \text{utility}_{e} \leq 0 \quad \forall a, e\end{split}\]</div>
<p>and then replaces zero on the right-hand side
with a value specified as <code class="code docutils literal notranslate"><span class="pre">difference_bound</span></code>. The resulting
constraints are instantiated as</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">UtilityParity</span><span class="p">(</span><span class="n">difference_bound</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>  
</pre></div>
</div>
<p>Note that satisfying these constraints does not mean
that the difference between the groups with the highest and
smallest utility in each event is bounded by <code class="code docutils literal notranslate"><span class="pre">difference_bound</span></code>.
The value of <code class="code docutils literal notranslate"><span class="pre">difference_bound</span></code> instead bounds
the difference between the utility of each group and the overall mean
utility within each event. This, however,
implies that the difference between groups in each event is
at most twice the value of <code class="code docutils literal notranslate"><span class="pre">difference_bound</span></code>.</p>
<p>The <em>ratio-based relaxation</em> relaxes the parity
constraint as</p>
<div class="math notranslate nohighlight">
\[r \leq \dfrac{\text{utility}_{a,e}}{\text{utility}_e} \leq \dfrac{1}{r} \quad \forall a, e\]</div>
<p>for some value of <span class="math notranslate nohighlight">\(r\)</span> in (0,1]. For example, if <span class="math notranslate nohighlight">\(r=0.9\)</span>, this means
that within each event
<span class="math notranslate nohighlight">\(0.9 \cdot \text{utility}_{a,e} \leq \text{utility}_e\)</span>, i.e., the utility for
each group needs to be at least 90% of the overall utility for the event, and
<span class="math notranslate nohighlight">\(0.9 \cdot \text{utility}_e \leq \text{utility}_{a,e}\)</span>, i.e., the overall utility
for the event needs to be at least 90% of each group’s utility.</p>
<p>The two ratio constraints can be rewritten as</p>
<div class="math notranslate nohighlight">
\[\begin{split}- \text{utility}_{a,e} + r \cdot \text{utility}_e \leq 0 \quad \forall a, e \\
r \cdot \text{utility}_{a,e} - \text{utility}_e \leq 0 \quad \forall a, e\end{split}\]</div>
<p>When instantiating the ratio constraints, we use <code class="code docutils literal notranslate"><span class="pre">ratio_bound</span></code> for <span class="math notranslate nohighlight">\(r\)</span>,
and also allow further relaxation by replacing the zeros on the right hand side
by some non-negative <code class="code docutils literal notranslate"><span class="pre">ratio_bound_slack</span></code>. The resulting instantiation
looks as</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">UtilityParity</span><span class="p">(</span><span class="n">ratio_bound</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">ratio_bound_slack</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>  
</pre></div>
</div>
<p>Similarly to the difference constraints, the ratio constraints do not directly
bound the ratio between the pairs of groups, but such a bound is implied.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>It is not possible to specify both <code class="code docutils literal notranslate"><span class="pre">difference_bound</span></code> <em>and</em>
<code class="code docutils literal notranslate"><span class="pre">ratio_bound</span></code> for the same constraint object.</p>
</div>
<section id="demographic-parity">
<span id="id13"></span><h4>Demographic Parity<a class="headerlink" href="#demographic-parity" title="Permalink to this headline">#</a></h4>
<p>A binary classifier <span class="math notranslate nohighlight">\(h(X)\)</span> satisfies <em>demographic parity</em> if</p>
<div class="math notranslate nohighlight">
\[\P[h(X) = 1 \given A = a] = \P[h(X) = 1] \quad \forall a\]</div>
<p>In other words, the selection rate or percentage of samples with label 1
should be equal across all groups. Implicitly this means the percentage
with label 0 is equal as well. In this case, the utility function
is equal to <span class="math notranslate nohighlight">\(h(X)\)</span> and there is only a single event <span class="math notranslate nohighlight">\(*\)</span>.</p>
<p>In the example below group <code class="code docutils literal notranslate"><span class="pre">&quot;a&quot;</span></code> has a selection rate of 60%,
<code class="code docutils literal notranslate"><span class="pre">&quot;b&quot;</span></code> has a selection rate of 20%. The overall selection rate is 40%,
so <code class="code docutils literal notranslate"><span class="pre">&quot;a&quot;</span></code> is <cite>0.2</cite> above the overall selection rate, and <code class="code docutils literal notranslate"><span class="pre">&quot;b&quot;</span></code> is
<cite>0.2</cite> below. Invoking the method <code class="code docutils literal notranslate"><span class="pre">gamma</span></code> shows the values
of the left-hand sides of the constraints described
in <a class="reference internal" href="#constraints-binary-classification"><span class="std std-ref">Fairness constraints for binary classification</span></a>, which is independent
of the provided <code class="code docutils literal notranslate"><span class="pre">difference_bound</span></code>. Note that the left-hand sides
corresponding to different values of <code class="code docutils literal notranslate"><span class="pre">sign</span></code> are just negatives
of each other.
The value of <code class="code docutils literal notranslate"><span class="pre">y_true</span></code> is in this example irrelevant to the calculations,
because the underlying utility in demographic parity, selection rate, does not
consider performance relative to the true labels, but rather proportions in
the predicted labels.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>When providing <code class="code docutils literal notranslate"><span class="pre">DemographicParity</span></code> to mitigation algorithms, only use
the constructor and the mitigation algorithm itself then invokes <code class="code docutils literal notranslate"><span class="pre">load_data</span></code>.
The example below uses <code class="code docutils literal notranslate"><span class="pre">load_data</span></code> to illustrate how <code class="code docutils literal notranslate"><span class="pre">DemographicParity</span></code>
instantiates inequalities from <a class="reference internal" href="#constraints-binary-classification"><span class="std std-ref">Fairness constraints for binary classification</span></a>.</p>
</div>
<div class="highlight-pycon3 notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">fairlearn.reductions</span> <span class="kn">import</span> <span class="n">DemographicParity</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">fairlearn.metrics</span> <span class="kn">import</span> <span class="n">MetricFrame</span><span class="p">,</span> <span class="n">selection_rate</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dp</span> <span class="o">=</span> <span class="n">DemographicParity</span><span class="p">(</span><span class="n">difference_bound</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span>                  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="mi">6</span><span class="p">],</span> <span class="p">[</span><span class="mi">7</span><span class="p">],</span> <span class="p">[</span><span class="mi">8</span><span class="p">],</span> <span class="p">[</span><span class="mi">9</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span>             <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span> <span class="mi">1</span> <span class="p">,</span>  <span class="mi">1</span> <span class="p">,</span>  <span class="mi">1</span> <span class="p">,</span>  <span class="mi">1</span> <span class="p">,</span>  <span class="mi">0</span><span class="p">,</span>   <span class="mi">0</span> <span class="p">,</span>  <span class="mi">0</span> <span class="p">,</span>  <span class="mi">0</span> <span class="p">,</span>  <span class="mi">0</span> <span class="p">,</span>  <span class="mi">0</span> <span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span>             <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span> <span class="mi">1</span> <span class="p">,</span>  <span class="mi">1</span> <span class="p">,</span>  <span class="mi">1</span> <span class="p">,</span>  <span class="mi">1</span> <span class="p">,</span>  <span class="mi">0</span><span class="p">,</span>   <span class="mi">0</span> <span class="p">,</span>  <span class="mi">0</span> <span class="p">,</span>  <span class="mi">0</span> <span class="p">,</span>  <span class="mi">0</span> <span class="p">,</span>  <span class="mi">0</span> <span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sensitive_features</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">selection_rate_summary</span> <span class="o">=</span> <span class="n">MetricFrame</span><span class="p">(</span><span class="n">metrics</span><span class="o">=</span><span class="n">selection_rate</span><span class="p">,</span>
<span class="gp">... </span>                                     <span class="n">y_true</span><span class="o">=</span><span class="n">y_true</span><span class="p">,</span>
<span class="gp">... </span>                                     <span class="n">y_pred</span><span class="o">=</span><span class="n">y_pred</span><span class="p">,</span>
<span class="gp">... </span>                                     <span class="n">sensitive_features</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">sensitive_features</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;SF 0&quot;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">selection_rate_summary</span><span class="o">.</span><span class="n">overall</span>
<span class="go">    0.4</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">selection_rate_summary</span><span class="o">.</span><span class="n">by_group</span>
<span class="go">SF 0</span>
<span class="go">a    0.6</span>
<span class="go">b    0.2</span>
<span class="go">Name: selection_rate, dtype: float64</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dp</span><span class="o">.</span><span class="n">load_data</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y_true</span><span class="p">,</span> <span class="n">sensitive_features</span><span class="o">=</span><span class="n">sensitive_features</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dp</span><span class="o">.</span><span class="n">gamma</span><span class="p">(</span><span class="k">lambda</span> <span class="n">X</span><span class="p">:</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="go">sign  event  group_id</span>
<span class="go">+     all    a           0.2</span>
<span class="go">             b          -0.2</span>
<span class="go">-     all    a          -0.2</span>
<span class="go">             b           0.2</span>
<span class="go">dtype: float64</span>
</pre></div>
</div>
<p>The ratio constraints for the demographic parity with <code class="code docutils literal notranslate"><span class="pre">ratio_bound</span></code>
<span class="math notranslate nohighlight">\(r\)</span> (and <code class="code docutils literal notranslate"><span class="pre">ratio_bound_slack=0</span></code>) take form</p>
<div class="math notranslate nohighlight">
\[r \leq \dfrac{\P[h(X) = 1 \given A = a]}{\P[h(X) = 1]} \leq \dfrac{1}{r} \quad \forall a\]</div>
<p>Revisiting the same example as above we get</p>
<div class="highlight-pycon3 notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">dp</span> <span class="o">=</span> <span class="n">DemographicParity</span><span class="p">(</span><span class="n">ratio_bound</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">ratio_bound_slack</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dp</span><span class="o">.</span><span class="n">load_data</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">sensitive_features</span><span class="o">=</span><span class="n">sensitive_features</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dp</span><span class="o">.</span><span class="n">gamma</span><span class="p">(</span><span class="k">lambda</span> <span class="n">X</span><span class="p">:</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="go">sign  event  group_id</span>
<span class="go">+     all    a           0.14</span>
<span class="go">             b          -0.22</span>
<span class="go">-     all    a          -0.24</span>
<span class="go">             b           0.16</span>
<span class="go">dtype: float64</span>
</pre></div>
</div>
<p>Following the expressions for the left-hand sides
of the constraints, we obtain</p>
<div class="math notranslate nohighlight">
\[\begin{split}r \cdot \text{utility}_{a,*} - \text{utility}_* = 0.9 \times 0.6 - 0.4 = 0.14 \\
r \cdot \text{utility}_{b,*} - \text{utility}_* = 0.9 \times 0.2 - 0.4 = -0.22 \\
- \text{utility}_{a,*} + r \cdot \text{utility}_* = - 0.6 + 0.9 \times 0.4 = -0.24 \\
- \text{utility}_{b,*} + r \cdot \text{utility}_* = - 0.2 + 0.9 \times 0.4 = 0.16 \\\end{split}\]</div>
</section>
<section id="true-positive-rate-parity-and-false-positive-rate-parity">
<span id="false-positive-rate-parity"></span><span id="true-positive-rate-parity"></span><h4>True Positive Rate Parity and False Positive Rate Parity<a class="headerlink" href="#true-positive-rate-parity-and-false-positive-rate-parity" title="Permalink to this headline">#</a></h4>
<p>A binary classifier <span class="math notranslate nohighlight">\(h(X)\)</span> satisfies <em>true positive rate parity</em> if</p>
<div class="math notranslate nohighlight">
\[\P[h(X) = 1 \given A = a, Y = 1] = \P[h(X) = 1 \given Y = 1] \quad \forall a\]</div>
<p>and <em>false positive rate parity</em> if</p>
<div class="math notranslate nohighlight">
\[\P[h(X) = 1 \given A = a, Y = 0] = \P[h(X) = 1 \given Y = 0] \quad \forall a\]</div>
<p>In first case, we only have one event <span class="math notranslate nohighlight">\(Y=1\)</span> and
ignore the samples with <span class="math notranslate nohighlight">\(Y=0\)</span>, and in the second case vice versa.
Refer to <a class="reference internal" href="#equalized-odds"><span class="std std-ref">Equalized Odds</span></a> for the fairness constraint type that simultaneously
enforce both true positive rate parity and false positive rate parity
by considering both events <span class="math notranslate nohighlight">\(Y=0\)</span> and <span class="math notranslate nohighlight">\(Y=1\)</span>.</p>
<p>In practice this can be used in a difference-based relaxation as follows:</p>
<div class="highlight-pycon3 notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">fairlearn.reductions</span> <span class="kn">import</span> <span class="n">TruePositiveRateParity</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">fairlearn.metrics</span> <span class="kn">import</span> <span class="n">true_positive_rate</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tprp</span> <span class="o">=</span> <span class="n">TruePositiveRateParity</span><span class="p">(</span><span class="n">difference_bound</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span>                  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="mi">6</span><span class="p">],</span> <span class="p">[</span><span class="mi">7</span><span class="p">],</span> <span class="p">[</span><span class="mi">8</span><span class="p">],</span> <span class="p">[</span><span class="mi">9</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span>             <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span> <span class="mi">1</span> <span class="p">,</span>  <span class="mi">1</span> <span class="p">,</span>  <span class="mi">1</span> <span class="p">,</span>  <span class="mi">1</span> <span class="p">,</span>  <span class="mi">1</span><span class="p">,</span>   <span class="mi">1</span> <span class="p">,</span>  <span class="mi">1</span> <span class="p">,</span>  <span class="mi">0</span> <span class="p">,</span>  <span class="mi">0</span> <span class="p">,</span>  <span class="mi">0</span> <span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span>             <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span> <span class="mi">1</span> <span class="p">,</span>  <span class="mi">1</span> <span class="p">,</span>  <span class="mi">1</span> <span class="p">,</span>  <span class="mi">1</span> <span class="p">,</span>  <span class="mi">0</span><span class="p">,</span>   <span class="mi">0</span> <span class="p">,</span>  <span class="mi">0</span> <span class="p">,</span>  <span class="mi">1</span> <span class="p">,</span>  <span class="mi">0</span> <span class="p">,</span>  <span class="mi">0</span> <span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sensitive_features</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tpr_summary</span> <span class="o">=</span> <span class="n">MetricFrame</span><span class="p">(</span><span class="n">metrics</span><span class="o">=</span><span class="n">true_positive_rate</span><span class="p">,</span>
<span class="gp">... </span>                          <span class="n">y_true</span><span class="o">=</span><span class="n">y_true</span><span class="p">,</span>
<span class="gp">... </span>                          <span class="n">y_pred</span><span class="o">=</span><span class="n">y_pred</span><span class="p">,</span>
<span class="gp">... </span>                          <span class="n">sensitive_features</span><span class="o">=</span><span class="n">sensitive_features</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tpr_summary</span><span class="o">.</span><span class="n">overall</span>
<span class="go">0.5714285714285714</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tpr_summary</span><span class="o">.</span><span class="n">by_group</span>
<span class="go">sensitive_feature_0</span>
<span class="go">a    0.75...</span>
<span class="go">b    0.33...</span>
<span class="go">Name: true_positive_rate, dtype: float64</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tprp</span><span class="o">.</span><span class="n">load_data</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y_true</span><span class="p">,</span> <span class="n">sensitive_features</span><span class="o">=</span><span class="n">sensitive_features</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tprp</span><span class="o">.</span><span class="n">gamma</span><span class="p">(</span><span class="k">lambda</span> <span class="n">X</span><span class="p">:</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="go">sign  event    group_id</span>
<span class="go">+     label=1  a           0.1785...</span>
<span class="go">               b          -0.2380...</span>
<span class="go">-     label=1  a          -0.1785...</span>
<span class="go">               b           0.2380...</span>
<span class="go">dtype: float64</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>When providing <code class="code docutils literal notranslate"><span class="pre">TruePositiveRateParity</span></code> or <code class="code docutils literal notranslate"><span class="pre">FalsePositiveRateParity</span></code>
to mitigation algorithms, only use
the constructor. The mitigation algorithm itself then invokes <code class="code docutils literal notranslate"><span class="pre">load_data</span></code>.
The example uses <code class="code docutils literal notranslate"><span class="pre">load_data</span></code> to illustrate how <code class="code docutils literal notranslate"><span class="pre">TruePositiveRateParity</span></code>
instantiates inequalities from <a class="reference internal" href="#constraints-binary-classification"><span class="std std-ref">Fairness constraints for binary classification</span></a>.</p>
</div>
<p>Alternatively, a ratio-based relaxation is also available:</p>
<div class="highlight-pycon3 notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">tprp</span> <span class="o">=</span> <span class="n">TruePositiveRateParity</span><span class="p">(</span><span class="n">ratio_bound</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">ratio_bound_slack</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tprp</span><span class="o">.</span><span class="n">load_data</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y_true</span><span class="p">,</span> <span class="n">sensitive_features</span><span class="o">=</span><span class="n">sensitive_features</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tprp</span><span class="o">.</span><span class="n">gamma</span><span class="p">(</span><span class="k">lambda</span> <span class="n">X</span><span class="p">:</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="go">sign  event    group_id</span>
<span class="go">+     label=1  a           0.1035...</span>
<span class="go">               b          -0.2714...</span>
<span class="go">-     label=1  a          -0.2357...</span>
<span class="go">               b           0.1809...</span>
<span class="go">dtype: float64</span>
</pre></div>
</div>
</section>
<section id="equalized-odds">
<span id="id14"></span><h4>Equalized Odds<a class="headerlink" href="#equalized-odds" title="Permalink to this headline">#</a></h4>
<p>A binary classifier <span class="math notranslate nohighlight">\(h(X)\)</span> satisfies <em>equalized odds</em> if it satisfies both
<em>true positive rate parity</em> and <em>false positive rate parity</em>, i.e.,</p>
<div class="math notranslate nohighlight">
\[\P[h(X) = 1 \given A = a, Y = y] = \P[h(X) = 1 \given Y = y] \quad \forall a, y\]</div>
<p>The constraints represent the union of constraints for true positive rate
and false positive rate.</p>
<div class="highlight-pycon3 notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">fairlearn.reductions</span> <span class="kn">import</span> <span class="n">EqualizedOdds</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">eo</span> <span class="o">=</span> <span class="n">EqualizedOdds</span><span class="p">(</span><span class="n">difference_bound</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">eo</span><span class="o">.</span><span class="n">load_data</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y_true</span><span class="p">,</span> <span class="n">sensitive_features</span><span class="o">=</span><span class="n">sensitive_features</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">eo</span><span class="o">.</span><span class="n">gamma</span><span class="p">(</span><span class="k">lambda</span> <span class="n">X</span><span class="p">:</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="go">sign  event    group_id</span>
<span class="go">+     label=0  a          -0.3333...</span>
<span class="go">               b           0.1666...</span>
<span class="go">      label=1  a           0.1785...</span>
<span class="go">               b          -0.2380...</span>
<span class="go">-     label=0  a           0.3333...</span>
<span class="go">               b          -0.1666...</span>
<span class="go">      label=1  a          -0.1785...</span>
<span class="go">               b           0.2380...</span>
<span class="go">dtype: float64</span>
</pre></div>
</div>
</section>
<section id="error-rate-parity">
<span id="id15"></span><h4>Error Rate Parity<a class="headerlink" href="#error-rate-parity" title="Permalink to this headline">#</a></h4>
<p>The <em>error rate parity</em> requires that the error rates should be
the same across all groups. For a classifier <span class="math notranslate nohighlight">\(h(X)\)</span>
this means that</p>
<div class="math notranslate nohighlight">
\[\P[h(X) \ne Y \given A = a] = \P[h(X) \ne Y] \quad \forall a\]</div>
<p>In this case, the utility is equal to 1 if <span class="math notranslate nohighlight">\(h(X)\ne Y\)</span> and equal to
0 if <span class="math notranslate nohighlight">\(h(X)=Y\)</span>, and so large value of utility here actually correspond
to poor outcomes. The difference-based relaxation specifies that
the error rate of any given group should not deviate from
the overall error rate by more than the value of <code class="code docutils literal notranslate"><span class="pre">difference_bound</span></code>.</p>
<div class="highlight-pycon3 notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">fairlearn.reductions</span> <span class="kn">import</span> <span class="n">ErrorRateParity</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">accuracy_summary</span> <span class="o">=</span> <span class="n">MetricFrame</span><span class="p">(</span><span class="n">metrics</span><span class="o">=</span><span class="n">accuracy_score</span><span class="p">,</span>
<span class="gp">... </span>                               <span class="n">y_true</span><span class="o">=</span><span class="n">y_true</span><span class="p">,</span>
<span class="gp">... </span>                               <span class="n">y_pred</span><span class="o">=</span><span class="n">y_pred</span><span class="p">,</span>
<span class="gp">... </span>                               <span class="n">sensitive_features</span><span class="o">=</span><span class="n">sensitive_features</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">accuracy_summary</span><span class="o">.</span><span class="n">overall</span>
<span class="go">0.6</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">accuracy_summary</span><span class="o">.</span><span class="n">by_group</span>
<span class="go">sensitive_feature_0</span>
<span class="go">a    0.8</span>
<span class="go">b    0.4</span>
<span class="go">Name: accuracy_score, dtype: float64</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">erp</span> <span class="o">=</span> <span class="n">ErrorRateParity</span><span class="p">(</span><span class="n">difference_bound</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">erp</span><span class="o">.</span><span class="n">load_data</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y_true</span><span class="p">,</span> <span class="n">sensitive_features</span><span class="o">=</span><span class="n">sensitive_features</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">erp</span><span class="o">.</span><span class="n">gamma</span><span class="p">(</span><span class="k">lambda</span> <span class="n">X</span><span class="p">:</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="go">sign  event  group_id</span>
<span class="go">+     all    a          -0.2</span>
<span class="go">             b           0.2</span>
<span class="go">-     all    a           0.2</span>
<span class="go">             b          -0.2</span>
<span class="go">dtype: float64</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>When providing <code class="code docutils literal notranslate"><span class="pre">ErrorRateParity</span></code> to mitigation algorithms, only use
the constructor. The mitigation algorithm itself then invokes <code class="code docutils literal notranslate"><span class="pre">load_data</span></code>.
The example uses <code class="code docutils literal notranslate"><span class="pre">load_data</span></code> to illustrate how <code class="code docutils literal notranslate"><span class="pre">ErrorRateParity</span></code>
instantiates inequalities from <a class="reference internal" href="#constraints-binary-classification"><span class="std std-ref">Fairness constraints for binary classification</span></a>.</p>
</div>
<p>Alternatively, error rate parity can be relaxed via ratio constraints as</p>
<div class="math notranslate nohighlight">
\[r \leq \dfrac{\P[h(X) \ne Y \given A = a]}{\P[h(X) \ne Y]} \leq \dfrac{1}{r} \quad \forall a\]</div>
<p>with a <code class="code docutils literal notranslate"><span class="pre">ratio_bound</span></code> <span class="math notranslate nohighlight">\(r\)</span>. The usage is identical with other
constraints:</p>
<div class="highlight-pycon3 notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">fairlearn.reductions</span> <span class="kn">import</span> <span class="n">ErrorRateParity</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">erp</span> <span class="o">=</span> <span class="n">ErrorRateParity</span><span class="p">(</span><span class="n">ratio_bound</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">ratio_bound_slack</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">erp</span><span class="o">.</span><span class="n">load_data</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y_true</span><span class="p">,</span> <span class="n">sensitive_features</span><span class="o">=</span><span class="n">sensitive_features</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">erp</span><span class="o">.</span><span class="n">gamma</span><span class="p">(</span><span class="k">lambda</span> <span class="n">X</span><span class="p">:</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="go">sign  event  group_id</span>
<span class="go">+     all    a          -0.22</span>
<span class="go">             b           0.14</span>
<span class="go">-     all    a           0.16</span>
<span class="go">             b          -0.24</span>
<span class="go">dtype: float64</span>
</pre></div>
</div>
</section>
<section id="control-features">
<h4>Control features<a class="headerlink" href="#control-features" title="Permalink to this headline">#</a></h4>
<p>The above examples of <a class="reference internal" href="../api_reference/fairlearn.reductions.html#fairlearn.reductions.Moment" title="fairlearn.reductions.Moment"><code class="xref py py-class docutils literal notranslate"><span class="pre">Moment</span></code></a> (<a class="reference internal" href="#demographic-parity"><span class="std std-ref">Demographic Parity</span></a>,
<a class="reference internal" href="#true-positive-rate-parity"><span class="std std-ref">True and False Positive Rate Parity</span></a>,
<a class="reference internal" href="#equalized-odds"><span class="std std-ref">Equalized Odds</span></a> and <a class="reference internal" href="#error-rate-parity"><span class="std std-ref">Error Rate Parity</span></a>) all support the concept
of <em>control features</em> when applying their fairness constraints.
A control feature stratifies the dataset, and applies the fairness constraint
within each stratum, but not between strata.
One case this might be useful is a loan scenario, where we might want
to apply a mitigation for the sensitive features while controlling for some
other feature(s).
This should be done with caution, since the control features may have a
correlation with the sensitive features due to historical biases.
In the loan scenario, we might choose to control for income level, on the
grounds that higher income individuals are more likely to be able to repay
a loan.
However, due to historical bias, there is a correlation between the income level
of individuals and their race and gender.</p>
<p>Control features modify the above equations.
Consider a control feature value, drawn from a set of valid values
(that is, <span class="math notranslate nohighlight">\(c \in \mathcal{C}\)</span>).
The equation given above for Demographic Parity will become:</p>
<div class="math notranslate nohighlight">
\[P[h(X) = 1 | A = a, C = c] = P[h(X) = 1 | C = c] \; \forall a, c\]</div>
<p>The other constraints acquire similar modifications.</p>
</section>
</section>
<section id="fairness-constraints-for-multiclass-classification">
<span id="constraints-multi-class-classification"></span><h3>Fairness constraints for multiclass classification<a class="headerlink" href="#fairness-constraints-for-multiclass-classification" title="Permalink to this headline">#</a></h3>
<p>Reductions approaches do not support multiclass classification yet at this
point. If this is an important scenario for you please let us know!</p>
</section>
<section id="fairness-constraints-for-regression">
<span id="constraints-regression"></span><h3>Fairness constraints for regression<a class="headerlink" href="#fairness-constraints-for-regression" title="Permalink to this headline">#</a></h3>
<p>The performance objective in the regression scenario is to minimize the
loss of our regressor <span class="math notranslate nohighlight">\(h\)</span>. The loss can be expressed as
<a class="reference internal" href="../api_reference/fairlearn.reductions.html#fairlearn.reductions.SquareLoss" title="fairlearn.reductions.SquareLoss"><code class="xref py py-class docutils literal notranslate"><span class="pre">SquareLoss</span></code></a> or <a class="reference internal" href="../api_reference/fairlearn.reductions.html#fairlearn.reductions.AbsoluteLoss" title="fairlearn.reductions.AbsoluteLoss"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbsoluteLoss</span></code></a>. Both take constructor arguments
<code class="code docutils literal notranslate"><span class="pre">min_val</span></code> and <code class="code docutils literal notranslate"><span class="pre">max_val</span></code> that define the value range within which
the loss is evaluated. Values outside of the value range get clipped.</p>
<div class="highlight-pycon3 notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">fairlearn.reductions</span> <span class="kn">import</span> <span class="n">SquareLoss</span><span class="p">,</span> <span class="n">AbsoluteLoss</span><span class="p">,</span> <span class="n">ZeroOneLoss</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span>   <span class="mf">0.3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span>   <span class="mf">0.9</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">,</span> <span class="mf">1.3</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">SquareLoss</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="go">array([0.01, 0.01, 0.01, 0.16])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># clipping at 1 reduces the error for the fourth entry</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">SquareLoss</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="go">array([0.01, 0.01, 0.01, 0.01])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">AbsoluteLoss</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="go">array([0.1, 0.1, 0.1, 0.4])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">AbsoluteLoss</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="go">array([0.1, 0.1, 0.1, 0.1])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># ZeroOneLoss is identical to AbsoluteLoss(0, 1)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ZeroOneLoss</span><span class="p">()</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="go">array([0.1, 0.1, 0.1, 0.1])</span>
</pre></div>
</div>
<p>When using Fairlearn’s reduction techniques for regression it’s required to
specify the type of loss by passing the corresponding loss object when
instantiating the object that represents our fairness constraint. The only
supported type of constraint at this point is <a class="reference internal" href="../api_reference/fairlearn.reductions.html#fairlearn.reductions.BoundedGroupLoss" title="fairlearn.reductions.BoundedGroupLoss"><code class="xref py py-class docutils literal notranslate"><span class="pre">BoundedGroupLoss</span></code></a>.</p>
<section id="bounded-group-loss">
<span id="id16"></span><h4>Bounded Group Loss<a class="headerlink" href="#bounded-group-loss" title="Permalink to this headline">#</a></h4>
<p><em>Bounded group loss</em> requires the loss of each group to be below a
user-specified amount <span class="math notranslate nohighlight">\(\zeta\)</span>. If <span class="math notranslate nohighlight">\(\zeta\)</span> is chosen reasonably
small the losses of all groups are very similar.
Formally, a predictor <span class="math notranslate nohighlight">\(h\)</span> satisfies bounded group loss at level
<span class="math notranslate nohighlight">\(\zeta\)</span> under a distribution over <span class="math notranslate nohighlight">\((X, A, Y)\)</span> if</p>
<div class="math notranslate nohighlight">
\[\E[loss(Y, h(X)) \given A=a] \leq \zeta \quad \forall a\]</div>
<p>In the example below we use <a class="reference internal" href="../api_reference/fairlearn.reductions.html#fairlearn.reductions.BoundedGroupLoss" title="fairlearn.reductions.BoundedGroupLoss"><code class="xref py py-class docutils literal notranslate"><span class="pre">BoundedGroupLoss</span></code></a> with
<a class="reference internal" href="../api_reference/fairlearn.reductions.html#fairlearn.reductions.ZeroOneLoss" title="fairlearn.reductions.ZeroOneLoss"><code class="xref py py-class docutils literal notranslate"><span class="pre">ZeroOneLoss</span></code></a> on two groups <code class="code docutils literal notranslate"><span class="pre">&quot;a&quot;</span></code> and <code class="code docutils literal notranslate"><span class="pre">&quot;b&quot;</span></code>.
Group <code class="code docutils literal notranslate"><span class="pre">&quot;a&quot;</span></code> has an average loss of <span class="math notranslate nohighlight">\(0.05\)</span>, while group
<code class="code docutils literal notranslate"><span class="pre">&quot;b&quot;</span></code>’s average loss is <span class="math notranslate nohighlight">\(0.5\)</span>.</p>
<div class="highlight-pycon3 notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">fairlearn.reductions</span> <span class="kn">import</span> <span class="n">BoundedGroupLoss</span><span class="p">,</span> <span class="n">ZeroOneLoss</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_absolute_error</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bgl</span> <span class="o">=</span> <span class="n">BoundedGroupLoss</span><span class="p">(</span><span class="n">ZeroOneLoss</span><span class="p">(),</span> <span class="n">upper_bound</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span>                  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span>             <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span>             <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sensitive_features</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mae_frame</span> <span class="o">=</span> <span class="n">MetricFrame</span><span class="p">(</span><span class="n">metrics</span><span class="o">=</span><span class="n">mean_absolute_error</span><span class="p">,</span>
<span class="gp">... </span>                        <span class="n">y_true</span><span class="o">=</span><span class="n">y_true</span><span class="p">,</span>
<span class="gp">... </span>                        <span class="n">y_pred</span><span class="o">=</span><span class="n">y_pred</span><span class="p">,</span>
<span class="gp">... </span>                        <span class="n">sensitive_features</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">sensitive_features</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;SF 0&quot;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mae_frame</span><span class="o">.</span><span class="n">overall</span>
<span class="go">0.275</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mae_frame</span><span class="o">.</span><span class="n">by_group</span>
<span class="go">SF 0</span>
<span class="go">a    0.05</span>
<span class="go">b    0.50</span>
<span class="go">Name: mean_absolute_error, dtype: float64</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bgl</span><span class="o">.</span><span class="n">load_data</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y_true</span><span class="p">,</span> <span class="n">sensitive_features</span><span class="o">=</span><span class="n">sensitive_features</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bgl</span><span class="o">.</span><span class="n">gamma</span><span class="p">(</span><span class="k">lambda</span> <span class="n">X</span><span class="p">:</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="go">group_id</span>
<span class="go">a    0.05</span>
<span class="go">b    0.50</span>
<span class="go">Name: loss, dtype: float64</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>In the example above the <code class="code docutils literal notranslate"><span class="pre">BoundedGroupLoss</span></code> object does not use the
<code class="code docutils literal notranslate"><span class="pre">upper_bound</span></code> argument. It is only used by reductions techniques
during the unfairness mitigation. As a result the constraint violation
detected by <code class="code docutils literal notranslate"><span class="pre">gamma</span></code> is identical to the mean absolute error.</p>
</div>
</section>
</section>
<section id="exponentiated-gradient">
<span id="id17"></span><h3>Exponentiated Gradient<a class="headerlink" href="#exponentiated-gradient" title="Permalink to this headline">#</a></h3>
</section>
<section id="grid-search">
<span id="id18"></span><h3>Grid Search<a class="headerlink" href="#grid-search" title="Permalink to this headline">#</a></h3>
</section>
</section>
<section id="adversarial-mitigation">
<span id="adversarial"></span><h2>Adversarial Mitigation<a class="headerlink" href="#adversarial-mitigation" title="Permalink to this headline">#</a></h2>
<p>Fairlearn provides an implementation of the adversarial
mitigation method of Zhang <em>et al.</em><a class="footnote-reference brackets" href="#footcite-zhang2018mitigating" id="id19">4</a>.
The input to the method consists of features <span class="math notranslate nohighlight">\(X,\)</span> labels <span class="math notranslate nohighlight">\(Y,\)</span>
and sensitive features <span class="math notranslate nohighlight">\(A\)</span>. The goal is to fit an estimator that
predicts <span class="math notranslate nohighlight">\(Y\)</span> from <span class="math notranslate nohighlight">\(X\)</span> while enforcing fairness constraints with
respect to <span class="math notranslate nohighlight">\(A\)</span>. Both classification and regression
are supported (classes <a class="reference internal" href="../api_reference/fairlearn.adversarial.html#fairlearn.adversarial.AdversarialFairnessClassifier" title="fairlearn.adversarial.AdversarialFairnessClassifier"><code class="xref py py-class docutils literal notranslate"><span class="pre">AdversarialFairnessClassifier</span></code></a> and
<a class="reference internal" href="../api_reference/fairlearn.adversarial.html#fairlearn.adversarial.AdversarialFairnessRegressor" title="fairlearn.adversarial.AdversarialFairnessRegressor"><code class="xref py py-class docutils literal notranslate"><span class="pre">AdversarialFairnessRegressor</span></code></a>) with two types of
fairness constraints: demographic parity and equalized odds.</p>
<p>To train an adversarial mitigation algorithm, the user needs to provide
two neural networks, a predictor network and an adversary network,
with learnable weights <span class="math notranslate nohighlight">\(W\)</span> and <span class="math notranslate nohighlight">\(U,\)</span> respectively. The predictor
network is constructed to solve the underlying supervised learning task,
without considering fairness, by minimizing the predictor loss <span class="math notranslate nohighlight">\(L_P.\)</span>
However, to improve fairness, we do not
only minimize the predictor loss, but we also want to decrease the
adversary’s ability to predict the sensitive features from the predictor’s
predictions (when implementing demographic parity), or jointly from the predictor’s
predictions and true labels (when implementing equalized odds).</p>
<p>Suppose the adversary has the loss term <span class="math notranslate nohighlight">\(L_A.\)</span> The algorithm
updates adversary weights <span class="math notranslate nohighlight">\(U\)</span> by descending along the gradient <span class="math notranslate nohighlight">\(\nabla_U L_A\)</span>.
However, when updating the predictor weights <span class="math notranslate nohighlight">\(W\)</span>, the algorithm uses</p>
<div class="math notranslate nohighlight">
\[\nabla_W L_P - \text{proj}_{\nabla_W L_A} \nabla_W L_P - \alpha \nabla_W L_A.\]</div>
<p>instead of just gradient.
Compared with standard stochastic gradient descent, there are two additional terms
that seek to prevent the decrease of the adversary loss. The hyperparameter
<span class="math notranslate nohighlight">\(\alpha\)</span> specifies the strength of enforcing the fairness constraint.
For details, see Zhang <em>et al.</em><a class="footnote-reference brackets" href="#footcite-zhang2018mitigating" id="id20">4</a>.</p>
<p>In <a class="reference internal" href="#models"><span class="std std-ref">Models</span></a>, we discuss the models that this implementation accepts.
In <a class="reference internal" href="#data-types"><span class="std std-ref">Data types and loss functions</span></a>, we discuss the input format of <span class="math notranslate nohighlight">\(X,\)</span>
how <span class="math notranslate nohighlight">\(Y\)</span> and <span class="math notranslate nohighlight">\(A\)</span> are preprocessed, and
how the loss functions <span class="math notranslate nohighlight">\(L_P\)</span> and <span class="math notranslate nohighlight">\(L_A\)</span> are chosen.
Finally, in <a class="reference internal" href="#training"><span class="std std-ref">Training</span></a> we give some
useful tips to keep in mind when training this model, as
adversarial methods such as these
can be difficult to train.</p>
<section id="models">
<span id="id21"></span><h3>Models<a class="headerlink" href="#models" title="Permalink to this headline">#</a></h3>
<p>One can implement the predictor and adversarial neural networks as
a <cite>torch.nn.Module</cite> (using PyTorch) or as a <cite>tensorflow.keras.Model</cite> (using TensorFlow).
This implementation has a soft dependency on either PyTorch or TensorFlow, and the user
needs to have installed either one of the two soft dependencies. It is not possible to
mix these dependencies, so a PyTorch predictor with a TensorFlow loss function is not
possible.</p>
<p>It is very important to define the neural network models with no activation function
or discrete prediction function on the final layer. So, for instance, when predicting
a categorical feature that is one-hot-encoded, the neural network should output a
vector of real-valued scores, not the one-hot-encoded discrete prediction:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">predictor_model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">),</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="p">])</span>
<span class="n">adversary_model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">),</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="p">])</span>
<span class="n">mitigator</span> <span class="o">=</span> <span class="n">AdversarialFairnessClassifier</span><span class="p">(</span>
    <span class="n">predictor_model</span><span class="o">=</span><span class="n">predictor_model</span><span class="p">,</span>
    <span class="n">adversary_model</span><span class="o">=</span><span class="n">adversary_model</span>
<span class="p">)</span>
</pre></div>
</div>
<p>For simple or exploratory use cases, Fairlearn provides a very basic neural
network builder.
Instead of a neural network model, it is possible to pass a list
<span class="math notranslate nohighlight">\([k_1, k_2, \dots]\)</span>, where each <span class="math notranslate nohighlight">\(k_i\)</span> either indicates
the number of nodes (if <span class="math notranslate nohighlight">\(k_i\)</span> is an integer) or
an activation function (if <span class="math notranslate nohighlight">\(k_i\)</span> is a string) or
a layer or activation function instance directly (if <span class="math notranslate nohighlight">\(k_i\)</span> is
a callable).
However, the number of nodes in the input
and output layer is automatically inferred from data, and the final
activation function (such as softmax for categorical
predictors) is also inferred from data.
So, in the following example, the predictor model is
a neural network with an input layer of
the appropriate number of nodes, a hidden layer with 50 nodes and
ReLU activations, and an output layer with an appropriate activation function.
The appropriate function in case of classification will be softmax for one
hot encoded <span class="math notranslate nohighlight">\(Y\)</span> and sigmoid for binary <span class="math notranslate nohighlight">\(Y\)</span>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">mitigator</span> <span class="o">=</span> <span class="n">AdversarialFairnessClassifier</span><span class="p">(</span>
    <span class="n">predictor_model</span><span class="o">=</span><span class="p">[</span><span class="mi">50</span><span class="p">,</span> <span class="s2">&quot;relu&quot;</span><span class="p">],</span>
    <span class="n">adversary_model</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="s2">&quot;relu&quot;</span><span class="p">]</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<section id="data-types-and-loss-functions">
<span id="data-types"></span><h3>Data types and loss functions<a class="headerlink" href="#data-types-and-loss-functions" title="Permalink to this headline">#</a></h3>
<p>We require the provided data <span class="math notranslate nohighlight">\(X\)</span> to be provided as a matrix
(2d array-like) of floats; this data is directly passed to
neural network models.</p>
<p>Labels <span class="math notranslate nohighlight">\(Y\)</span> and sensitive features <span class="math notranslate nohighlight">\(A\)</span> are automatically
preprocessed based on their type: binary data is represented as 0/1,
categorical data is one-hot encoded, float data is left unchanged.</p>
<p>Zhang <em>et al.</em><a class="footnote-reference brackets" href="#footcite-zhang2018mitigating" id="id22">4</a> do not explicitly define loss functions.
In <a class="reference internal" href="../api_reference/fairlearn.adversarial.html#fairlearn.adversarial.AdversarialFairnessClassifier" title="fairlearn.adversarial.AdversarialFairnessClassifier"><code class="xref py py-class docutils literal notranslate"><span class="pre">AdversarialFairnessClassifier</span></code></a> and <a class="reference internal" href="../api_reference/fairlearn.adversarial.html#fairlearn.adversarial.AdversarialFairnessRegressor" title="fairlearn.adversarial.AdversarialFairnessRegressor"><code class="xref py py-class docutils literal notranslate"><span class="pre">AdversarialFairnessRegressor</span></code></a>,
the loss functions are automatically inferred based on
the data type of the label and sensitive features.
For binary and categorical target variables, the training loss is cross-entropy.
For float targets variables, the training loss is the mean squared error.</p>
<p>To summarize:</p>
<table class="colwidths-given table">
<colgroup>
<col style="width: 16%" />
<col style="width: 11%" />
<col style="width: 16%" />
<col style="width: 16%" />
<col style="width: 26%" />
<col style="width: 16%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>label <span class="math notranslate nohighlight">\(Y\)</span></p></th>
<th class="head"><p>derived label <span class="math notranslate nohighlight">\(Y'\)</span></p></th>
<th class="head"><p>network output <span class="math notranslate nohighlight">\(Z\)</span></p></th>
<th class="head"><p>probabilistic prediction</p></th>
<th class="head"><p>loss function</p></th>
<th class="head"><p>prediction</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>binary</strong></p></td>
<td><p>0/1</p></td>
<td><p><span class="math notranslate nohighlight">\(\mathbb{R}\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\mathbb{P}(Y'=1)\)</span>
<span class="math notranslate nohighlight">\(\;\;=1/(1+e^{-Z})\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(-Y'\log\mathbb{P}(Y'=1)\)</span>
<span class="math notranslate nohighlight">\(\;\;-(1-Y')\log\mathbb{P}(Y'=0)\)</span></p></td>
<td><p>1 if <span class="math notranslate nohighlight">\(Z\ge 0\)</span>, else 0</p></td>
</tr>
<tr class="row-odd"><td><p><strong>categorical</strong>
(<span class="math notranslate nohighlight">\(k\)</span> values)</p></td>
<td><p>one-hot encoding</p></td>
<td><p><span class="math notranslate nohighlight">\(\mathbb{R}^k\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\mathbb{P}(Y'=\mathbf{e}_j)\)</span>
<span class="math notranslate nohighlight">\(\;\;=e^{Z_j}/\sum_{\ell=1}^k e^{Z_{\ell}}\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(-\sum_{j=1}^k Y'_j\log\mathbb{P}(Y'=\mathbf{e}_j)\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\text{argmax}_j\,Z_j\)</span></p></td>
</tr>
<tr class="row-even"><td><p><strong>continuous</strong>
(in <span class="math notranslate nohighlight">\(\mathbb{R}^k\)</span>)</p></td>
<td><p>unchanged</p></td>
<td><p><span class="math notranslate nohighlight">\(\mathbb{R}^k\)</span></p></td>
<td><p>not available</p></td>
<td><p><span class="math notranslate nohighlight">\(\Vert Z-Y\Vert^2\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(Z\)</span></p></td>
</tr>
</tbody>
</table>
<p>The label is treated as binary if it takes on two distinct <code class="code docutils literal notranslate"><span class="pre">int</span></code> or <code class="code docutils literal notranslate"><span class="pre">str</span></code> values,
as categorical if it takes on <span class="math notranslate nohighlight">\(k\)</span> distinct <code class="code docutils literal notranslate"><span class="pre">int</span></code> or <code class="code docutils literal notranslate"><span class="pre">str</span></code> values (with <span class="math notranslate nohighlight">\(k&gt;2\)</span>),
and as continuous if it is a float or a vector of floats. Sensitive features are treated similarly.</p>
<p><em>Note: currently, all data needs to be passed to the model in the first call
to fit.</em></p>
</section>
<section id="training">
<span id="id23"></span><h3>Training<a class="headerlink" href="#training" title="Permalink to this headline">#</a></h3>
<p>Adversarial learning is inherently difficult because of various issues,
such as mode collapse, divergence, and diminishing gradients. Mode collapse
is the scenario where the predictor learns to produce one output, and because
it does this relatively well, it will never learn any other output. Diminishing
gradients are common as well, and could be due to an adversary that is trained
too well in comparison to the predictor.
Such problems
have been studied extensively by others, so we encourage the user to find remedies
elsewhere from more extensive sources. As a general rule of thumb,
training adversarially is best done with a lower and possibly decaying learning
rate while ensuring the
losses remain balanced, and keeping track of validation accuracies every few
iterations may save you a lot of headaches if the model suddenly diverges or
collapses.</p>
<p>Some pieces of advice regarding training with adversarial fairness:</p>
<ol class="arabic simple">
<li><p>For some tabular datasets, we found that single hidden layer neural
networks are easier to train than deeper networks.</p></li>
<li><p>Validate your model! Provide this model with a callback function in
the constructor’s keyword <code class="code docutils literal notranslate"><span class="pre">callbacks</span></code> (see <a class="reference internal" href="#example-2"><span class="std std-ref">Example 2: Finetuning training</span></a>).
Optionally, have this function return <code class="code docutils literal notranslate"><span class="pre">True</span></code>
to indicate early stopping.</p></li>
<li><p>Zhang <em>et al.</em><a class="footnote-reference brackets" href="#footcite-zhang2018mitigating" id="id24">4</a> have found it to be useful to maintain a global step
count and gradually increase <span class="math notranslate nohighlight">\(\alpha\)</span> while decreasing the learning
rate <span class="math notranslate nohighlight">\(\eta\)</span> and taking <span class="math notranslate nohighlight">\(\alpha \eta \rightarrow 0\)</span>
as the global step count increases. In particular, use a callback function to perform
these hyperparameter updates. An example can be seen in the example notebook.</p></li>
</ol>
</section>
<section id="example-1-basics-model-specification">
<span id="example-1"></span><h3>Example 1: Basics &amp; model specification<a class="headerlink" href="#example-1-basics-model-specification" title="Permalink to this headline">#</a></h3>
<p>First, we cover a most basic application of adversarial mitigation.
We start by loading and preprocessing the dataset:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">fetch_openml</span>

<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">fetch_openml</span><span class="p">(</span><span class="n">data_id</span><span class="o">=</span><span class="mi">1590</span><span class="p">,</span> <span class="n">as_frame</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">pos_label</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="n">z</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="s2">&quot;sex&quot;</span><span class="p">]</span> <span class="c1"># In this example, we consider &#39;sex&#39; the sensitive feature.</span>
</pre></div>
</div>
<p>The UCI adult dataset cannot be fed into a neural network (yet),
as we have many columns that are not numerical in nature. To resolve this
issue, we could for instance use one-hot encodings to preprocess categorical
columns. Additionally, let’s preprocess the numeric columns to a
standardized range. For these tasks, we can use functionality from
scikit-learn (<code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.preprocessor</span></code>). We also use an imputer
to get rid of NaN’s:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.compose</span> <span class="kn">import</span> <span class="n">make_column_transformer</span><span class="p">,</span> <span class="n">make_column_selector</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">OneHotEncoder</span><span class="p">,</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.impute</span> <span class="kn">import</span> <span class="n">SimpleImputer</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="kn">from</span> <span class="nn">numpy</span> <span class="kn">import</span> <span class="n">number</span>

<span class="n">ct</span> <span class="o">=</span> <span class="n">make_column_transformer</span><span class="p">(</span>
    <span class="p">(</span>
        <span class="n">Pipeline</span><span class="p">(</span>
            <span class="p">[</span>
                <span class="p">(</span><span class="s2">&quot;imputer&quot;</span><span class="p">,</span> <span class="n">SimpleImputer</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s2">&quot;mean&quot;</span><span class="p">)),</span>
                <span class="p">(</span><span class="s2">&quot;normalizer&quot;</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">()),</span>
            <span class="p">]</span>
        <span class="p">),</span>
        <span class="n">make_column_selector</span><span class="p">(</span><span class="n">dtype_include</span><span class="o">=</span><span class="n">number</span><span class="p">),</span>
    <span class="p">),</span>
    <span class="p">(</span>
        <span class="n">Pipeline</span><span class="p">(</span>
            <span class="p">[</span>
                <span class="p">(</span><span class="s2">&quot;imputer&quot;</span><span class="p">,</span> <span class="n">SimpleImputer</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s2">&quot;most_frequent&quot;</span><span class="p">)),</span>
                <span class="p">(</span><span class="s2">&quot;encoder&quot;</span><span class="p">,</span> <span class="n">OneHotEncoder</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="s2">&quot;if_binary&quot;</span><span class="p">,</span> <span class="n">sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">)),</span>
            <span class="p">]</span>
        <span class="p">),</span>
        <span class="n">make_column_selector</span><span class="p">(</span><span class="n">dtype_include</span><span class="o">=</span><span class="s2">&quot;category&quot;</span><span class="p">),</span>
    <span class="p">),</span>
<span class="p">)</span>
</pre></div>
</div>
<p>As with other machine learning methods, it is wise to take a train-test split
of the data in order to validate the model on unseen data:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">,</span> <span class="n">Z_train</span><span class="p">,</span> <span class="n">Z_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">12345</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">y</span>
<span class="p">)</span>

<span class="n">X_prep_train</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span> <span class="c1"># Only fit on training data!</span>
<span class="n">X_prep_test</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</pre></div>
</div>
<p>Now, we can use <a class="reference internal" href="../api_reference/fairlearn.adversarial.html#fairlearn.adversarial.AdversarialFairnessClassifier" title="fairlearn.adversarial.AdversarialFairnessClassifier"><code class="xref py py-class docutils literal notranslate"><span class="pre">AdversarialFairnessClassifier</span></code></a>
to train on the
UCI Adult dataset. As our predictor and adversary models, we use for
simplicity the default constructors for fully connected neural
networks with sigmoid activations implemented in Fairlearn. We initialize
neural network constructors
by passing a list <span class="math notranslate nohighlight">\(h_1, h_2, \dots\)</span> that indicate the number of nodes
<span class="math notranslate nohighlight">\(h_i\)</span> per hidden layer <span class="math notranslate nohighlight">\(i\)</span>. You can also put strings in this list
to indicate certain activation functions, or just pass an initialized
activation function directly.</p>
<p>The specific fairness
objective that we choose for this example is demographic parity, so we also
set <code class="code docutils literal notranslate"><span class="pre">objective</span> <span class="pre">=</span> <span class="pre">&quot;demographic_parity&quot;</span></code>. We generally follow sklearn API,
but in this case we require some extra kwargs. In particular, we should
specify the number of epochs, batch size, whether to shuffle the rows of data
after every epoch, and optionally after how many seconds to show a progress
update:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">fairlearn.adversarial</span> <span class="kn">import</span> <span class="n">AdversarialFairnessClassifier</span>

<span class="n">mitigator</span> <span class="o">=</span> <span class="n">AdversarialFairnessClassifier</span><span class="p">(</span>
    <span class="n">backend</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span>
    <span class="n">predictor_model</span><span class="o">=</span><span class="p">[</span><span class="mi">50</span><span class="p">,</span> <span class="s2">&quot;leaky_relu&quot;</span><span class="p">],</span>
    <span class="n">adversary_model</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="s2">&quot;leaky_relu&quot;</span><span class="p">],</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">2</span> <span class="o">**</span> <span class="mi">8</span><span class="p">,</span>
    <span class="n">progress_updates</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
    <span class="n">random_state</span><span class="o">=</span><span class="mi">123</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<p>Then, we can fit the data to our model:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">mitigator</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_prep_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">,</span> <span class="n">sensitive_features</span><span class="o">=</span><span class="n">Z_train</span><span class="p">)</span>
</pre></div>
</div>
<p>Finally, we evaluate the predictions. In particular, we trained the
predictor for demographic parity, so we are not only interested in
the accuracy, but also in the selection rate. MetricFrames are a great resource
here:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">predictions</span> <span class="o">=</span> <span class="n">mitigator</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_prep_test</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">fairlearn.metrics</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">MetricFrame</span><span class="p">,</span>
    <span class="n">selection_rate</span><span class="p">,</span>
    <span class="n">demographic_parity_difference</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>

<span class="n">mf</span> <span class="o">=</span> <span class="n">MetricFrame</span><span class="p">(</span>
    <span class="n">metrics</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;accuracy&quot;</span><span class="p">:</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="s2">&quot;selection_rate&quot;</span><span class="p">:</span> <span class="n">selection_rate</span><span class="p">},</span>
    <span class="n">y_true</span><span class="o">=</span><span class="n">Y_test</span> <span class="o">==</span> <span class="n">pos_label</span><span class="p">,</span>
    <span class="n">y_pred</span><span class="o">=</span><span class="n">predictions</span> <span class="o">==</span> <span class="n">pos_label</span><span class="p">,</span>
    <span class="n">sensitive_features</span><span class="o">=</span><span class="n">Z_test</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<p>Then, to display the result:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">mf</span><span class="o">.</span><span class="n">by_group</span><span class="p">)</span>
<span class="go">        accuracy selection_rate</span>
<span class="go">sex</span>
<span class="go">Female  0.906308       0.978664</span>
<span class="go">Male    0.723336       0.484927</span>
</pre></div>
</div>
<p>The above statistics tell us that the accuracy of our model is quite good,
90% for females and 72% for males. However, the selection rates differ, so there
is a large demographic disparity here. When using adversarial fairness
out-of-the-box, users may not yield such
good training results after the first attempt. In general, training
adversarial networks is hard, and users may need to tweak the
hyperparameters continuously. Besides general scikit-learn algorithms
that finetune estimators,
<a class="reference internal" href="#example-2"><span class="std std-ref">Example 2: Finetuning training</span></a> will demonstrate some problem-specific
techniques we can use such as using dynamic hyperparameters,
validation, and early stopping to improve adversarial training.</p>
</section>
<section id="example-2-finetuning-training">
<span id="example-2"></span><h3>Example 2: Finetuning training<a class="headerlink" href="#example-2-finetuning-training" title="Permalink to this headline">#</a></h3>
<p>Adversarial learning is inherently difficult because of various issues,
such as mode collapse, divergence, and diminishing gradients.
In particular, mode collapse seems a real problem on this dataset: the
predictor and adversary trap themselves in a local minimum by favoring one
class (mode). Problems with diverging parameters may also occur, which
may be an indication of a bad choice of hyperparameters, such as a
learning rate that is too large. The problems that a user may encounter are
of course case specific, but general good practices when training
such models are: train slowly, ensuring the
losses remain balanced, and keep track of validation accuracies.
Additionally, we found that single hidden layer neural
networks work best for this use case.</p>
<p>In this example, we demonstrate some of these good practices.
We start by defining our
predictor neural network explicitly so that it is more apparent.
We will be using PyTorch, but the same can be achieved using Tensorflow:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>

<span class="k">class</span> <span class="nc">PredictorModel</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">PredictorModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">X_prep_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">200</span><span class="p">),</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(),</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">200</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">(),</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>


<span class="n">predictor_model</span> <span class="o">=</span> <span class="n">PredictorModel</span><span class="p">()</span>
</pre></div>
</div>
<p>We also take a look at some validation
metrics. Most importantly, we chose the demographic parity difference
to check to what
extent the constraint (demographic parity in this case) is satisfied.
We also look at the selection rate to observe whether our model is
suffering from mode collapse, and we also calculate the accuracy on the
validation set as well.
We will pass this validation step to our model later:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">numpy</span> <span class="kn">import</span> <span class="n">mean</span>

<span class="k">def</span> <span class="nf">validate</span><span class="p">(</span><span class="n">mitigator</span><span class="p">):</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="n">mitigator</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_prep_test</span><span class="p">)</span>
    <span class="n">dp_diff</span> <span class="o">=</span> <span class="n">demographic_parity_difference</span><span class="p">(</span>
        <span class="n">Y_test</span> <span class="o">==</span> <span class="n">pos_label</span><span class="p">,</span>
        <span class="n">predictions</span> <span class="o">==</span> <span class="n">pos_label</span><span class="p">,</span>
        <span class="n">sensitive_features</span><span class="o">=</span><span class="n">Z_test</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">mean</span><span class="p">(</span><span class="n">predictions</span><span class="o">.</span><span class="n">values</span> <span class="o">==</span> <span class="n">Y_test</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
    <span class="n">selection_rate</span> <span class="o">=</span> <span class="n">mean</span><span class="p">(</span><span class="n">predictions</span> <span class="o">==</span> <span class="n">pos_label</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span>
        <span class="s2">&quot;DP diff: </span><span class="si">{:.4f}</span><span class="s2">, accuracy: </span><span class="si">{:.4f}</span><span class="s2">, selection_rate: </span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
            <span class="n">dp_diff</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">,</span> <span class="n">selection_rate</span>
        <span class="p">)</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">dp_diff</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">,</span> <span class="n">selection_rate</span>
</pre></div>
</div>
<p>We may define the optimizers however we like. In this case, we use the
suggestion from the paper to set the hyperparameters <span class="math notranslate nohighlight">\(\alpha\)</span> and learning
rate <span class="math notranslate nohighlight">\(\eta\)</span> to depend on the timestep such that <span class="math notranslate nohighlight">\(\alpha \eta
\rightarrow 0\)</span> as the timestep grows:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">schedulers</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">def</span> <span class="nf">optimizer_constructor</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
    <span class="k">global</span> <span class="n">schedulers</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
    <span class="n">schedulers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">ExponentialLR</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.995</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">optimizer</span>

<span class="n">step</span> <span class="o">=</span> <span class="mi">1</span>
</pre></div>
</div>
<p>We make use of a callback function to both update the hyperparameters and to
validate the model. We update these hyperparameters at every 10 steps, and we
validate every 100 steps. Additionally, we can implement early stopping
easily by calling <code class="code docutils literal notranslate"><span class="pre">return</span> <span class="pre">True</span></code> in a callback function:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">math</span> <span class="kn">import</span> <span class="n">sqrt</span>

<span class="k">def</span> <span class="nf">callbacks</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">):</span>
    <span class="k">global</span> <span class="n">step</span>
    <span class="k">global</span> <span class="n">schedulers</span>
    <span class="n">step</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="c1"># Update hyperparameters</span>
    <span class="n">model</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.3</span> <span class="o">*</span> <span class="n">sqrt</span><span class="p">(</span><span class="n">step</span> <span class="o">//</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">scheduler</span> <span class="ow">in</span> <span class="n">schedulers</span><span class="p">:</span>
        <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
    <span class="c1"># Validate (and early stopping) every 50 steps</span>
    <span class="k">if</span> <span class="n">step</span> <span class="o">%</span> <span class="mi">50</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">dp_diff</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">,</span> <span class="n">selection_rate</span> <span class="o">=</span> <span class="n">validate</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
        <span class="c1"># Early stopping condition:</span>
        <span class="c1"># Good accuracy + low dp_diff + no mode collapse</span>
        <span class="k">if</span> <span class="p">(</span>
            <span class="n">dp_diff</span> <span class="o">&lt;</span> <span class="mf">0.03</span>
            <span class="ow">and</span> <span class="n">accuracy</span> <span class="o">&gt;</span> <span class="mf">0.8</span>
            <span class="ow">and</span> <span class="n">selection_rate</span> <span class="o">&gt;</span> <span class="mf">0.01</span>
            <span class="ow">and</span> <span class="n">selection_rate</span> <span class="o">&lt;</span> <span class="mf">0.99</span>
        <span class="p">):</span>
            <span class="k">return</span> <span class="kc">True</span>
</pre></div>
</div>
<p>Then, the instance itself. Notice that we do not explicitly define loss
functions, because adversarial fairness is able to infer the loss function
on its own in this example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">mitigator</span> <span class="o">=</span> <span class="n">AdversarialFairnessClassifier</span><span class="p">(</span>
    <span class="n">predictor_model</span><span class="o">=</span><span class="n">predictor_model</span><span class="p">,</span>
    <span class="n">adversary_model</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="s2">&quot;leaky_relu&quot;</span><span class="p">],</span>
    <span class="n">predictor_optimizer</span><span class="o">=</span><span class="n">optimizer_constructor</span><span class="p">,</span>
    <span class="n">adversary_optimizer</span><span class="o">=</span><span class="n">optimizer_constructor</span><span class="p">,</span>
    <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">2</span> <span class="o">**</span> <span class="mi">7</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">,</span>
    <span class="n">random_state</span><span class="o">=</span><span class="mi">123</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<p>Then, we fit the model:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">mitigator</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_prep_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">,</span> <span class="n">sensitive_features</span><span class="o">=</span><span class="n">Z_train</span><span class="p">)</span>
</pre></div>
</div>
<p>Finally, we validate as before, and take a look at the results:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">validate</span><span class="p">(</span><span class="n">mitigator</span><span class="p">)</span> <span class="c1"># to see DP difference, accuracy, and selection_rate</span>
<span class="go">(0.12749738693557688, 0.8005937148121609, 0.8286416214556249)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">mitigator</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_prep_test</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mf</span> <span class="o">=</span> <span class="n">MetricFrame</span><span class="p">(</span>
<span class="go">        metrics={&quot;accuracy&quot;: accuracy_score, &quot;selection_rate&quot;: selection_rate},</span>
<span class="go">        y_true=Y_test == pos_label,</span>
<span class="go">        y_pred=predictions == pos_label,</span>
<span class="go">        sensitive_features=Z_test,</span>
<span class="go">    )</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">mf</span><span class="o">.</span><span class="n">by_group</span><span class="p">)</span>
<span class="go">        accuracy selection_rate</span>
<span class="go">sex</span>
<span class="go">Female  0.823129       0.743352</span>
<span class="go">Male    0.789441       0.870849</span>
</pre></div>
</div>
<p>Notice we achieve a much lower demographic parity
difference than in Exercise 1! This may come at the cost of some accuracy,
but such a tradeoff is to be expected as we are purposely mitigating
the unfairness that was present in the data.</p>
</section>
<section id="example-3-scikit-learn-applications">
<span id="example-3"></span><h3>Example 3: Scikit-learn applications<a class="headerlink" href="#example-3-scikit-learn-applications" title="Permalink to this headline">#</a></h3>
<p>AdversarialFairness is quite compliant with scikit-learn API, so functions
such as pipelining and model selection are applicable here. In particular,
applying pipelining might seem complicated as scikit-learn only pipelines
<code class="code docutils literal notranslate"><span class="pre">X</span></code> and <code class="code docutils literal notranslate"><span class="pre">Y</span></code>, not the <code class="code docutils literal notranslate"><span class="pre">sensitive_features</span></code>.
We overcome this issue by passing the sensitive features through the
pipeline as keyword-argument <code class="code docutils literal notranslate"><span class="pre">[name</span> <span class="pre">of</span> <span class="pre">model]__sensitive_features</span></code>
to fit:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span>
<span class="go">        [</span>
<span class="go">            (&quot;preprocessor&quot;, ct),</span>
<span class="go">            (</span>
<span class="go">                &quot;classifier&quot;,</span>
<span class="go">                AdversarialFairnessClassifier(</span>
<span class="go">                    backend=&quot;torch&quot;,</span>
<span class="go">                    predictor_model=[50, &quot;leaky_relu&quot;],</span>
<span class="go">                    adversary_model=[3, &quot;leaky_relu&quot;],</span>
<span class="go">                    batch_size=2 ** 8,</span>
<span class="go">                    random_state=123,</span>
<span class="go">                ),</span>
<span class="go">            ),</span>
<span class="go">        ]</span>
<span class="go">    )</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pipeline</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">,</span> <span class="n">classifier__sensitive_features</span><span class="o">=</span><span class="n">Z_train</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">pipeline</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mf</span> <span class="o">=</span> <span class="n">MetricFrame</span><span class="p">(</span>
<span class="go">        metrics={&quot;accuracy&quot;: accuracy_score, &quot;selection_rate&quot;: selection_rate},</span>
<span class="go">        y_true=Y_test == pos_label,</span>
<span class="go">        y_pred=predictions == pos_label,</span>
<span class="go">        sensitive_features=Z_test,</span>
<span class="go">    )</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">mf</span><span class="o">.</span><span class="n">by_group</span><span class="p">)</span>
<span class="go">        accuracy selection_rate</span>
<span class="go">sex</span>
<span class="go">Female  0.906308       0.978664</span>
<span class="go">Male    0.723336       0.484927</span>
</pre></div>
</div>
<p>Notice how the same result is obtained as in <a class="reference internal" href="#example-1"><span class="std std-ref">Example 1: Basics &amp; model specification</span></a>.</p>
</section>
<section id="references">
<span id="id25"></span><h3>References<a class="headerlink" href="#references" title="Permalink to this headline">#</a></h3>
<div class="docutils container" id="id26">
<dl class="footnote brackets">
<dt class="label" id="footcite-agarwal2018reductions"><span class="brackets">1</span><span class="fn-backref">(<a href="#id2">1</a>,<a href="#id3">2</a>,<a href="#id11">3</a>)</span></dt>
<dd><p>Alekh Agarwal, Alina Beygelzimer, Miroslav Dudík, John Langford, and Hanna M. Wallach. A reductions approach to fair classification. In <em>ICML</em>, volume 80 of Proceedings of Machine Learning Research, 60–69. PMLR, 2018. URL: <a class="reference external" href="http://proceedings.mlr.press/v80/agarwal18a.html">http://proceedings.mlr.press/v80/agarwal18a.html</a>.</p>
</dd>
<dt class="label" id="footcite-agarwal2019fair"><span class="brackets">2</span><span class="fn-backref">(<a href="#id4">1</a>,<a href="#id12">2</a>)</span></dt>
<dd><p>Alekh Agarwal, Miroslav Dudík, and Zhiwei Steven Wu. Fair regression: quantitative definitions and reduction-based algorithms. In <em>ICML</em>, volume 97 of Proceedings of Machine Learning Research, 120–129. PMLR, 2019. URL: <a class="reference external" href="http://proceedings.mlr.press/v97/agarwal19d.html">http://proceedings.mlr.press/v97/agarwal19d.html</a>.</p>
</dd>
<dt class="label" id="footcite-hardt2016equality"><span class="brackets"><a class="fn-backref" href="#id5">3</a></span></dt>
<dd><p>Moritz Hardt, Eric Price, and Nati Srebro. Equality of opportunity in supervised learning. In <em>NeurIPS</em>, 3315–3323. 2016. URL: <a class="reference external" href="https://proceedings.neurips.cc/paper/2016/hash/9d2682367c3935defcb1f9e247a97c0d-Abstract.html">https://proceedings.neurips.cc/paper/2016/hash/9d2682367c3935defcb1f9e247a97c0d-Abstract.html</a>.</p>
</dd>
<dt class="label" id="footcite-zhang2018mitigating"><span class="brackets">4</span><span class="fn-backref">(<a href="#id6">1</a>,<a href="#id19">2</a>,<a href="#id20">3</a>,<a href="#id22">4</a>,<a href="#id24">5</a>)</span></dt>
<dd><p>Brian Hu Zhang, Blake Lemoine, and Margaret Mitchell. Mitigating unwanted biases with adversarial learning. In <em>Proceedings of the 2018 AAAI/ACM Conference on AI, Ethics, and Society</em>, 335–340. 2018.</p>
</dd>
</dl>
</div>
</section>
</section>
</section>


              </article>
              

              
          </div>
          
      </div>
    </div>

  
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=92025949c220c2e29695"></script>

<footer class="bd-footer"><div class="bd-footer__inner container">
  
  <div class="footer-item">
    <p class="copyright">
    &copy; Copyright 2018 - 2022, Fairlearn contributors.<br>
</p>
  </div>
  
  <div class="footer-item">
    <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 4.5.0.<br>
</p>
  </div>
  
</div>
</footer>
  </body>
</html>