
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>fairlearn.adversarial package &#8212; Fairlearn 0.8.0 documentation</title>
<script>
  document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
  document.documentElement.dataset.theme = localStorage.getItem("theme") || "light"
</script>

  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=92025949c220c2e29695" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=92025949c220c2e29695" rel="stylesheet">


  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/custom.css" />

  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=92025949c220c2e29695">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script>window.MathJax = {"tex": {"macros": {"E": "{\\mathbb{E}}", "P": "{\\mathbb{P}}", "given": "\\mathbin{\\vert}"}}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="fairlearn.experimental package" href="fairlearn.experimental.html" />
    <link rel="prev" title="fairlearn.reductions package" href="fairlearn.reductions.html" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta name="docsearch:language" content="None">
  </head>
  
  
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="180" data-default-mode="">
    <div class="bd-header-announcement container-fluid" id="banner">
      

    </div>

    
    <nav class="bd-header navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="bd-header__inner container-xl">

  <div id="navbar-start">
    
    
  
  


<a class="navbar-brand logo" href="../https%3A//fairlearn.org.html">
  
  
  
  
    <img src="../_static/fairlearn_full_color.svg" class="logo__image only-light" alt="Logo image">
    <img src="../_static/fairlearn_full_color.svg" class="logo__image only-dark" alt="Logo image">
  
  
</a>
    
    <div class="dropdown" id="version_switcher">
    <button type="button" class="btn btn-sm navbar-btn dropdown-toggle" id="version_switcher_button" data-toggle="dropdown">
        0.8.0  <!-- this text may get changed later by javascript -->
        <span class="caret"></span>
    </button>
    <div id="version_switcher_menu" class="dropdown-menu list-group-flush py-0" aria-labelledby="version_switcher_button">
    <!-- dropdown will be populated by javascript on page load -->
    </div>
</div>

<!-- NOTE: this JS must live here (not in our global JS file) because it relies
     on being processed by Jinja before it is run (specifically for replacing
     variables api_reference/fairlearn.adversarial and {'json_url': 'https://fairlearn.org/main/_static/versions.json', 'version_match': '0.8.0'}.
-->

<script type="text/javascript">
// Check if corresponding page path exists in other version of docs
// and, if so, go there instead of the homepage of the other docs version
function checkPageExistsAndRedirect(event) {
    const currentFilePath = "api_reference/fairlearn.adversarial.html",
          tryUrl = event.target.getAttribute("href");
    let otherDocsHomepage = tryUrl.replace(currentFilePath, "");
    $.ajax({
        type: 'HEAD',
        url: tryUrl,
        // if the page exists, go there
        success: function() {
            location.href = tryUrl;
        }
    }).fail(function() {
        location.href = otherDocsHomepage;
    });
    // this prevents the browser from following the href of the clicked node
    // (which is fine because this function takes care of redirecting)
    return false;
}

// Populate the version switcher from the JSON config file
(function () {
    $.getJSON("https://fairlearn.org/main/_static/versions.json", function(data, textStatus, jqXHR) {
        const currentFilePath = "api_reference/fairlearn.adversarial.html";
        let btn = document.getElementById("version_switcher_button");
        // Set empty strings by default so that these attributes exist and can be used in CSS selectors
        btn.dataset["activeVersionName"] = "";
        btn.dataset["activeVersion"] = "";
        // create links to the corresponding page in the other docs versions
        $.each(data, function(index, entry) {
            // if no custom name specified (e.g., "latest"), use version string
            if (!("name" in entry)) {
                entry.name = entry.version;
            }
            // create the node
            const node = document.createElement("a");
            node.setAttribute("class", "list-group-item list-group-item-action py-1");
            node.textContent = `${entry.name}`;
            node.setAttribute("href", `${entry.url}${currentFilePath}`);
            // on click, AJAX calls will check if the linked page exists before
            // trying to redirect, and if not, will redirect to the homepage
            // for that version of the docs.
            node.onclick = checkPageExistsAndRedirect;
            // Add dataset values for the version and name in case people want
            // to apply CSS styling based on this information.
            node.dataset["versionName"] = entry.name;
            node.dataset["version"] = entry.version;

            $("#version_switcher_menu").append(node);
            // replace dropdown button text with the preferred display name of
            // this version, rather than using sphinx's  variable.
            // also highlight the dropdown entry for the currently-viewed
            // version's entry
            if (entry.version == "0.8.0") {
                node.classList.add("active");
                btn.innerText = btn.dataset["activeVersionName"] = entry.name;
                btn.dataset["activeVersion"] = entry.version;
            }
        });
    });
})();
</script>
    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="fas fa-bars"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../quickstart.html">
  Get Started
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../user_guide/index.html">
  User Guide
 </a>
</li>

<li class="toctree-l1 current active nav-item">
 <a class="reference internal nav-link" href="index.html">
  API Docs
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../auto_examples/index.html">
  Example Notebooks
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../contributor_guide/index.html">
  Contributor Guide
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../faq.html">
  FAQ
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../about/index.html">
  About Us
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <span id="theme-switch" class="btn btn-sm btn-outline-primary navbar-btn rounded-circle">
    <a class="theme-switch" data-mode="light"><i class="fas fa-sun"></i></a>
    <a class="theme-switch" data-mode="dark"><i class="far fa-moon"></i></a>
    <a class="theme-switch" data-mode="auto"><i class="fas fa-adjust"></i></a>
</span>
      </div>
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/fairlearn/fairlearn" rel="noopener" target="_blank" title="GitHub"><span><i class="fab fa-github"></i></span>
            <label class="sr-only">GitHub</label></a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="https://twitter.com/fairlearn" rel="noopener" target="_blank" title="Twitter"><span><i class="fab fa-twitter"></i></span>
            <label class="sr-only">Twitter</label></a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="https://stackoverflow.com/questions/tagged/fairlearn" rel="noopener" target="_blank" title="StackOverflow"><span><i class="fab fa-stack-overflow"></i></span>
            <label class="sr-only">StackOverflow</label></a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="https://discord.gg/R22yCfgsRn" rel="noopener" target="_blank" title="Discord"><span><i class="fab fa-discord"></i></span>
            <label class="sr-only">Discord</label></a>
        </li>
      </ul>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="bd-container container-xl">
      <div class="bd-container__inner row">
          

<!-- Only show if we have sidebars configured, else just a small margin  -->
<div class="bd-sidebar-primary col-12 col-md-3 bd-sidebar">
  <div class="sidebar-start-items"><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="fairlearn.datasets.html">
   fairlearn.datasets package
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="fairlearn.metrics.html">
   fairlearn.metrics package
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="fairlearn.postprocessing.html">
   fairlearn.postprocessing package
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="fairlearn.preprocessing.html">
   fairlearn.preprocessing package
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="fairlearn.reductions.html">
   fairlearn.reductions package
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   fairlearn.adversarial package
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="fairlearn.experimental.html">
   fairlearn.experimental package
  </a>
 </li>
</ul>

  </div>
</nav>
  </div>
  <div class="sidebar-end-items">
  </div>
</div>


          


<div class="bd-sidebar-secondary d-none d-xl-block col-xl-2 bd-toc">
  
    
    <div class="toc-item">
      

<nav id="bd-toc-nav">
    
</nav>
    </div>
    
    <div class="toc-item">
      
    </div>
    
  
</div>


          
          
          <div class="bd-content col-12 col-md-9 col-xl-7">
              
              <article class="bd-article" role="main">
                
  <section id="module-fairlearn.adversarial">
<span id="fairlearn-adversarial-package"></span><h1>fairlearn.adversarial package<a class="headerlink" href="#module-fairlearn.adversarial" title="Permalink to this headline">#</a></h1>
<p>Adversarial techniques to help mitigate unfairness.</p>
<dl class="py class">
<dt class="sig sig-object py" id="fairlearn.adversarial.AdversarialFairnessClassifier">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">fairlearn.adversarial.</span></span><span class="sig-name descname"><span class="pre">AdversarialFairnessClassifier</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">backend</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">predictor_model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">adversary_model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">predictor_optimizer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'Adam'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">adversary_optimizer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'Adam'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'demographic_parity'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epochs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">32</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shuffle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">progress_updates</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">skip_validation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cuda</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">warm_start</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="http://github.com/fairlearn/fairlearn/blob/v0.8.0/fairlearn/adversarial/_adversarial_mitigation.py#L804-L1002"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#fairlearn.adversarial.AdversarialFairnessClassifier" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">fairlearn.adversarial._adversarial_mitigation._AdversarialFairness</span></code>, <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.base.ClassifierMixin.html#sklearn.base.ClassifierMixin" title="(in scikit-learn v1.1)"><code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.base.ClassifierMixin</span></code></a></p>
<p>Train PyTorch or TensorFlow classifiers while mitigating unfairness.</p>
<p>This estimator implements the supervised learning method proposed in
<a class="reference external" href="https://dl.acm.org/doi/pdf/10.1145/3278721.3278779">“Mitigating Unwanted Biases with Adversarial Learning”</a> <a class="reference internal" href="#r88ef1dc9a4f5-1" id="id1">[1]</a>.
The training algorithm takes as input two neural network
models, a predictor model and an adversarial model, defined either as a
<a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html">PyTorch module</a> or
<a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/keras/Model">TensorFlow2 model</a>. The API
follows conventions of <cite>sklearn</cite> estimators.</p>
<p>The predictor model takes the features <code class="code docutils literal notranslate"><span class="pre">X</span></code> as input and seeks
to predict <code class="code docutils literal notranslate"><span class="pre">y</span></code>.
For binary classification, the predictor model should return a single
real-valued score, which is transformed into a probability of the
positive class via the logistic function (aka sigmoid), similarly to
logistic regression. For multi-class classification, the predictor
model should return a vector of real-valued scores, which are
transformed into class probabilities via the softmax function,
similarly to multinomial logistic regression. The training loss is
the negative log likelihood (aka log loss, logistic loss,
cross-entropy loss).</p>
<p>The adversarial model for demographic parity takes scores
produced by the predictor model as input, and seeks to predict
<code class="code docutils literal notranslate"><span class="pre">sensitive_features</span></code>. Depending on the type of the provided
sensitive features, the model should produce a scalar
or vector output. Three types of sensitive features are supported:
(1) a single binary feature; (2) a single discrete feature; (3) one or
multiple real-valued features. For a single binary sensitive feature
and a single discrete feature, the network outputs are transformed
by the logistic function and the softmax function, respectively, and
the loss is the negative log likelihood. For one or multiple
real-valued features, the network output is left as is, and the
loss is a square loss.</p>
<p>The adversarial model for equalized odds additionaly takes
<code class="code docutils literal notranslate"><span class="pre">y</span></code> as input. For multi-class classification, <code class="code docutils literal notranslate"><span class="pre">y</span></code> is
transformed using one-hot encoding.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>backend</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><em>str</em></a><em>, </em><em>BackendEngine</em><em>, </em><em>default = 'auto'</em>) – The backend to use. Must be one of <code class="code docutils literal notranslate"><span class="pre">'torch'</span></code>, <code class="code docutils literal notranslate"><span class="pre">'tensorflow'</span></code>,
or <code class="code docutils literal notranslate"><span class="pre">'auto'</span></code> which indicates PyTorch, TensorFlow, or to
automatically infer
the backend from the <code class="code docutils literal notranslate"><span class="pre">predictor_model</span></code>.
You can also pass in a BackendEngine class.</p></li>
<li><p><strong>predictor_model</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.11)"><em>list</em></a><em>, </em><em>torch.nn.Module</em><em>, </em><a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/keras/Model" title="(in TensorFlow v2.4)"><em>tf.keras.Model</em></a>) – The predictor model to train.
Instead of a neural network model, it is possible to pass a list
<span class="math notranslate nohighlight">\([k_1, k_2, \dots]\)</span>, where each <span class="math notranslate nohighlight">\(k_i\)</span> either indicates
the number of nodes (if <span class="math notranslate nohighlight">\(k_i\)</span> is an integer) or
an activation function (if <span class="math notranslate nohighlight">\(k_i\)</span> is a string) or
a layer or activation function instance directly (if <span class="math notranslate nohighlight">\(k_i\)</span> is
a callable). The default parameter is <code class="code docutils literal notranslate"><span class="pre">[]</span></code>, which indicates
a neural network without any hidden layers.
However, the number of nodes in the input
and output layer are automatically inferred from data, and the final
activation function (such as softmax for categorical
predictors) are inferred from data.
If <code class="code docutils literal notranslate"><span class="pre">backend</span></code> is specified, you cannot pass a model
that uses a different backend.</p></li>
<li><p><strong>adversary_model</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.11)"><em>list</em></a><em>, </em><em>torch.nn.Module</em><em>, </em><a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/keras/Model" title="(in TensorFlow v2.4)"><em>tf.keras.Model</em></a>) – The adversary model to train. Defined similarly as <code class="code docutils literal notranslate"><span class="pre">predictor_model</span></code>.
Must be the same type as the
<code class="code docutils literal notranslate"><span class="pre">predictor_model</span></code>.</p></li>
<li><p><strong>predictor_optimizer</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><em>str</em></a><em>, </em><em>torch.optim</em><em>, </em><em>tensorflow.keras.optimizers</em><em>, </em><em>callable</em><em>, </em><em>default = 'Adam'</em>) – The optimizer class to use. If a string is passed instead, this must be
either ‘SGD’ or ‘Adam’. A corresponding SGD or Adam optimizer is
initialized with the given predictor model and learning rate.
If an instance of a subclass of torch.optim.Optimizer
or tensorflow.keras.optimizers.Optimizer is passed, this
is used directly. If a callable <code class="code docutils literal notranslate"><span class="pre">fn</span></code> is passed, we call this
callable and pass our model, and set the result of this call
as the optimizer, so: <code class="code docutils literal notranslate"><span class="pre">predictor_optimizer=fn(predictor_model)</span></code>.</p></li>
<li><p><strong>adversary_optimizer</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><em>str</em></a><em>, </em><em>torch.optim</em><em>, </em><em>tensorflow.keras.optimizers</em><em>, </em><em>callable</em><em>, </em><em>default = 'Adam'</em>) – The optimizer class to use. Defined similarly as
<code class="code docutils literal notranslate"><span class="pre">predictor_optimizer</span></code>.</p></li>
<li><p><strong>constraints</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><em>str</em></a><em>, </em><em>default = 'demographic_parity'</em>) – The fairness constraint. Must be either ‘demographic_parity’
or ‘equalized_odds’.</p></li>
<li><p><strong>learning_rate</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.11)"><em>float</em></a><em>, </em><em>default = 0.001</em>) – A small number greater than zero to set as a learning rate.</p></li>
<li><p><strong>alpha</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.11)"><em>float</em></a><em>, </em><em>default = 1.0</em>) – A small number <span class="math notranslate nohighlight">\(\alpha\)</span> as specified in the paper. It
is the factor that balances the training towards predicting <code class="code docutils literal notranslate"><span class="pre">y</span></code>
(choose <span class="math notranslate nohighlight">\(\alpha\)</span> closer to zero) or enforcing fairness constraint
(choose larger <span class="math notranslate nohighlight">\(\alpha\)</span>).</p></li>
<li><p><strong>epochs</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.11)"><em>int</em></a><em>, </em><em>default = 1</em>) – Number of epochs to train for.</p></li>
<li><p><strong>batch_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.11)"><em>int</em></a><em>, </em><em>default = 32</em>) – Batch size. For no batching, set this to -1.</p></li>
<li><p><strong>shuffle</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.11)"><em>bool</em></a><em>, </em><em>default = False</em>) – When true, shuffle the data before every epoch (including the first).</p></li>
<li><p><strong>progress_updates</strong> (<em>number</em><em>, </em><em>optional</em><em>, </em><em>default = None</em>) – If a number <span class="math notranslate nohighlight">\(t\)</span> is provided, we print an update
about the training loop after processing a batch and <span class="math notranslate nohighlight">\(t\)</span> seconds
have passed since the previous update.</p></li>
<li><p><strong>skip_validation</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.11)"><em>bool</em></a><em>, </em><em>default = False</em>) – Skip the validation of the data. Useful because validate_input is
a costly operation, and we may instead pass all data to validate_input
at an earlier stage. Note that not only checking <code class="code docutils literal notranslate"><span class="pre">X</span></code>
is skipped, but also no tranform is applied to <code class="code docutils literal notranslate"><span class="pre">y</span></code> and
<code class="code docutils literal notranslate"><span class="pre">sensitive_features</span></code>.</p></li>
<li><p><strong>callbacks</strong> (<em>callable</em>) – Callback function, called after every batch. For instance useable when
wanting to validate. A list of callback functions can also be provided.
Each callback function is passed two arguments <code class="code docutils literal notranslate"><span class="pre">self</span></code> (the
estimator instance) and <code class="code docutils literal notranslate"><span class="pre">step</span></code> (the completed iteration), and
may return a Boolean value. If the returned value is <cite>True</cite>, the
optimization algorithm terminates. This can be used to implement
<em>early stopping</em>.</p></li>
<li><p><strong>cuda</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><em>str</em></a><em>, </em><em>default = None</em>) – A string to indicate which device to use when training. For instance,
set <code class="code docutils literal notranslate"><span class="pre">cuda='cuda:0'</span></code> to train on the first GPU. Only for PyTorch
backend.</p></li>
<li><p><strong>warm_start</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.11)"><em>bool</em></a><em>, </em><em>default = False</em>) – Normally, when set to False, a call to <code class="code docutils literal notranslate"><span class="pre">fit()</span></code> triggers reinitialization,
which discards the models and intializes them again. Setting to
True triggers reuse of these models. Note: if pre-initialized models
are passed, the models (and their parameters) are never discarded.</p></li>
<li><p><strong>random_state</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.11)"><em>int</em></a><em>, </em><em>RandomState</em><em>, </em><em>default = None</em>) – Controls the randomized aspects of this algorithm, such as shuffling.
Useful to get reproducible output across multiple function calls.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="citation">
<dt class="label" id="r88ef1dc9a4f5-1"><span class="brackets"><a class="fn-backref" href="#id1">1</a></span></dt>
<dd><p>Zhang, Lemoine, Mitchell <a class="reference external" href="https://dl.acm.org/doi/pdf/10.1145/3278721.3278779">“Mitigating Unwanted Biases with
Adversarial Learning”</a>,
AIES, 2018.</p>
</dd>
</dl>
<p class="rubric">Methods</p>
<table class="autosummary longtable table autosummary">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">decision_function</span></code>(X)</p></td>
<td><p>Compute predictor output for given test data.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">fit</span></code>(X, y, *[, sensitive_features])</p></td>
<td><p>Fit the model based on the given training data and sensitive features.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_params</span></code>([deep])</p></td>
<td><p>Get parameters for this estimator.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">partial_fit</span></code>(X, y, *[, sensitive_features])</p></td>
<td><p>Perform one epoch on given samples and update model.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">predict</span></code>(X)</p></td>
<td><p>Compute predictions for given test data.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">score</span></code>(X, y[, sample_weight])</p></td>
<td><p>Return the mean accuracy on the given test data and labels.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_params</span></code>(**params)</p></td>
<td><p>Set the parameters of this estimator.</p></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="fairlearn.adversarial.AdversarialFairnessRegressor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">fairlearn.adversarial.</span></span><span class="sig-name descname"><span class="pre">AdversarialFairnessRegressor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">backend</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">predictor_model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">adversary_model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">predictor_optimizer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'Adam'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">adversary_optimizer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'Adam'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'demographic_parity'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epochs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">32</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shuffle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">progress_updates</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">skip_validation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cuda</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">warm_start</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="http://github.com/fairlearn/fairlearn/blob/v0.8.0/fairlearn/adversarial/_adversarial_mitigation.py#L1005-L1194"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#fairlearn.adversarial.AdversarialFairnessRegressor" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">fairlearn.adversarial._adversarial_mitigation._AdversarialFairness</span></code>, <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.base.RegressorMixin.html#sklearn.base.RegressorMixin" title="(in scikit-learn v1.1)"><code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.base.RegressorMixin</span></code></a></p>
<p>Train PyTorch or TensorFlow regressors while mitigating unfairness.</p>
<p>This estimator implements the supervised learning method proposed in
<a class="reference external" href="https://dl.acm.org/doi/pdf/10.1145/3278721.3278779">“Mitigating Unwanted Biases with Adversarial Learning”</a> <a class="reference internal" href="#rcde887200b43-1" id="id4">[1]</a>.
The training algorithm takes as input two neural network
models, a predictor model and an adversarial model, defined either as a
<a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html">PyTorch module</a> or
<a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/keras/Model">TensorFlow2 model</a>. The API
follows conventions of <cite>sklearn</cite> estimators.</p>
<p>The regressor model takes the features <code class="code docutils literal notranslate"><span class="pre">X</span></code> as input and seeks
to predict <code class="code docutils literal notranslate"><span class="pre">y</span></code>.
The training loss is measured using the squared error.</p>
<p>The adversarial model for demographic parity takes scores
produced by the predictor model as input, and seeks to predict
<code class="code docutils literal notranslate"><span class="pre">sensitive_features</span></code>. Depending on the type of the provided
sensitive features, the model should produce a scalar
or vector output. Three types of sensitive features are supported:
(1) a single binary feature; (2) a single discrete feature; (3) one or
multiple real-valued features. For a single binary sensitive feature
and a single discrete feature, the network outputs are transformed
by the logistic function and the softmax function, respectively, and
the loss is the negative log likelihood. For one or multiple
real-valued features, the network output is left as is, and the
loss is a square loss.</p>
<p>The adversarial model for equalized odds additionaly takes
<code class="code docutils literal notranslate"><span class="pre">y</span></code> as input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>backend</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><em>str</em></a><em>, </em><em>BackendEngine</em><em>, </em><em>default = 'auto'</em>) – The backend to use. Must be one of <code class="code docutils literal notranslate"><span class="pre">'torch'</span></code>, <code class="code docutils literal notranslate"><span class="pre">'tensorflow'</span></code>,
or <code class="code docutils literal notranslate"><span class="pre">'auto'</span></code> which indicates PyTorch, TensorFlow, or to
automatically infer
the backend from the <code class="code docutils literal notranslate"><span class="pre">predictor_model</span></code>.
You can also pass in a BackendEngine class.</p></li>
<li><p><strong>predictor_model</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.11)"><em>list</em></a><em>, </em><em>torch.nn.Module</em><em>, </em><a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/keras/Model" title="(in TensorFlow v2.4)"><em>tf.keras.Model</em></a>) – The predictor model to train.
Instead of a neural network model, it is possible to pass a list
<span class="math notranslate nohighlight">\([k_1, k_2, \dots]\)</span>, where each <span class="math notranslate nohighlight">\(k_i\)</span> either indicates
the number of nodes (if <span class="math notranslate nohighlight">\(k_i\)</span> is an integer) or
an activation function (if <span class="math notranslate nohighlight">\(k_i\)</span> is a string) or
a layer or activation function instance directly (if <span class="math notranslate nohighlight">\(k_i\)</span> is
a callable). The default parameter is <code class="code docutils literal notranslate"><span class="pre">[]</span></code>, which indicates
a neural network without any hidden layers.
However, the number of nodes in the input
and output layer are automatically inferred from data, and the final
activation function (such as softmax for categorical
predictors) are inferred from data.
If <code class="code docutils literal notranslate"><span class="pre">backend</span></code> is specified, you cannot pass a model
that uses a different backend.</p></li>
<li><p><strong>adversary_model</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.11)"><em>list</em></a><em>, </em><em>torch.nn.Module</em><em>, </em><a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/keras/Model" title="(in TensorFlow v2.4)"><em>tf.keras.Model</em></a>) – The adversary model to train. Defined similarly as <code class="code docutils literal notranslate"><span class="pre">predictor_model</span></code>.
Must be the same type as the
<code class="code docutils literal notranslate"><span class="pre">predictor_model</span></code>.</p></li>
<li><p><strong>predictor_optimizer</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><em>str</em></a><em>, </em><em>torch.optim</em><em>, </em><em>tensorflow.keras.optimizers</em><em>, </em><em>callable</em><em>, </em><em>default = 'Adam'</em>) – The optimizer class to use. If a string is passed instead, this must be
either ‘SGD’ or ‘Adam’. A corresponding SGD or Adam optimizer is
initialized with the given predictor model and learning rate.
If an instance of a subclass of torch.optim.Optimizer
or tensorflow.keras.optimizers.Optimizer is passed, this
is used directly. If a callable <code class="code docutils literal notranslate"><span class="pre">fn</span></code> is passed, we call this
callable and pass our model, and set the result of this call
as the optimizer, so: <code class="code docutils literal notranslate"><span class="pre">predictor_optimizer=fn(predictor_model)</span></code>.</p></li>
<li><p><strong>adversary_optimizer</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><em>str</em></a><em>, </em><em>torch.optim</em><em>, </em><em>tensorflow.keras.optimizers</em><em>, </em><em>callable</em><em>, </em><em>default = 'Adam'</em>) – The optimizer class to use. Defined similarly as
<code class="code docutils literal notranslate"><span class="pre">predictor_optimizer</span></code>.</p></li>
<li><p><strong>constraints</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><em>str</em></a><em>, </em><em>default = 'demographic_parity'</em>) – The fairness constraint. Must be either ‘demographic_parity’
or ‘equalized_odds’.</p></li>
<li><p><strong>learning_rate</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.11)"><em>float</em></a><em>, </em><em>default = 0.001</em>) – A small number greater than zero to set as a learning rate.</p></li>
<li><p><strong>alpha</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.11)"><em>float</em></a><em>, </em><em>default = 1.0</em>) – A small number <span class="math notranslate nohighlight">\(\alpha\)</span> as specified in the paper. It
is the factor that balances the training towards predicting <code class="code docutils literal notranslate"><span class="pre">y</span></code>
(choose <span class="math notranslate nohighlight">\(\alpha\)</span> closer to zero) or enforcing fairness constraint
(choose larger <span class="math notranslate nohighlight">\(\alpha\)</span>).</p></li>
<li><p><strong>epochs</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.11)"><em>int</em></a><em>, </em><em>default = 1</em>) – Number of epochs to train for.</p></li>
<li><p><strong>batch_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.11)"><em>int</em></a><em>, </em><em>default = 32</em>) – Batch size. For no batching, set this to -1.</p></li>
<li><p><strong>shuffle</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.11)"><em>bool</em></a><em>, </em><em>default = False</em>) – When true, shuffle the data before every epoch (including the first).</p></li>
<li><p><strong>progress_updates</strong> (<em>number</em><em>, </em><em>optional</em><em>, </em><em>default = None</em>) – If a number <span class="math notranslate nohighlight">\(t\)</span> is provided, we print an update
about the training loop after processing a batch and <span class="math notranslate nohighlight">\(t\)</span> seconds
have passed since the previous update.</p></li>
<li><p><strong>skip_validation</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.11)"><em>bool</em></a><em>, </em><em>default = False</em>) – Skip the validation of the data. Useful because validate_input is
a costly operation, and we may instead pass all data to validate_input
at an earlier stage. Note that not only checking <code class="code docutils literal notranslate"><span class="pre">X</span></code>
is skipped, but also no tranform is applied to <code class="code docutils literal notranslate"><span class="pre">y</span></code> and
<code class="code docutils literal notranslate"><span class="pre">sensitive_features</span></code>.</p></li>
<li><p><strong>callbacks</strong> (<em>callable</em>) – Callback function, called after every batch. For instance useable when
wanting to validate. A list of callback functions can also be provided.
Each callback function is passed two arguments <code class="code docutils literal notranslate"><span class="pre">self</span></code> (the
estimator instance) and <code class="code docutils literal notranslate"><span class="pre">step</span></code> (the completed iteration), and
may return a Boolean value. If the returned value is <cite>True</cite>, the
optimization algorithm terminates. This can be used to implement
<em>early stopping</em>.</p></li>
<li><p><strong>cuda</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><em>str</em></a><em>, </em><em>default = None</em>) – A string to indicate which device to use when training. For instance,
set <code class="code docutils literal notranslate"><span class="pre">cuda='cuda:0'</span></code> to train on the first GPU. Only for PyTorch
backend.</p></li>
<li><p><strong>warm_start</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.11)"><em>bool</em></a><em>, </em><em>default = False</em>) – Normally, when set to False, a call to <code class="code docutils literal notranslate"><span class="pre">fit()</span></code> triggers reinitialization,
which discards the models and intializes them again. Setting to
True triggers reuse of these models. Note: if pre-initialized models
are passed, the models (and their parameters) are never discarded.</p></li>
<li><p><strong>random_state</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.11)"><em>int</em></a><em>, </em><em>RandomState</em><em>, </em><em>default = None</em>) – Controls the randomized aspects of this algorithm, such as shuffling.
Useful to get reproducible output across multiple function calls.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="citation">
<dt class="label" id="rcde887200b43-1"><span class="brackets"><a class="fn-backref" href="#id4">1</a></span></dt>
<dd><p>Zhang, Lemoine, Mitchell <a class="reference external" href="https://dl.acm.org/doi/pdf/10.1145/3278721.3278779">“Mitigating Unwanted Biases with
Adversarial Learning”</a>,
AIES, 2018.</p>
</dd>
</dl>
<p class="rubric">Methods</p>
<table class="autosummary longtable table autosummary">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">decision_function</span></code>(X)</p></td>
<td><p>Compute predictor output for given test data.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">fit</span></code>(X, y, *[, sensitive_features])</p></td>
<td><p>Fit the model based on the given training data and sensitive features.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_params</span></code>([deep])</p></td>
<td><p>Get parameters for this estimator.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">partial_fit</span></code>(X, y, *[, sensitive_features])</p></td>
<td><p>Perform one epoch on given samples and update model.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">predict</span></code>(X)</p></td>
<td><p>Compute predictions for given test data.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">score</span></code>(X, y[, sample_weight])</p></td>
<td><p>Return the coefficient of determination of the prediction.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_params</span></code>(**params)</p></td>
<td><p>Set the parameters of this estimator.</p></td>
</tr>
</tbody>
</table>
</dd></dl>

</section>


              </article>
              

              
          </div>
          
      </div>
    </div>

  
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=92025949c220c2e29695"></script>

<footer class="bd-footer"><div class="bd-footer__inner container">
  
  <div class="footer-item">
    <p class="copyright">
    &copy; Copyright 2018 - 2022, Fairlearn contributors.<br>
</p>
  </div>
  
  <div class="footer-item">
    <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 4.5.0.<br>
</p>
  </div>
  
</div>
</footer>
  </body>
</html>