
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Binary Classification on COMPAS dataset &#8212; Fairlearn 0.4.6 documentation</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet" />
  <link href="../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/basic.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/custom.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.1c5a1a01449ed65a7b51.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>window.MathJax = {"tex": {"macros": {"E": "{\\mathbb{E}}", "P": "{\\mathbb{P}}", "given": "\\mathbin{\\vert}"}}}</script>
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Contribution Guide" href="../contribution_guide.html" />
    <link rel="prev" title="Example Notebooks" href="index.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    

<a class="navbar-brand" href="https://fairlearn.org">
  <img src="../_static/fairlearn_full_color.svg" class="logo" alt="logo">
</a>


    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../quickstart.html">
  Quickstart
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../user_guide/main.html">
  User Guide
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../api_reference/main.html">
  API Reference
 </a>
</li>

<li class="toctree-l1 current active nav-item">
 <a class="reference internal nav-link" href="index.html">
  Example Notebooks
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../contribution_guide.html">
  Contribution Guide
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../community.html">
  Community
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/fairlearn/fairlearn" rel="noopener" target="_blank" title="GitHub">
            <span><i class="fab fa-github"></i></span>
            <label class="sr-only">GitHub</label>
          </a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="https://twitter.com/fairlearn" rel="noopener" target="_blank" title="Twitter">
            <span><i class="fab fa-twitter"></i></span>
            <label class="sr-only">Twitter</label>
          </a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="https://stackoverflow.com/questions/tagged/fairlearn" rel="noopener" target="_blank" title="StackOverflow">
            <span><i class="fab fa-stack-overflow"></i></span>
            <label class="sr-only">StackOverflow</label>
          </a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="https://discord.gg/R22yCfgsRn" rel="noopener" target="_blank" title="Discord">
            <span><i class="fab fa-discord"></i></span>
            <label class="sr-only">Discord</label>
          </a>
        </li>
      </ul>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar"><div class="sidebar-message">
  
  <h4>Versions</h4>
  <ul>
      
        
          <li><strong><a href="plot_binary_classification_COMPAS.html">v0.4.6</a></strong></li>
        
      
      
        <li>v0.5.0: Documentation page not present</li>
      
      
        <li>v0.6.2: Documentation page not present</li>
      
      
        <li>v0.7.0: Documentation page not present</li>
      
      
        <li>main: Documentation page not present</li>
      
  </ul>
  
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Binary Classification on COMPAS dataset
  </a>
 </li>
</ul>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Binary Classification on COMPAS dataset
  </a>
 </li>
</ul>

  </div>
</nav>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
              
              <div class="toc-item">
                
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#getting-and-preparing-the-data">
   Getting and preparing the data
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#create-a-fairness-unaware-model">
   Create a fairness-unaware model
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#postprocessing-the-model-to-get-a-fair-model">
   Postprocessing the model to get a fair model
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#post-processing-in-detail">
   Post Processing in Detail
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#finding-threshold-rules">
     Finding threshold rules
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#interpolated-predictions-and-probabilistic-classifiers">
     Interpolated Predictions and Probabilistic Classifiers
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#finding-the-equalized-odds-solution">
     Finding the Equalized Odds solution
    </a>
   </li>
  </ul>
 </li>
</ul>

</nav>
              </div>
              
              <div class="toc-item">
                
              </div>
              
            
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-auto-examples-plot-binary-classification-compas-py"><span class="std std-ref">here</span></a>
to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="binary-classification-on-compas-dataset">
<span id="sphx-glr-auto-examples-plot-binary-classification-compas-py"></span><h1>Binary Classification on COMPAS dataset<a class="headerlink" href="#binary-classification-on-compas-dataset" title="Permalink to this headline">Â¶</a></h1>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="vm">__doc__</span><span class="p">)</span>
</pre></div>
</div>
<div class="section" id="getting-and-preparing-the-data">
<h2>Getting and preparing the data<a class="headerlink" href="#getting-and-preparing-the-data" title="Permalink to this headline">Â¶</a></h2>
<p>To demonstrate the post processing algorithm we use the âCOMPASâ dataset from
<a class="reference external" href="https://raw.githubusercontent.com/propublica/compas-analysis/master/compas-scores-two-years.csv">ProPublica</a>.
The labels represent the two-year recidivism ID, i.e. whether a person got
rearrested within two years (label 1) or not (label 0). The features include
sex, age, as well as information on prior incidents.</p>
<p>To start, letâs download the dataset using <cite>tempeh</cite></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">tempeh.configurations</span> <span class="kn">import</span> <span class="n">datasets</span>

<span class="n">compas_dataset</span> <span class="o">=</span> <span class="n">datasets</span><span class="p">[</span><span class="s2">&quot;compas&quot;</span><span class="p">]()</span>
<a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.core.frame.DataFrame" class="sphx-glr-backref-module-pandas-core-frame sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">X_train</span></a><span class="p">,</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.core.frame.DataFrame" class="sphx-glr-backref-module-pandas-core-frame sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">X_test</span></a> <span class="o">=</span> <span class="n">compas_dataset</span><span class="o">.</span><span class="n">get_X</span><span class="p">(</span><span class="nb">format</span><span class="o">=</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.core.frame.DataFrame" class="sphx-glr-backref-module-pandas-core-frame sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">)</span>
<a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html#pandas.Series" title="pandas.core.series.Series" class="sphx-glr-backref-module-pandas-core-series sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">y_train</span></a><span class="p">,</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html#pandas.Series" title="pandas.core.series.Series" class="sphx-glr-backref-module-pandas-core-series sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">y_test</span></a> <span class="o">=</span> <span class="n">compas_dataset</span><span class="o">.</span><span class="n">get_y</span><span class="p">(</span><span class="nb">format</span><span class="o">=</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html#pandas.Series" title="pandas.core.series.Series" class="sphx-glr-backref-module-pandas-core-series sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">Series</span></a><span class="p">)</span>
<span class="p">(</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html#pandas.Series" title="pandas.core.series.Series" class="sphx-glr-backref-module-pandas-core-series sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">sensitive_features_train</span></a><span class="p">,</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html#pandas.Series" title="pandas.core.series.Series" class="sphx-glr-backref-module-pandas-core-series sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">sensitive_features_test</span></a><span class="p">,</span>
<span class="p">)</span> <span class="o">=</span> <span class="n">compas_dataset</span><span class="o">.</span><span class="n">get_sensitive_features</span><span class="p">(</span><span class="s2">&quot;race&quot;</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html#pandas.Series" title="pandas.core.series.Series" class="sphx-glr-backref-module-pandas-core-series sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">Series</span></a><span class="p">)</span>
<a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-property"><span class="n">X_train</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html#pandas.Series" title="pandas.core.series.Series" class="sphx-glr-backref-module-pandas-core-series sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">y_train</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>(age                        25.000000
juv_fel_count               0.000000
juv_misd_count             -2.340451
juv_other_count             1.000000
priors_count              -15.010999
age_cat_25 - 45             1.000000
age_cat_Greater than 45     0.000000
age_cat_Less than 25        0.000000
c_charge_degree_F           0.000000
c_charge_degree_M           1.000000
Name: 0, dtype: float64, 1.0)
</pre></div>
</div>
</div>
<div class="section" id="create-a-fairness-unaware-model">
<h2>Create a fairness-unaware model<a class="headerlink" href="#create-a-fairness-unaware-model" title="Permalink to this headline">Â¶</a></h2>
<p>First we set up a helper function that will help in analyzing the dataset as
well as predictions from our models. Feel free to skip to the next cell for
the actual logic.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">matplotlib.cm</span> <span class="k">as</span> <span class="nn">cm</span>


<span class="c1"># show_proportions is only a helper function for plotting</span>
<span class="k">def</span> <span class="nf">show_proportions</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">sensitive_features</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">plot_row_index</span><span class="o">=</span><span class="mi">1</span>
<span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="n">description</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">plot_row_index</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">description</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;P[recidivism predicted | conditions]&quot;</span><span class="p">)</span>

    <span class="n">indices</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">positive_indices</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">negative_indices</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">recidivism_count</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">recidivism_pct</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">groups</span> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.unique.html#numpy.unique" title="numpy.unique" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">unique</span></a><span class="p">(</span><span class="n">sensitive_features</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
    <span class="n">n_groups</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">groups</span><span class="p">)</span>
    <span class="n">max_group_length</span> <span class="o">=</span> <span class="nb">max</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">group</span><span class="p">)</span> <span class="k">for</span> <span class="n">group</span> <span class="ow">in</span> <span class="n">groups</span><span class="p">])</span>
    <span class="n">color</span> <span class="o">=</span> <span class="n">cm</span><span class="o">.</span><span class="n">rainbow</span><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.linspace.html#numpy.linspace" title="numpy.linspace" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">linspace</span></a><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n_groups</span><span class="p">))</span>
    <span class="n">x_tick_labels_basic</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">x_tick_labels_by_label</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">group</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">groups</span><span class="p">):</span>
        <span class="n">indices</span><span class="p">[</span><span class="n">group</span><span class="p">]</span> <span class="o">=</span> <span class="n">sensitive_features</span><span class="o">.</span><span class="n">index</span><span class="p">[</span><span class="n">sensitive_features</span> <span class="o">==</span> <span class="n">group</span><span class="p">]</span>
        <span class="n">recidivism_count</span><span class="p">[</span><span class="n">group</span><span class="p">]</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">y_pred</span><span class="p">[</span><span class="n">indices</span><span class="p">[</span><span class="n">group</span><span class="p">]])</span>
        <span class="n">recidivism_pct</span><span class="p">[</span><span class="n">group</span><span class="p">]</span> <span class="o">=</span> <span class="n">recidivism_count</span><span class="p">[</span><span class="n">group</span><span class="p">]</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">indices</span><span class="p">[</span><span class="n">group</span><span class="p">])</span>
        <span class="nb">print</span><span class="p">(</span>
            <span class="s2">&quot;P[recidivism predicted | </span><span class="si">{}</span><span class="s2">]                </span><span class="si">{}</span><span class="s2">= </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                <span class="n">group</span><span class="p">,</span> <span class="s2">&quot; &quot;</span> <span class="o">*</span> <span class="p">(</span><span class="n">max_group_length</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">group</span><span class="p">)),</span> <span class="n">recidivism_pct</span><span class="p">[</span><span class="n">group</span><span class="p">]</span>
            <span class="p">)</span>
        <span class="p">)</span>

        <span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">index</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">recidivism_pct</span><span class="p">[</span><span class="n">group</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">[</span><span class="n">index</span><span class="p">])</span>
        <span class="n">x_tick_labels_basic</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">group</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">y</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">positive_indices</span><span class="p">[</span><span class="n">group</span><span class="p">]</span> <span class="o">=</span> <span class="n">sensitive_features</span><span class="o">.</span><span class="n">index</span><span class="p">[</span>
                <span class="p">(</span><span class="n">sensitive_features</span> <span class="o">==</span> <span class="n">group</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">y</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span>
            <span class="p">]</span>
            <span class="n">negative_indices</span><span class="p">[</span><span class="n">group</span><span class="p">]</span> <span class="o">=</span> <span class="n">sensitive_features</span><span class="o">.</span><span class="n">index</span><span class="p">[</span>
                <span class="p">(</span><span class="n">sensitive_features</span> <span class="o">==</span> <span class="n">group</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">y</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span>
            <span class="p">]</span>
            <span class="n">prob_1</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">y_pred</span><span class="p">[</span><span class="n">positive_indices</span><span class="p">[</span><span class="n">group</span><span class="p">]])</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">positive_indices</span><span class="p">[</span><span class="n">group</span><span class="p">])</span>
            <span class="n">prob_0</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">y_pred</span><span class="p">[</span><span class="n">negative_indices</span><span class="p">[</span><span class="n">group</span><span class="p">]])</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">negative_indices</span><span class="p">[</span><span class="n">group</span><span class="p">])</span>
            <span class="nb">print</span><span class="p">(</span>
                <span class="s2">&quot;P[recidivism predicted | </span><span class="si">{}</span><span class="s2">, recidivism]    </span><span class="si">{}</span><span class="s2">= </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="n">group</span><span class="p">,</span> <span class="s2">&quot; &quot;</span> <span class="o">*</span> <span class="p">(</span><span class="n">max_group_length</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">group</span><span class="p">)),</span> <span class="n">prob_1</span>
                <span class="p">)</span>
            <span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span>
                <span class="s2">&quot;P[recidivism predicted | </span><span class="si">{}</span><span class="s2">, no recidivism] </span><span class="si">{}</span><span class="s2">= </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="n">group</span><span class="p">,</span> <span class="s2">&quot; &quot;</span> <span class="o">*</span> <span class="p">(</span><span class="n">max_group_length</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">group</span><span class="p">)),</span> <span class="n">prob_0</span>
                <span class="p">)</span>
            <span class="p">)</span>

            <span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">n_groups</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">index</span><span class="p">,</span> <span class="n">prob_1</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">[</span><span class="n">index</span><span class="p">])</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">n_groups</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">index</span><span class="p">,</span> <span class="n">prob_0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">[</span><span class="n">index</span><span class="p">])</span>
            <span class="n">x_tick_labels_by_label</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span>
                <span class="p">[</span><span class="s2">&quot;</span><span class="si">{}</span><span class="s2"> recidivism&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">group</span><span class="p">),</span> <span class="s2">&quot;</span><span class="si">{}</span><span class="s2"> no recidivism&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">group</span><span class="p">)]</span>
            <span class="p">)</span>

    <span class="n">x_tick_labels</span> <span class="o">=</span> <span class="n">x_tick_labels_basic</span> <span class="o">+</span> <span class="n">x_tick_labels_by_label</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span>
        <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">x_tick_labels</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span>
        <span class="n">x_tick_labels</span><span class="p">,</span>
        <span class="n">rotation</span><span class="o">=</span><span class="mi">45</span><span class="p">,</span>
        <span class="n">horizontalalignment</span><span class="o">=</span><span class="s2">&quot;right&quot;</span><span class="p">,</span>
    <span class="p">)</span>
</pre></div>
</div>
<p>To get started we look at a very basic Logistic Regression model. We fit it
to the training data and plot some characteristics of training and test data
as well as the predictions of the model on those datasets.</p>
<p>We notice a stark contrast in the predictions with African-Americans being a
lot more likely to be predicted to reoffend, similar to the original training
data. However, thereâs even a disparity between the subgroup of
African-Americans and Caucasians with recidivism. When considering only the
samples labeled with âno recidivismâ African-Americans are much more likely
to be predicted to reoffend than Caucasians. The test data shows a similar
disparity.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression" title="sklearn.linear_model.LogisticRegression" class="sphx-glr-backref-module-sklearn-linear_model sphx-glr-backref-type-py-class"><span class="n">LogisticRegression</span></a>

<a href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression" title="sklearn.linear_model.LogisticRegression" class="sphx-glr-backref-module-sklearn-linear_model sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">estimator</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression" title="sklearn.linear_model.LogisticRegression" class="sphx-glr-backref-module-sklearn-linear_model sphx-glr-backref-type-py-class"><span class="n">LogisticRegression</span></a><span class="p">(</span><span class="n">solver</span><span class="o">=</span><span class="s2">&quot;liblinear&quot;</span><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression.fit" title="sklearn.linear_model.LogisticRegression.fit" class="sphx-glr-backref-module-sklearn-linear_model sphx-glr-backref-type-py-method"><span class="n">estimator</span><span class="o">.</span><span class="n">fit</span></a><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.core.frame.DataFrame" class="sphx-glr-backref-module-pandas-core-frame sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">X_train</span></a><span class="p">,</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html#pandas.Series" title="pandas.core.series.Series" class="sphx-glr-backref-module-pandas-core-series sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">y_train</span></a><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>LogisticRegression(solver=&#39;liblinear&#39;)
</pre></div>
</div>
<p>print and plot data from training and test set as well as predictions with
fairness-unaware classifier on both sets show only test data related plots by
default - uncomment the next two lines to see training data plots as well</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># show_proportions(X_train, sensitive_features_train, y_train,</span>
<span class="c1">#                  description=&quot;original training data:&quot;, plot_row_index=1)</span>
<span class="c1"># show_proportions(X_train, sensitive_features_train,</span>
<span class="c1">#                  estimator.predict(X_train), y_train,</span>
<span class="c1">#                  description=&quot;fairness-unaware prediction on training data:&quot;,</span>
<span class="c1">#                  plot_row_index=2)</span>
<span class="n">show_proportions</span><span class="p">(</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.core.frame.DataFrame" class="sphx-glr-backref-module-pandas-core-frame sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">X_test</span></a><span class="p">,</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html#pandas.Series" title="pandas.core.series.Series" class="sphx-glr-backref-module-pandas-core-series sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">sensitive_features_test</span></a><span class="p">,</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html#pandas.Series" title="pandas.core.series.Series" class="sphx-glr-backref-module-pandas-core-series sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">y_test</span></a><span class="p">,</span>
    <span class="n">description</span><span class="o">=</span><span class="s2">&quot;original test data:&quot;</span><span class="p">,</span>
    <span class="n">plot_row_index</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">show_proportions</span><span class="p">(</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.core.frame.DataFrame" class="sphx-glr-backref-module-pandas-core-frame sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">X_test</span></a><span class="p">,</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html#pandas.Series" title="pandas.core.series.Series" class="sphx-glr-backref-module-pandas-core-series sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">sensitive_features_test</span></a><span class="p">,</span>
    <a href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression.predict" title="sklearn.linear_model.LogisticRegression.predict" class="sphx-glr-backref-module-sklearn-linear_model sphx-glr-backref-type-py-method"><span class="n">estimator</span><span class="o">.</span><span class="n">predict</span></a><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.core.frame.DataFrame" class="sphx-glr-backref-module-pandas-core-frame sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">X_test</span></a><span class="p">),</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html#pandas.Series" title="pandas.core.series.Series" class="sphx-glr-backref-module-pandas-core-series sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">y_test</span></a><span class="p">,</span>
    <span class="n">description</span><span class="o">=</span><span class="s2">&quot;fairness-unaware prediction on test data:&quot;</span><span class="p">,</span>
    <span class="n">plot_row_index</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<ul class="sphx-glr-horizontal">
<li><img src="../_images/sphx_glr_plot_binary_classification_COMPAS_001.png" srcset="../_images/sphx_glr_plot_binary_classification_COMPAS_001.png" alt="original test data:" class = "sphx-glr-multi-img"/></li>
<li><img src="../_images/sphx_glr_plot_binary_classification_COMPAS_002.png" srcset="../_images/sphx_glr_plot_binary_classification_COMPAS_002.png" alt="fairness-unaware prediction on test data:" class = "sphx-glr-multi-img"/></li>
</ul>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>original test data:
P[recidivism predicted | African-American]                = 0.5457198443579766
P[recidivism predicted | Caucasian]                       = 0.3795518207282913

fairness-unaware prediction on test data:
P[recidivism predicted | African-American]                = 0.5155642023346303
P[recidivism predicted | African-American, recidivism]    = 0.661319073083779
P[recidivism predicted | African-American, no recidivism] = 0.3404710920770878
P[recidivism predicted | Caucasian]                       = 0.2815126050420168
P[recidivism predicted | Caucasian, recidivism]           = 0.42435424354243545
P[recidivism predicted | Caucasian, no recidivism]        = 0.19413092550790068
</pre></div>
</div>
</div>
<div class="section" id="postprocessing-the-model-to-get-a-fair-model">
<h2>Postprocessing the model to get a fair model<a class="headerlink" href="#postprocessing-the-model-to-get-a-fair-model" title="Permalink to this headline">Â¶</a></h2>
<p>The idea behind postprocessing is to alter the output of the fairness-unaware
model to achieve fairness. The postprocessing algorithm requires three input
arguments:
- the matrix of samples X
- the vector of predictions y from the fairness-unaware model
- the vector of group attribute values A (in the code we refer to it as <cite>sensitive_features</cite>)</p>
<p>The goal is to make the output fair with respect to constraints. The
postprocessing algorithm uses one of</p>
<ul class="simple">
<li><p>Demographic Parity (DP):
<span class="math notranslate nohighlight">\(P\ [\ h(X)=\hat{y}\ |\ A=a] = P\ [\ h(X)=\hat{y}\ ] \qquad \forall a, \hat{y}\)</span></p></li>
<li><p>Equalized Odds (EO):
<span class="math notranslate nohighlight">\(P\ [\ h(X)=\hat{y}\ |\ A=a, Y=y] = P\ [\ h(X)=\hat{y}\ |\ Y=y\ ] \qquad \forall a, \hat{y}\)</span></p></li>
</ul>
<p>where <span class="math notranslate nohighlight">\(h(X)\)</span> is the prediction based on the input <span class="math notranslate nohighlight">\(X\)</span>,
<span class="math notranslate nohighlight">\(\hat{y}\)</span> and <span class="math notranslate nohighlight">\(y\)</span> are labels, and <span class="math notranslate nohighlight">\(a\)</span> is a sensitive feature
value. In this example, weâd expect the postprocessed model with DP to be
balanced between races. In this particular scenario it makes more sense to
aim at fairness through accuracy like EO. EO does not make the same
guarantees. Instead, it ensures parity between the subgroups of each race
with label 1 in the training set, and parity between the subgroups of each
race with label 0 in the training set. Applied to this scenario, this means
that the subgroups of each race who reoffended in the past are equally likely
to be predicted to reoffend (and therefore also equally likely not to).
Similarly, there is parity between subgroups of each race without recidivism,
but we have no parity between the groups with different training labels. In
mathematical terms at the example of African-American and Caucasian:</p>
<div class="math notranslate nohighlight">
\[P\ [\ \text{recidivism predicted}\ |\ \text{African-American, recidivism}\ ] = P\ [\ \text{recidivism predicted}\ |\ \text{Caucasian, recidivism}\ ], \text{e.g. } 0.95\]</div>
<div class="math notranslate nohighlight">
\[P\ [\ \text{recidivism predicted}\ |\ \text{African-American, no recidivism}\ ] = P\ [\ \text{recidivism predicted}\ |\ \text{Caucasian, no recidivism}\ ], \text{e.g. } 0.15\]</div>
<p>but that also means that African-Americans (and Caucasians) of different
subgroup based on training labels donât necessarily have parity:</p>
<div class="math notranslate nohighlight">
\[P[\text{recidivism predicted} | \text{African-American, recidivism}] = 0.95 \neq 0.15 = P[\text{recidivism predicted} | \text{African-American, no recidivism}]\]</div>
<p>Assessing which disparity metric is indeed fair varies by application
scenario. In this case the evaluation focuses on Equalized Odds, because the
recidivism prediction should be accurate for each race, and for each subgroup
within. The plot for the training data shows the intended outcome, while the
plot for the test data exhibits slight variation which is likely due to
randomized predictions as well as a slightly different data distribution.</p>
<p>This wrapper around the unconstrained estimator serves the purpose of mapping
the predict method to <code class="docutils literal notranslate"><span class="pre">predict_proba`</span></code> so that we can use real values to get
more accurate estimates.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">clone</span>
<span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html#sklearn.base.BaseEstimator" title="sklearn.base.BaseEstimator" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-class"><span class="n">BaseEstimator</span></a><span class="p">,</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.ClassifierMixin.html#sklearn.base.ClassifierMixin" title="sklearn.base.ClassifierMixin" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-class"><span class="n">ClassifierMixin</span></a>
<span class="kn">from</span> <span class="nn">sklearn.utils.validation</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.utils.validation.check_is_fitted.html#sklearn.utils.validation.check_is_fitted" title="sklearn.utils.validation.check_is_fitted" class="sphx-glr-backref-module-sklearn-utils-validation sphx-glr-backref-type-py-function"><span class="n">check_is_fitted</span></a>
<span class="kn">from</span> <span class="nn">sklearn.exceptions</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.exceptions.NotFittedError.html#sklearn.exceptions.NotFittedError" title="sklearn.exceptions.NotFittedError" class="sphx-glr-backref-module-sklearn-exceptions sphx-glr-backref-type-py-class"><span class="n">NotFittedError</span></a>


<span class="k">class</span> <span class="nc">LogisticRegressionAsRegression</span><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html#sklearn.base.BaseEstimator" title="sklearn.base.BaseEstimator" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-class"><span class="n">BaseEstimator</span></a><span class="p">,</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.ClassifierMixin.html#sklearn.base.ClassifierMixin" title="sklearn.base.ClassifierMixin" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-class"><span class="n">ClassifierMixin</span></a><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logistic_regression_estimator</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">logistic_regression_estimator</span> <span class="o">=</span> <span class="n">logistic_regression_estimator</span>

    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="k">try</span><span class="p">:</span>
            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.utils.validation.check_is_fitted.html#sklearn.utils.validation.check_is_fitted" title="sklearn.utils.validation.check_is_fitted" class="sphx-glr-backref-module-sklearn-utils-validation sphx-glr-backref-type-py-function"><span class="n">check_is_fitted</span></a><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">logistic_regression_estimator</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">logistic_regression_estimator_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">logistic_regression_estimator</span>
        <span class="k">except</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.exceptions.NotFittedError.html#sklearn.exceptions.NotFittedError" title="sklearn.exceptions.NotFittedError" class="sphx-glr-backref-module-sklearn-exceptions sphx-glr-backref-type-py-class"><span class="n">NotFittedError</span></a><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">logistic_regression_estimator_</span> <span class="o">=</span> <span class="n">clone</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">logistic_regression_estimator</span>
            <span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="c1"># use predict_proba to get real values instead of 0/1, select only prob for 1</span>
        <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">scores</span></a> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">logistic_regression_estimator_</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
        <span class="k">return</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">scores</span></a>


<span class="kn">from</span> <span class="nn">fairlearn.postprocessing</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html#sklearn.base.BaseEstimator" title="sklearn.base.BaseEstimator" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-class"><span class="n">ThresholdOptimizer</span></a>

<span class="n">estimator_wrapper</span> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html#sklearn.base.BaseEstimator" title="sklearn.base.BaseEstimator" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-class"><span class="n">LogisticRegressionAsRegression</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression" title="sklearn.linear_model.LogisticRegression" class="sphx-glr-backref-module-sklearn-linear_model sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">estimator</span></a><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.core.frame.DataFrame" class="sphx-glr-backref-module-pandas-core-frame sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">X_train</span></a><span class="p">,</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html#pandas.Series" title="pandas.core.series.Series" class="sphx-glr-backref-module-pandas-core-series sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">y_train</span></a><span class="p">)</span>
<span class="n">postprocessed_predictor_EO</span> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html#sklearn.base.BaseEstimator" title="sklearn.base.BaseEstimator" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-class"><span class="n">ThresholdOptimizer</span></a><span class="p">(</span>
    <a href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression" title="sklearn.linear_model.LogisticRegression" class="sphx-glr-backref-module-sklearn-linear_model sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">estimator</span></a><span class="o">=</span><span class="n">estimator_wrapper</span><span class="p">,</span> <span class="n">constraints</span><span class="o">=</span><span class="s2">&quot;equalized_odds&quot;</span><span class="p">,</span> <span class="n">prefit</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>

<span class="n">postprocessed_predictor_EO</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.core.frame.DataFrame" class="sphx-glr-backref-module-pandas-core-frame sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">X_train</span></a><span class="p">,</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html#pandas.Series" title="pandas.core.series.Series" class="sphx-glr-backref-module-pandas-core-series sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">y_train</span></a><span class="p">,</span> <span class="n">sensitive_features</span><span class="o">=</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html#pandas.Series" title="pandas.core.series.Series" class="sphx-glr-backref-module-pandas-core-series sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">sensitive_features_train</span></a>
<span class="p">)</span>

<a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">fairness_aware_predictions_EO_train</span></a> <span class="o">=</span> <span class="n">postprocessed_predictor_EO</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.core.frame.DataFrame" class="sphx-glr-backref-module-pandas-core-frame sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">X_train</span></a><span class="p">,</span> <span class="n">sensitive_features</span><span class="o">=</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html#pandas.Series" title="pandas.core.series.Series" class="sphx-glr-backref-module-pandas-core-series sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">sensitive_features_train</span></a>
<span class="p">)</span>
<a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">fairness_aware_predictions_EO_test</span></a> <span class="o">=</span> <span class="n">postprocessed_predictor_EO</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.core.frame.DataFrame" class="sphx-glr-backref-module-pandas-core-frame sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">X_test</span></a><span class="p">,</span> <span class="n">sensitive_features</span><span class="o">=</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html#pandas.Series" title="pandas.core.series.Series" class="sphx-glr-backref-module-pandas-core-series sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">sensitive_features_test</span></a>
<span class="p">)</span>

<span class="c1"># show only test data related plot by default - uncomment the next line to see</span>
<span class="c1"># training data plot as well</span>

<span class="c1"># show_proportions(</span>
<span class="c1">#     X_train, sensitive_features_train, fairness_aware_predictions_EO_train,</span>
<span class="c1">#     y_train,</span>
<span class="c1">#     description=&quot;equalized odds with postprocessed model on training data:&quot;,</span>
<span class="c1">#     plot_row_index=1)</span>
<span class="n">show_proportions</span><span class="p">(</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.core.frame.DataFrame" class="sphx-glr-backref-module-pandas-core-frame sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">X_test</span></a><span class="p">,</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html#pandas.Series" title="pandas.core.series.Series" class="sphx-glr-backref-module-pandas-core-series sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">sensitive_features_test</span></a><span class="p">,</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">fairness_aware_predictions_EO_test</span></a><span class="p">,</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html#pandas.Series" title="pandas.core.series.Series" class="sphx-glr-backref-module-pandas-core-series sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">y_test</span></a><span class="p">,</span>
    <span class="n">description</span><span class="o">=</span><span class="s2">&quot;equalized odds with postprocessed model on test data:&quot;</span><span class="p">,</span>
    <span class="n">plot_row_index</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<img src="../_images/sphx_glr_plot_binary_classification_COMPAS_003.png" srcset="../_images/sphx_glr_plot_binary_classification_COMPAS_003.png" alt="equalized odds with postprocessed model on test data:" class = "sphx-glr-single-img"/><p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>equalized odds with postprocessed model on test data:
P[recidivism predicted | African-American]                = 0.25583657587548636
P[recidivism predicted | African-American, recidivism]    = 0.3404634581105169
P[recidivism predicted | African-American, no recidivism] = 0.15417558886509636
P[recidivism predicted | Caucasian]                       = 0.23949579831932774
P[recidivism predicted | Caucasian, recidivism]           = 0.3726937269372694
P[recidivism predicted | Caucasian, no recidivism]        = 0.1580135440180587
</pre></div>
</div>
</div>
<div class="section" id="post-processing-in-detail">
<h2>Post Processing in Detail<a class="headerlink" href="#post-processing-in-detail" title="Permalink to this headline">Â¶</a></h2>
<p>While this worked as the numbers show, itâs not entirely obvious how it found
its solution. The following section will provide a deep dive on post
processing for Equalized Odds (EO).</p>
<p>The post processing method (based on work by <a class="reference external" href="https://arxiv.org/pdf/1610.02413.pdf">Hardt, Price,
Srebro</a>) takes a fairness-unaware model
and disparity constraints (such as EO) in the constructor and features (X),
labels (y), and a sensitive feature (sensitive_features) in the fit method.
It subsequently uses the model to make predictions for all samples in X. Note
that these predictions could be 0/1 (as in this example), or more categories,
or even real valued scores. In this case, this looks as follows:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">scores</span></a> <span class="o">=</span> <span class="n">estimator_wrapper</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.core.frame.DataFrame" class="sphx-glr-backref-module-pandas-core-frame sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">X_train</span></a><span class="p">)</span>
<a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">scores</span></a>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>array([0.08207579, 0.43139474, 0.54704338, ..., 0.5663099 , 0.2746925 ,
       0.37253929])
</pre></div>
</div>
<div class="section" id="finding-threshold-rules">
<h3>Finding threshold rules<a class="headerlink" href="#finding-threshold-rules" title="Permalink to this headline">Â¶</a></h3>
<p>The algorithm then tries to find all thresholding rules with which it could
divide the data. Any score for which the thresholding rule evaluates to true
is predicted to be 1. It does that for each group, so in this case for each
race. Depending on the unconstrained predictorâs scores you could have lots
of thresholding rules, between each set of such values. For each rule we just
evaluate the following two probabilities empirically:</p>
<div class="math notranslate nohighlight">
\[P[\hat{Y} = 1 | Y = 0] \text{ which is labeled x below to indicate that it'll be plotted on the x-axis}\]</div>
<div class="math notranslate nohighlight">
\[P[\hat{Y} = 1 | Y = 1] \text{ which is labeled y below to indicate that it'll be plotted on the y-axis}\]</div>
<p>The former is the false negative rate (of that group), while the latter is
the true positive rate (of that group). In this example, the threshold rules
would be the ones shown below:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">fairlearn.postprocessing._threshold_optimizer</span> <span class="kn">import</span> <span class="n">_reformat_and_group_data</span>

<span class="n">data_grouped_by_sensitive_feature</span> <span class="o">=</span> <span class="n">_reformat_and_group_data</span><span class="p">(</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html#pandas.Series" title="pandas.core.series.Series" class="sphx-glr-backref-module-pandas-core-series sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">sensitive_features_train</span></a><span class="p">,</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.astype.html#pandas.Series.astype" title="pandas.Series.astype" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">y_train</span><span class="o">.</span><span class="n">astype</span></a><span class="p">(</span><span class="nb">int</span><span class="p">),</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">scores</span></a>
<span class="p">)</span>
<a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.core.groupby.DataFrameGroupBy.describe.html#pandas.core.groupby.DataFrameGroupBy.describe" title="pandas.core.groupby.DataFrameGroupBy.describe" class="sphx-glr-backref-module-pandas-core-groupby sphx-glr-backref-type-py-method"><span class="n">data_grouped_by_sensitive_feature</span><span class="o">.</span><span class="n">describe</span></a><span class="p">()</span>

<span class="kn">from</span> <span class="nn">fairlearn.postprocessing._roc_curve_utilities</span> <span class="kn">import</span> <span class="n">_calculate_roc_points</span>

<span class="n">roc_points</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">group_name</span><span class="p">,</span> <span class="n">group</span> <span class="ow">in</span> <span class="n">data_grouped_by_sensitive_feature</span><span class="p">:</span>
    <span class="n">roc_points</span><span class="p">[</span><span class="n">group_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">_calculate_roc_points</span><span class="p">(</span>
        <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.core.groupby.GroupBy.get_group.html#pandas.core.groupby.GroupBy.get_group" title="pandas.core.groupby.GroupBy.get_group" class="sphx-glr-backref-module-pandas-core-groupby sphx-glr-backref-type-py-method"><span class="n">data_grouped_by_sensitive_feature</span><span class="o">.</span><span class="n">get_group</span></a><span class="p">(</span><span class="n">group_name</span><span class="p">),</span> <span class="mi">0</span>
    <span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Thresholding rules:&quot;</span><span class="p">)</span>
<span class="n">roc_points</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Thresholding rules:

{&#39;African-American&#39;:              x  ...                operation
0     0.000000  ...                   [&gt;inf]
1     0.000000  ...    [&gt;0.9900687636639462]
2     0.000000  ...    [&gt;0.9833277651688408]
3     0.000000  ...    [&gt;0.9769547709302975]
4     0.000000  ...    [&gt;0.9759584558991194]
...        ...  ...                      ...
1325  0.997135  ...   [&gt;0.07782828780556121]
1326  0.998090  ...   [&gt;0.07110773039018758]
1328  0.999045  ...    [&gt;0.0628409225957082]
1329  0.999045  ...  [&gt;0.049301185293287406]
1330  1.000000  ...                  [&gt;-inf]

[1331 rows x 3 columns], &#39;Caucasian&#39;:             x  ...                operation
0    0.000000  ...                   [&gt;inf]
1    0.000000  ...    [&gt;0.9900788571796195]
2    0.000000  ...    [&gt;0.9841750223687503]
3    0.000000  ...    [&gt;0.9777093594991544]
4    0.000000  ...     [&gt;0.970539859957543]
..        ...  ...                      ...
885  0.995227  ...   [&gt;0.06951543060753071]
886  0.996420  ...   [&gt;0.06209095551282254]
887  0.997613  ...   [&gt;0.04704292461740367]
888  0.998807  ...  [&gt;0.020606227673374417]
889  1.000000  ...                  [&gt;-inf]

[890 rows x 3 columns]}
</pre></div>
</div>
<p>The base points with (x,y) as (0,0) and (1,1) always exist, because that
essentially just means that weâre predicting everything as 0 or everything as
1 regardless of the scores from the fairness-unaware model. Letâs look at
both cases:</p>
<ul class="simple">
<li><p>x=0, y=0, threshold rule â&gt;infâ: more than infinity is impossible, which
means every sample is predicted as 0. That means <span class="math notranslate nohighlight">\(P[\hat{Y} = 1 | Y =
0] = 0\)</span> (represented as x) because the predictions <span class="math notranslate nohighlight">\(\hat{Y}\)</span> are
never 1, and similarly <span class="math notranslate nohighlight">\(P[\hat{Y} = 1 | Y = 1] = 0\)</span> (represented as
y).</p></li>
<li><p>x=1, y=1, threshold rule â&gt;-infâ: more than infinity is always true, which
means every sample is predicted as 1. That means <span class="math notranslate nohighlight">\(P[\hat{Y} = 1 | Y =
0] = 1\)</span> (represented as x) because the predictions <span class="math notranslate nohighlight">\(\hat{Y}\)</span> are
always 1, and similarly <span class="math notranslate nohighlight">\(P[\hat{Y} = 1 | Y = 1] = 1\)</span> (represented as
y).</p></li>
</ul>
<p>The more interesting logic happens in between. The x and y values were
calculated as follows:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">n_group_0</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">n_group_1</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">group_name</span><span class="p">,</span> <span class="n">group</span> <span class="ow">in</span> <span class="n">data_grouped_by_sensitive_feature</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{}</span><span class="s2">:&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">group_name</span><span class="p">))</span>
    <span class="n">n_group_1</span><span class="p">[</span><span class="n">group_name</span><span class="p">]</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">group</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">])</span>
    <span class="n">n_group_0</span><span class="p">[</span><span class="n">group_name</span><span class="p">]</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">group</span><span class="p">)</span> <span class="o">-</span> <span class="n">n_group_1</span><span class="p">[</span><span class="n">group_name</span><span class="p">]</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;    number of samples with label 1: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">n_group_1</span><span class="p">[</span><span class="n">group_name</span><span class="p">]))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;    number of samples with label 0: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">n_group_0</span><span class="p">[</span><span class="n">group_name</span><span class="p">]))</span>

<span class="n">threshold</span> <span class="o">=</span> <span class="mf">0.5</span>
<span class="k">for</span> <span class="n">group_name</span><span class="p">,</span> <span class="n">group</span> <span class="ow">in</span> <span class="n">data_grouped_by_sensitive_feature</span><span class="p">:</span>
    <span class="n">x_group_0_5</span> <span class="o">=</span> <span class="p">(</span>
        <span class="nb">sum</span><span class="p">((</span><span class="n">group</span><span class="p">[</span><span class="s2">&quot;score&quot;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">threshold</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">group</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">))</span>
        <span class="o">/</span> <span class="n">n_group_0</span><span class="p">[</span><span class="n">group_name</span><span class="p">]</span>
    <span class="p">)</span>
    <span class="n">y_group_0_5</span> <span class="o">=</span> <span class="p">(</span>
        <span class="nb">sum</span><span class="p">((</span><span class="n">group</span><span class="p">[</span><span class="s2">&quot;score&quot;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">threshold</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">group</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">))</span>
        <span class="o">/</span> <span class="n">n_group_1</span><span class="p">[</span><span class="n">group_name</span><span class="p">]</span>
    <span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{}</span><span class="s2">:&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">group_name</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;    P[Å¶ = 1 | Y = 0] = </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">x_group_0_5</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;    P[Å¶ = 1 | Y = 1] = </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">y_group_0_5</span><span class="p">))</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>African-American:
    number of samples with label 1: 1100
    number of samples with label 0: 1047
Caucasian:
    number of samples with label 1: 551
    number of samples with label 0: 838
African-American:
    P[Å¶ = 1 | Y = 0] = 0.3390639923591213
    P[Å¶ = 1 | Y = 1] = 0.6845454545454546
Caucasian:
    P[Å¶ = 1 | Y = 0] = 0.18377088305489261
    P[Å¶ = 1 | Y = 1] = 0.4029038112522686
</pre></div>
</div>
<p>Note that it never makes sense to have <span class="math notranslate nohighlight">\(x&gt;y\)</span> because in that case youâre
better off flipping labels, i.e. completely turning around the meaning of the
scores. The method automatically does that unless specified otherwise.</p>
</div>
<div class="section" id="interpolated-predictions-and-probabilistic-classifiers">
<h3>Interpolated Predictions and Probabilistic Classifiers<a class="headerlink" href="#interpolated-predictions-and-probabilistic-classifiers" title="Permalink to this headline">Â¶</a></h3>
<p>This way you end up with a set of points above the diagonal line connecting
(0,0) and (1,1). We calculate the convex hull based on that, because we can
reach any point in between two known thresholding points by interpolation. An
interpolation could be <span class="math notranslate nohighlight">\(p_0 (x_0, y_0) + p_1 (x_1, y_1)\)</span>. For the post
processing algorithm that would mean that we use the rule defined by
<span class="math notranslate nohighlight">\((x_0, y_0, \text{operation}_0)\)</span> <span class="math notranslate nohighlight">\(\quad p_0\)</span> percent of the time,
and the rule defined by <span class="math notranslate nohighlight">\((x_1, y_1, \text{operation}_1)\)</span> <span class="math notranslate nohighlight">\(\quad
p_1\)</span> percent of the time, thus resulting in a probabilistic classifier.
Depending on the data certain fairness objectives can only be accomplished
with probabilistic classifiers. However, not every use case lends itself to
probabilistic classifiers, since it could mean that two people with identical
features are classified differently.</p>
</div>
<div class="section" id="finding-the-equalized-odds-solution">
<h3>Finding the Equalized Odds solution<a class="headerlink" href="#finding-the-equalized-odds-solution" title="Permalink to this headline">Â¶</a></h3>
<p>From all the ROC points (see below) we need to extract the convex hull for
both groups/curves.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">group_name</span><span class="p">,</span> <span class="n">group</span> <span class="ow">in</span> <span class="n">data_grouped_by_sensitive_feature</span><span class="p">:</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">roc_points</span><span class="p">[</span><span class="n">group_name</span><span class="p">]</span><span class="o">.</span><span class="n">x</span><span class="p">,</span> <span class="n">roc_points</span><span class="p">[</span><span class="n">group_name</span><span class="p">]</span><span class="o">.</span><span class="n">y</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;$P [ </span><span class="se">\\</span><span class="s2">hat</span><span class="si">{Y}</span><span class="s2">=1 | Y=0 ]$&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;$P [ </span><span class="se">\\</span><span class="s2">hat</span><span class="si">{Y}</span><span class="s2">=1 | Y=1 ]$&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<img src="../_images/sphx_glr_plot_binary_classification_COMPAS_004.png" srcset="../_images/sphx_glr_plot_binary_classification_COMPAS_004.png" alt="plot binary classification COMPAS" class = "sphx-glr-single-img"/><p>In the Equalized Odds case, we need to find a point where the presented
probabilities (false positive rate, true positive rate, and thereby also true
negative rate and false negative rate) for the corresponding groups match
while minimizing the error, which is equivalent to finding the minimum error
overlap of the convex hulls of the ROC curves. The error in the chart is
smallest in the top left corner. This is done as part of the <cite>fit</cite> step
above, and weâll repeat it here for completeness. The yellow area is the
overlap between the areas under the curve that are reachable with
interpolation for both groups. Of course, this works for more than two groups
as well. The result is that we have interpolated solutions for each group,
i.e. every prediction is calculated as the weighted result of two threshold
rules.</p>
<p>In this particular case the Caucasian curve is always below or matching the
African-American curve. That means that the area under the Caucasian curve is
also identical to the overlap. That does not always happen, though, and
overlaps can be fairly complex with multiple intersecting curves defining its
outline.</p>
<p>We can actually even look up the specific interpolations and interpret the
results. Keep in mind that these interpolations come up with a floating point
number between 0 and 1, and represent the probability of getting 0 or 1 in
the predicted outcome.</p>
<p>The result for African-Americans is a combination of two thresholding rules.
The first rule checks whether the score is above 0.542, the other whether it
is above 0.508. The first rule has a weight of 0.19, which means it
determines 19% of the resulting probability. The second rule determines the
remaining 81%. In the chart the Caucasian curve is below the African-American
curve at the EO solution. This means that there is a slight adjustment
according to the formula presented below.</p>
<p>The Caucasian rules have somewhat lower thresholds: The first ruleâs
threshold is &gt;0.421 and it is basically the deciding factor with a weight of
99.3%, while the second ruleâs threshold is &gt;0.404.</p>
<p>Overall, this means that the postprocessing algorithm learned to get
probabilities consistent with Equalized Odds and minimal error by setting
lower thresholds for Caucasians than for African-Americans. The resulting
probability from the formula below is then the probability to get label 1
from the probabilistic classifier.</p>
<p>Note that this does not necessarily mean itâs fair. It simply enforced the
constraints we asked it to enforce, as described by Equalized Odds. The
societal context plays a crucial role in determining whether this is fair.</p>
<p>The parameters <cite>p_ignore</cite> and <cite>prediction_constant</cite> are irrelevant for cases
where the curves intersect in the minimum error point. When that doesnât
happen, and the minimum error point is only part of one curve, then the
interpolation is adjusted as follows:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">p_ignore</span> <span class="o">*</span> <span class="n">prediction_constant</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">p_ignore</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">p0</span> <span class="o">*</span> <span class="n">operation0</span><span class="p">(</span><span class="n">score</span><span class="p">)</span> <span class="o">+</span> <span class="n">p1</span> <span class="o">*</span> <span class="n">operation1</span><span class="p">(</span><span class="n">score</span><span class="p">))</span>
</pre></div>
</div>
<p>The adjustment should happen to the higher one of the curves and essentially
brings it closer to the diagonal as represented by <cite>prediction_constant</cite>. In
this case this is not required since the curves intersect, but we are
actually slightly inaccurate because we only determine the minimum error
point on a grid of x values, instead of calculating the intersection point
analytically. By choosing a large <cite>grid_size</cite> this can be alleviated.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">postprocessed_predictor_EO</span><span class="o">.</span><span class="n">_plot</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">postprocessed_predictor_EO</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.core.frame.DataFrame" class="sphx-glr-backref-module-pandas-core-frame sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">X_train</span></a><span class="p">,</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html#pandas.Series" title="pandas.core.series.Series" class="sphx-glr-backref-module-pandas-core-series sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">y_train</span></a><span class="p">,</span> <span class="n">sensitive_features</span><span class="o">=</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html#pandas.Series" title="pandas.core.series.Series" class="sphx-glr-backref-module-pandas-core-series sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">sensitive_features_train</span></a>
<span class="p">)</span>

<span class="k">for</span> <span class="p">(</span>
    <span class="n">group</span><span class="p">,</span>
    <span class="n">interpolation</span><span class="p">,</span>
<span class="p">)</span> <span class="ow">in</span> <span class="n">postprocessed_predictor_EO</span><span class="o">.</span><span class="n">_post_processed_predictor_by_sensitive_feature</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{}</span><span class="s2">:&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">group</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2"> &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">interpolation</span><span class="o">.</span><span class="fm">__repr__</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;,&quot;</span><span class="p">)))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-----------------------------------&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>African-American:
[p_ignore: 0.26151601889416654
  prediction_constant: 0.14200000000000002
  p0: 0.8378857142857137
  operation0: [&gt;0.5825603754888381]
  p1: 0.16211428571428632
  operation1: [&gt;0.5665583358247704]]
-----------------------------------
Caucasian:
[p_ignore: 0.0
  prediction_constant: 0.14200000000000002
  p0: 0.0019999999999962322
  operation0: [&gt;0.5189601859111345]
  p1: 0.9980000000000038
  operation1: [&gt;0.51707025208793]]
-----------------------------------
</pre></div>
</div>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  3.062 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-plot-binary-classification-compas-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/f1baf35b8f217e0243288f072661e7be/plot_binary_classification_COMPAS.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">plot_binary_classification_COMPAS.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/63c0f36cfd64285ca660447b7b7f6b64/plot_binary_classification_COMPAS.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">plot_binary_classification_COMPAS.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>
</div>


              </div>
              
              
          </main>
          

      </div>
    </div>
  
  <script src="../_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  <footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="copyright">
    &copy; Copyright 2018 - 2022, Fairlearn contributors.<br/>
</p>
    </div>
    
    <div class="footer-item">
      <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 4.2.0.<br/>
</p>
    </div>
    
  </div>
</footer>
  </body>
</html>